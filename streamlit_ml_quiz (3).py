    {'category': 'Hyperparameter Tuning', 'question': 'What is dropout rate?', 'options': ['Learning rate', 'Fraction of neurons to drop', 'Batch size', 'Epochs'], 'correct': 1, 'explanation': 'Typically 0.2-0.5 for regularization.'},
    {'category': 'Hyperparameter Tuning', 'question': 'What is momentum?', 'options': ['Learning rate', 'Fraction of previous gradient', 'Batch size', 'Dropout'], 'correct': 1, 'explanation': 'Accelerates optimization.'},
    {'category': 'Hyperparameter Tuning', 'question': 'What is weight decay?', 'options': ['Dropout', 'L2 regularization strength', 'Learning rate', 'Momentum'], 'correct': 1, 'explanation': 'Penalizes large weights.'},
    {'category': 'Hyperparameter Tuning', 'question': 'What is patience in early stopping?', 'options': ['Epochs', 'Epochs to wait before stopping', 'Learning rate', 'Batch size'], 'correct': 1, 'explanation': 'Tolerance for no improvement.'},
    
    # Deep Learning Concepts (30 questions)
    {'category': 'Deep Learning', 'question': 'What is deep learning?', 'options': ['Shallow networks', 'Neural networks with many layers', 'Linear models', 'Trees'], 'correct': 1, 'explanation': 'ML using multi-layer neural networks.'},
    {'category': 'Deep Learning', 'question': 'What is CNN?', 'options': ['RNN', 'Convolutional Neural Network', 'Fully connected', 'LSTM'], 'correct': 1, 'explanation': 'For image and spatial data.'},
    {'category': 'Deep Learning', 'question': 'What is RNN?', 'options': ['CNN', 'Recurrent Neural Network', 'Fully connected', 'Transformer'], 'correct': 1, 'explanation': 'For sequential data.'},
    {'category': 'Deep Learning', 'question': 'What is LSTM?', 'options': ['RNN variant', 'Long Short-Term Memory', 'CNN', 'Transformer'], 'correct': 1, 'explanation': 'Handles long-term dependencies.'},
    {'category': 'Deep Learning', 'question': 'What is GRU?', 'options': ['LSTM', 'Gated Recurrent Unit', 'CNN', 'RNN'], 'correct': 1, 'explanation': 'Simpler than LSTM.'},
    {'category': 'Deep Learning', 'question': 'What is attention mechanism?', 'options': ['Pooling', 'Focus on relevant parts', 'Dropout', 'Convolution'], 'correct': 1, 'explanation': 'Learns what to focus on.'},
    {'category': 'Deep Learning', 'question': 'What is self-attention?', 'options': ['Cross-attention', 'Attention within same sequence', 'No attention', 'External'], 'correct': 1, 'explanation': 'Relates positions in single sequence.'},
    {'category': 'Deep Learning', 'question': 'What is transformer?', 'options': ['RNN', 'Architecture using attention', 'CNN', 'LSTM'], 'correct': 1, 'explanation': 'Based entirely on attention.'},
    {'category': 'Deep Learning', 'question': 'What is BERT?', 'options': ['GPT', 'Bidirectional Encoder Representations', 'CNN', 'RNN'], 'correct': 1, 'explanation': 'Transformer for understanding.'},
    {'category': 'Deep Learning', 'question': 'What is GPT?', 'options': ['BERT', 'Generative Pre-trained Transformer', 'CNN', 'RNN'], 'correct': 1, 'explanation': 'Transformer for generation.'},
    {'category': 'Deep Learning', 'question': 'What is transfer learning?', 'options': ['Train from scratch', 'Use pre-trained weights', 'No learning', 'Random init'], 'correct': 1, 'explanation': 'Leverages existing knowledge.'},
    {'category': 'Deep Learning', 'question': 'What is fine-tuning?', 'options': ['No training', 'Adjust pre-trained model', 'Train from scratch', 'Freeze all'], 'correct': 1, 'explanation': 'Adapts model to new task.'},
    {'category': 'Deep Learning', 'question': 'What is feature extraction?', 'options': ['Fine-tuning', 'Use pre-trained as fixed features', 'Train all', 'No features'], 'correct': 1, 'explanation': 'Freeze pre-trained layers.'},
    {'category': 'Deep Learning', 'question': 'What is autoencoder?', 'options': ['Supervised', 'Unsupervised encoder-decoder', 'Classification', 'Regression'], 'correct': 1, 'explanation': 'Learns compressed representation.'},
    {'category': 'Deep Learning', 'question': 'What is VAE?', 'options': ['Autoencoder', 'Variational Autoencoder', 'GAN', 'CNN'], 'correct': 1, 'explanation': 'Probabilistic autoencoder.'},
    {'category': 'Deep Learning', 'question': 'What is GAN?', 'options': ['Autoencoder', 'Generative Adversarial Network', 'CNN', 'RNN'], 'correct': 1, 'explanation': 'Generator vs discriminator.'},
    {'category': 'Deep Learning', 'question': 'What is generator in GAN?', 'options': ['Discriminator', 'Creates fake samples', 'Classifier', 'Encoder'], 'correct': 1, 'explanation': 'Generates synthetic data.'},
    {'category': 'Deep Learning', 'question': 'What is discriminator in GAN?', 'options': ['Generator', 'Distinguishes real from fake', 'Encoder', 'Decoder'], 'correct': 1, 'explanation': 'Judges authenticity.'},
    {'category': 'Deep Learning', 'question': 'What is ResNet?', 'options': ['Standard CNN', 'CNN with residual connections', 'RNN', 'Transformer'], 'correct': 1, 'explanation': 'Skip connections enable depth.'},
    {'category': 'Deep Learning', 'question': 'What is VGG?', 'options': ['ResNet', 'Deep CNN with small filters', 'RNN', 'Transformer'], 'correct': 1, 'explanation': 'Uses 3x3 convolutions.'},
    {'category': 'Deep Learning', 'question': 'What is Inception?', 'options': ['Single path', 'Multi-scale convolutions', 'RNN', 'Simple'], 'correct': 1, 'explanation': 'Parallel convolution paths.'},
    {'category': 'Deep Learning', 'question': 'What is U-Net?', 'options': ['Classification', 'Encoder-decoder for segmentation', 'Generation', 'Detection'], 'correct': 1, 'explanation': 'For image segmentation.'},
    {'category': 'Deep Learning', 'question': 'What is YOLO?', 'options': ['Segmentation', 'Real-time object detection', 'Classification', 'Generation'], 'correct': 1, 'explanation': 'You Only Look Once detector.'},
    {'category': 'Deep Learning', 'question': 'What is R-CNN?', 'options': ['YOLO', 'Region-based CNN', 'Segmentation', 'Classification'], 'correct': 1, 'explanation': 'Object detection with regions.'},
    {'category': 'Deep Learning', 'question': 'What is Faster R-CNN?', 'options': ['Slower', 'Faster with region proposal network', 'R-CNN', 'YOLO'], 'correct': 1, 'explanation': 'End-to-end object detection.'},
    {'category': 'Deep Learning', 'question': 'What is semantic segmentation?', 'options': ['Instance', 'Pixel-wise class labels', 'Detection', 'Classification'], 'correct': 1, 'explanation': 'Labels every pixel.'},
    {'category': 'Deep Learning', 'question': 'What is instance segmentation?', 'options': ['Semantic', 'Separate objects of same class', 'Detection', 'Classification'], 'correct': 1, 'explanation': 'Distinguishes individual instances.'},
    {'category': 'Deep Learning', 'question': 'What is word2vec?', 'options': ['Sentence embedding', 'Word embeddings', 'Character level', 'No embedding'], 'correct': 1, 'explanation': 'Dense word representations.'},
    {'category': 'Deep Learning', 'question': 'What is GloVe?', 'options': ['Word2vec', 'Global Vectors for word representation', 'Character', 'Sentence'], 'correct': 1, 'explanation': 'Uses co-occurrence statistics.'},
    {'category': 'Deep Learning', 'question': 'What is positional encoding?', 'options': ['No encoding', 'Adds position information', 'Only attention', 'Convolution'], 'correct': 1, 'explanation': 'For transformers without recurrence.'},
    
    # Clustering (25 questions)
    {'category': 'Clustering', 'question': 'What is clustering?', 'options': ['Supervised', 'Unsupervised grouping', 'Classification', 'Regression'], 'correct': 1, 'explanation': 'Groups similar data without labels.'},
    {'category': 'Clustering', 'question': 'What is K-Means?', 'options': ['Hierarchical', 'Partition-based clustering', 'Density-based', 'Model-based'], 'correct': 1, 'explanation': 'Iterative centroid-based method.'},
    {'category': 'Clustering', 'question': 'What is hierarchical clustering?', 'options': ['K-Means', 'Builds tree of clusters', 'Density', 'Model-based'], 'correct': 1, 'explanation': 'Creates nested cluster hierarchy.'},
    {'category': 'Clustering', 'question': 'What is agglomerative?', 'options': ['Divisive', 'Bottom-up merging', 'Top-down', 'Random'], 'correct': 1, 'explanation': 'Merges clusters iteratively.'},
    {'category': 'Clustering', 'question': 'What is divisive?', 'options': ['Agglomerative', 'Top-down splitting', 'Bottom-up', 'Random'], 'correct': 1, 'explanation': 'Splits clusters iteratively.'},
    {'category': 'Clustering', 'question': 'What is DBSCAN?', 'options': ['K-Means', 'Density-based clustering', 'Hierarchical', 'Model-based'], 'correct': 1, 'explanation': 'Finds arbitrary-shaped clusters.'},
    {'category': 'Clustering', 'question': 'What is epsilon in DBSCAN?', 'options': ['Min points', 'Neighborhood radius', 'Clusters', 'Distance metric'], 'correct': 1, 'explanation': 'Defines neighborhood size.'},
    {'category': 'Clustering', 'question': 'What is min_samples in DBSCAN?', 'options': ['Epsilon', 'Minimum points for core', 'Clusters', 'Distance'], 'correct': 1, 'explanation': 'Core point threshold.'},
    {'category': 'Clustering', 'question': 'What is core point?', 'options': ['Border', 'Point with min_samples in epsilon', 'Noise', 'Outlier'], 'correct': 1, 'explanation': 'Density criterion satisfied.'},
    {'category': 'Clustering', 'question': 'What is border point?', 'options': ['Core', 'In neighborhood but not core', 'Noise', 'Center'], 'correct': 1, 'explanation': 'Reachable from core.'},
    {'category': 'Clustering', 'question': 'What is noise point?', 'options': ['Core', 'Not core or border', 'Border', 'Center'], 'correct': 1, 'explanation': 'Outlier not in any cluster.'},
    {'category': 'Clustering', 'question': 'What is dendrogram?', 'options': ['K-Means plot', 'Hierarchical cluster tree', 'Scatter plot', 'Bar chart'], 'correct': 1, 'explanation': 'Visualizes hierarchical clustering.'},
    {'category': 'Clustering', 'question': 'What is linkage?', 'options': ['No linking', 'Method to measure cluster distance', 'Single cluster', 'No distance'], 'correct': 1, 'explanation': 'Defines inter-cluster distance.'},
    {'category': 'Clustering', 'question': 'What is single linkage?', 'options': ['Complete', 'Minimum distance between clusters', 'Average', 'Centroid'], 'correct': 1, 'explanation': 'Nearest neighbor distance.'},
    {'category': 'Clustering', 'question': 'What is complete linkage?', 'options': ['Single', 'Maximum distance between clusters', 'Average', 'Centroid'], 'correct': 1, 'explanation': 'Farthest neighbor distance.'},
    {'category': 'Clustering', 'question': 'What is average linkage?', 'options': ['Single', 'Average distance between clusters', 'Complete', 'Centroid'], 'correct': 1, 'explanation': 'Mean of all pairwise distances.'},
    {'category': 'Clustering', 'question': 'What is Ward linkage?', 'options': ['Single', 'Minimizes within-cluster variance', 'Average', 'Complete'], 'correct': 1, 'explanation': 'Minimizes total variance.'},
    {'category': 'Clustering', 'question': 'What is GMM?', 'options': ['K-Means', 'Gaussian Mixture Model', 'DBSCAN', 'Hierarchical'], 'correct': 1, 'explanation': 'Probabilistic clustering.'},
    {'category': 'Clustering', 'question': 'What is EM algorithm?', 'options': ['K-Means', 'Expectation-Maximization', 'DBSCAN', 'Gradient descent'], 'correct': 1, 'explanation': 'Iterative optimization for GMM.'},
    {'category': 'Clustering', 'question': 'What is Mean Shift?', 'options': ['K-Means', 'Density-based mode seeking', 'Hierarchical', 'GMM'], 'correct': 1, 'explanation': 'Finds density peaks.'},
    {'category': 'Clustering', 'question': 'What is spectral clustering?', 'options': ['K-Means', 'Graph-based clustering', 'Density', 'Hierarchical'], 'correct': 1, 'explanation': 'Uses graph theory.'},
    {'category': 'Clustering', 'question': 'What is affinity propagation?', 'options': ['K-Means', 'Message passing between points', 'Density', 'Hierarchical'], 'correct': 1, 'explanation': 'Finds exemplars automatically.'},
    {'category': 'Clustering', 'question': 'What is OPTICS?', 'options': ['DBSCAN', 'Ordering Points for cluster identification', 'K-Means', 'Hierarchical'], 'correct': 1, 'explanation': 'Extends DBSCAN for varying density.'},
    {'category': 'Clustering', 'question': 'What is HDBSCAN?', 'options': ['DBSCAN', 'Hierarchical DBSCAN', 'K-Means', 'GMM'], 'correct': 1, 'explanation': 'Hierarchical density-based.'},
    {'category': 'Clustering', 'question': 'What is BIRCH?', 'options': ['K-Means', 'Balanced Iterative Reducing Clustering', 'DBSCAN', 'GMM'], 'correct': 1, 'explanation': 'For large datasets efficiently.'},
    
    # Dimensionality Reduction (20 questions)
    {'category': 'Dimensionality Reduction', 'question': 'What is dimensionality reduction?', 'options': ['Increase dimensions', 'Reduce feature count', 'No change', 'Add features'], 'correct': 1, 'explanation': 'Reduces feature space.'},
    {'category': 'Dimensionality Reduction', 'question': 'What is PCA?', 'options': ['Supervised', 'Principal Component Analysis', 'Clustering', 'Classification'], 'correct': 1, 'explanation': 'Linear dimensionality reduction.'},
    {'category': 'Dimensionality Reduction', 'question': 'What is t-SNE?', 'options': ['Linear', 't-distributed Stochastic Neighbor Embedding', 'PCA', 'Supervised'], 'correct': 1, 'explanation': 'Non-linear visualization method.'},
    {'category': 'Dimensionality Reduction', 'question': 'What is UMAP?', 'options': ['PCA', 'Uniform Manifold Approximation', 't-SNE', 'Linear'], 'correct': 1, 'explanation': 'Preserves global and local structure.'},
    {'category': 'Dimensionality Reduction', 'question': 'What is LDA?', 'options': ['PCA', 'Linear Discriminant Analysis', 't-SNE', 'UMAP'], 'correct': 1, 'explanation': 'Supervised dimensionality reduction.'},
    {'category': 'Dimensionality Reduction', 'question': 'What is SVD?', 'options': ['PCA', 'Singular Value Decomposition', 't-SNE', 'LDA'], 'correct': 1, 'explanation': 'Matrix factorization technique.'},
    {'category': 'Dimensionality Reduction', 'question': 'What is ICA?', 'options': ['PCA', 'Independent Component Analysis', 't-SNE', 'LDA'], 'correct': 1, 'explanation': 'Finds statistically independent components.'},
    {'category': 'Dimensionality Reduction', 'question': 'What is MDS?', 'options': ['PCA', 'Multidimensional Scaling', 't-SNE', 'LDA'], 'correct': 1, 'explanation': 'Preserves distances between points.'},
    {'category': 'Dimensionality Reduction', 'question': 'What is Isomap?', 'options': ['PCA', 'Geodesic distance preservation', 't-SNE', 'Linear'], 'correct': 1, 'explanation': 'Non-linear using manifold.'},
    {'category': 'Dimensionality Reduction', 'question': 'What is LLE?', 'options': ['PCA', 'Locally Linear Embedding', 't-SNE', 'Global'], 'correct': 1, 'explanation': 'Preserves local neighborhoods.'},
    {'category': 'Dimensionality Reduction', 'question': 'What is autoencoder for DR?', 'options': ['PCA', 'Neural network encoder-decoder', 't-SNE', 'Linear'], 'correct': 1, 'explanation': 'Non-linear via neural networks.'},
    {'category': 'Dimensionality Reduction', 'question': 'What is feature selection?', 'options': ['Feature extraction', 'Choosing subset of features', 'Creating features', 'All features'], 'correct': 1, 'explanation': 'Selects most relevant features.'},
    {'category': 'Dimensionality Reduction', 'question': 'What is feature extraction?', 'options': ['Selection', 'Creating new features', 'Removing', 'No change'], 'correct': 1, 'explanation': 'Transforms to new features.'},
    {'category': 'Dimensionality Reduction', 'question': 'What is manifold learning?', 'options': ['Linear', 'Non-linear DR assuming manifold', 'PCA', 'Supervised'], 'correct': 1, 'explanation': 'Assumes data on lower-dim manifold.'},
    {'category': 'Dimensionality Reduction', 'question': 'When to use PCA vs t-SNE?', 'options': ['Always PCA', 'PCA for features, t-SNE for viz', 'Always t-SNE', 'No difference'], 'correct': 1, 'explanation': 'PCA preserves variance, t-SNE for visualization.'},
    {'category': 'Dimensionality Reduction', 'question': 'What is perplexity in t-SNE?', 'options': ['Learning rate', 'Balance local vs global structure', 'Iterations', 'Components'], 'correct': 1, 'explanation': 'Typically 5-50, affects neighborhood size.'},
    {'category': 'Dimensionality Reduction', 'question': 'Can t-SNE embed new data?', 'options': ['Yes, directly', 'No, needs retraining', 'Yes, easily', 'Always'], 'correct': 1, 'explanation': 't-SNE doesn\'t provide transform for new data.'},
    {'category': 'Dimensionality Reduction', 'question': 'Can UMAP embed new data?', 'options': ['No', 'Yes, has transform method', 'Never', 'Difficult'], 'correct': 1, 'explanation': 'UMAP can transform new samples.'},
    {'category': 'Dimensionality Reduction', 'question': 'What is curse of dimensionality?', 'options': ['More is better', 'Data sparse in high dimensions', 'No effect', 'Always good'], 'correct': 1, 'explanation': 'Distance metrics lose meaning.'},
    {'category': 'Dimensionality Reduction', 'question': 'What is intrinsic dimensionality?', 'options': ['Original dimensions', 'True underlying dimensions', 'Maximum dimensions', 'No dimension'], 'correct': 1, 'explanation': 'Actual degrees of freedom in data.'},
    
    # Additional Advanced Topics (50+ questions)
    {'category': 'Advanced ML', 'question': 'What is online learning?', 'options': ['Batch learning', 'Incremental learning from stream', 'No learning', 'Offline'], 'correct': 1, 'explanation': 'Updates model with new data continuously.'},
    {'category': 'Advanced ML', 'question': 'What is batch learning?', 'options': ['Online', 'Trains on entire dataset at once', 'Streaming', 'Incremental'], 'correct': 1, 'explanation': 'Traditional offline training.'},
    {'category': 'Advanced ML', 'question': 'What is active learning?', 'options': ['Passive', 'Model queries for labels', 'No queries', 'Supervised'], 'correct': 1, 'explanation': 'Selects most informative samples.'},
    {'category': 'Advanced ML', 'question': 'What is semi-supervised learning?', 'options': ['Supervised', 'Uses labeled and unlabeled data', 'Unsupervised', 'No labels'], 'correct': 1, 'explanation': 'Leverages both labeled and unlabeled.'},
    {'category': 'Advanced ML', 'question': 'What is self-supervised learning?', 'options': ['Supervised', 'Creates labels from data itself', 'Unsupervised', 'Semi-supervised'], 'correct': 1, 'explanation': 'Generates supervision signal automatically.'},
    {'category': 'Advanced ML', 'question': 'What is few-shot learning?', 'options': ['Many samples', 'Learning from few examples', 'No learning', 'Large dataset'], 'correct': 1, 'explanation': 'Works with minimal data.'},
    {'category': 'Advanced ML', 'question': 'What is zero-shot learning?', 'options': ['Few-shot', 'No training examples for new class', 'Many shots', 'Standard'], 'correct': 1, 'explanation': 'Generalizes to unseen classes.'},
    {'category': 'Advanced ML', 'question': 'What is meta-learning?', 'options': ['Standard learning', 'Learning to learn', 'No learning', 'Single task'], 'correct': 1, 'explanation': 'Learns how to learn quickly.'},
    {'category': 'Advanced ML', 'question': 'What is multi-task learning?', 'options': ['Single task', 'Trains on multiple related tasks', 'No tasks', 'Independent'], 'correct': 1, 'explanation': 'Shared representation across tasks.'},
    {'category': 'Advanced ML', 'question': 'What is continual learning?', 'options': ['Single task', 'Learn new tasks without forgetting', 'Forgets', 'Static'], 'correct': 1, 'explanation': 'Addresses catastrophic forgetting.'},
    {'category': 'Advanced ML', 'question': 'What is catastrophic forgetting?', 'options': ['Remembers all', 'Forgets old when learning new', 'No forgetting', 'Improves'], 'correct': 1, 'explanation': 'Neural networks forget previous tasks.'},
    {'category': 'Advanced ML', 'question': 'What is domain adaptation?', 'options': ['Same domain', 'Transfer between domains', 'No adaptation', 'Single domain'], 'correct': 1, 'explanation': 'Adapts model to new domain.'},
    {'category': 'Advanced ML', 'question': 'What is adversarial examples?', 'options': ['Normal inputs', 'Inputs designed to fool model', 'Clean data', 'Training data'], 'correct': 1, 'explanation': 'Perturbed inputs causing misclassification.'},
    {'category': 'Advanced ML', 'question': 'What is adversarial training?', 'options': ['Normal training', 'Train on adversarial examples', 'No training', 'Clean data only'], 'correct': 1, 'explanation': 'Improves robustness to adversarial attacks.'},
    {'category': 'Advanced ML', 'question': 'What is explainable AI?', 'options': ['Black box', 'Interpretable ML models', 'No explanation', 'Hidden'], 'correct': 1, 'explanation': 'Makes model decisions understandable.'},
    {'category': 'Advanced ML', 'question': 'What is LIME?', 'options': ['Model', 'Local Interpretable Model-agnostic Explanations', 'Algorithm', 'Loss'], 'correct': 1, 'explanation': 'Explains individual predictions.'},
    {'category': 'Advanced ML', 'question': 'What is SHAP?', 'options': ['Model', 'SHapley Additive exPlanations', 'Algorithm', 'Loss'], 'correct': 1, 'explanation': 'Unified approach to explain predictions.'},
    {'category': 'Advanced ML', 'question': 'What is model compression?', 'options': ['Enlarging', 'Reducing model size', 'No change', 'Expansion'], 'correct': 1, 'explanation': 'Makes models smaller for deployment.'},
    {'category': 'Advanced ML', 'question': 'What is quantization?', 'options': ['Float32 only', 'Reduce numerical precision', 'No reduction', 'Increase precision'], 'correct': 1, 'explanation': 'Uses INT8 instead of FP32.'},
    {'category': 'Advanced ML', 'question': 'What is pruning?', 'options': ['Add weights', 'Remove unimportant weights', 'No removal', 'Keep all'], 'correct': 1, 'explanation': 'Removes low-magnitude connections.'},
    {'category': 'Advanced ML', 'question': 'What is knowledge distillation?', 'options': ['Single model', 'Transfer from teacher to student', 'No transfer', 'Same size'], 'correct': 1, 'explanation': 'Compresses large model to small.'},
    {'category': 'Advanced ML', 'question': 'What is AutoML?', 'options': ['Manual ML', 'Automated machine learning', 'No automation', 'Human only'], 'correct': 1, 'explanation': 'Automates model selection and tuning.'},
    {'category': 'Advanced ML', 'question': 'What is NAS?', 'options': ['Manual design', 'Neural Architecture Search', 'No search', 'Fixed'], 'correct': 1, 'explanation': 'Automatically finds architectures.'},
    {'category': 'Advanced ML', 'question': 'What is HPO?', 'options': ['No optimization', 'Hyperparameter Optimization', 'Manual tuning', 'Fixed parameters'], 'correct': 1, 'explanation': 'Automated hyperparameter tuning.'},
    {'category': 'Advanced ML', 'question': 'What is federated learning?', 'options': ['Centralized', 'Distributed training on devices', 'Single device', 'Cloud only'], 'correct': 1, 'explanation': 'Trains without centralizing data.'},
    {'category': 'Advanced ML', 'question': 'What is differential privacy?', 'options': ['No privacy', 'Privacy-preserving learning', 'Public data', 'No protection'], 'correct': 1, 'explanation': 'Protects individual data points.'},
    {'category': 'Advanced ML', 'question': 'What is fairness in ML?', 'options': ['Bias is fine', 'Preventing discriminatory predictions', 'No concern', 'Ignore bias'], 'correct': 1, 'explanation': 'Ensures equitable treatment.'},
    {'category': 'Advanced ML', 'question': 'What is model bias?', 'options': ['No bias', 'Systematic errors in predictions', 'Random', 'Perfect'], 'correct': 1, 'explanation': 'Unfair treatment of groups.'},
    {'category': 'Advanced ML', 'question': 'What is data augmentation?', 'options': ['Reduce data', 'Artificially expand dataset', 'Delete data', 'No change'], 'correct': 1, 'explanation': 'Creates variations of training data.'},
    {'category': 'Advanced ML', 'question': 'What is data leakage?', 'options': ['No problem', 'Test info in training data', 'Good practice', 'Helps model'], 'correct': 1, 'explanation': 'Causes overly optimistic results.'}
]

def get_categories():    {'category': 'Feature Engineering', 'question': 'What is Z-score method?', 'options': ['IQR', 'Standard deviations from mean', 'Quartile-based', 'No method'], 'correct': 1, 'explanation': 'Outliers beyond ±3 standard deviations.'},
    {'category': 'Feature Engineering', 'question': 'What is feature aggregation?', 'options': ['No aggregation', 'Combining features with statistics', 'Selection', 'Removal'], 'correct': 1, 'explanation': 'Creates sum, mean, max, etc. of features.'},
    {'category': 'Feature Engineering', 'question': 'What is lag feature?', 'options': ['Current value', 'Previous time step values', 'Future value', 'No lag'], 'correct': 1, 'explanation': 'For time series, uses past values.'},
    {'category': 'Feature Engineering', 'question': 'What is rolling window?', 'options': ['Single point', 'Statistics over sliding window', 'No window', 'Fixed window'], 'correct': 1, 'explanation': 'Moving average, sum, etc.'},
    {'category': 'Feature Engineering', 'question': 'What is domain knowledge in FE?', 'options': ['Not important', 'Expert insights for creating features', 'Automatic', 'Random'], 'correct': 1, 'explanation': 'Uses field expertise to engineer meaningful features.'},
    
    # Ensemble Methods (30 questions)
    {'category': 'Ensemble Methods', 'question': 'What is ensemble learning?', 'options': ['Single model', 'Combining multiple models', 'Preprocessing', 'Feature selection'], 'correct': 1, 'explanation': 'Improves predictions by combining models.'},
    {'category': 'Ensemble Methods', 'question': 'What is bagging?', 'options': ['Sequential', 'Parallel training with bootstrap', 'No sampling', 'Boosting'], 'correct': 1, 'explanation': 'Bootstrap AGGregatING.'},
    {'category': 'Ensemble Methods', 'question': 'What is boosting?', 'options': ['Parallel', 'Sequential error correction', 'Bagging', 'Stacking'], 'correct': 1, 'explanation': 'Models trained sequentially on errors.'},
    {'category': 'Ensemble Methods', 'question': 'What is stacking?', 'options': ['Bagging', 'Meta-model on base predictions', 'Boosting', 'Voting'], 'correct': 1, 'explanation': 'Trains meta-learner on model outputs.'},
    {'category': 'Ensemble Methods', 'question': 'What is blending?', 'options': ['Stacking', 'Simpler stacking with holdout', 'Bagging', 'Boosting'], 'correct': 1, 'explanation': 'Uses holdout instead of CV.'},
    {'category': 'Ensemble Methods', 'question': 'What is voting classifier?', 'options': ['Single vote', 'Combines predictions by voting', 'Boosting', 'Bagging'], 'correct': 1, 'explanation': 'Hard or soft voting across models.'},
    {'category': 'Ensemble Methods', 'question': 'What is hard voting?', 'options': ['Soft voting', 'Majority class vote', 'Probability', 'Weighted'], 'correct': 1, 'explanation': 'Takes most frequent prediction.'},
    {'category': 'Ensemble Methods', 'question': 'What is soft voting?', 'options': ['Hard voting', 'Average class probabilities', 'Majority', 'No probabilities'], 'correct': 1, 'explanation': 'Averages predicted probabilities.'},
    {'category': 'Ensemble Methods', 'question': 'What is base learner?', 'options': ['Meta-learner', 'Individual model in ensemble', 'No learner', 'Final model'], 'correct': 1, 'explanation': 'Models combined in ensemble.'},
    {'category': 'Ensemble Methods', 'question': 'What is meta-learner?', 'options': ['Base learner', 'Model trained on base predictions', 'No learning', 'First layer'], 'correct': 1, 'explanation': 'Final model in stacking.'},
    {'category': 'Ensemble Methods', 'question': 'What is diversity in ensembles?', 'options': ['Same models', 'Different models or data', 'No diversity', 'Identical'], 'correct': 1, 'explanation': 'Varied models improve ensemble.'},
    {'category': 'Ensemble Methods', 'question': 'Why do ensembles work?', 'options': ['Magic', 'Reduce variance via averaging', 'Increase bias', 'Random'], 'correct': 1, 'explanation': 'Combining reduces prediction variance.'},
    {'category': 'Ensemble Methods', 'question': 'What is AdaBoost?', 'options': ['Bagging', 'Adaptive boosting with weights', 'Stacking', 'Voting'], 'correct': 1, 'explanation': 'Focuses on misclassified samples.'},
    {'category': 'Ensemble Methods', 'question': 'What is gradient boosting?', 'options': ['AdaBoost', 'Boosting via gradient descent', 'Bagging', 'Stacking'], 'correct': 1, 'explanation': 'Optimizes arbitrary loss functions.'},
    {'category': 'Ensemble Methods', 'question': 'What is XGBoost?', 'options': ['Random Forest', 'Extreme Gradient Boosting', 'AdaBoost', 'Bagging'], 'correct': 1, 'explanation': 'Optimized gradient boosting.'},
    {'category': 'Ensemble Methods', 'question': 'What is LightGBM?', 'options': ['XGBoost', 'Gradient boosting with histograms', 'Random Forest', 'AdaBoost'], 'correct': 1, 'explanation': 'Faster GB with histogram-based.'},
    {'category': 'Ensemble Methods', 'question': 'What is CatBoost?', 'options': ['XGBoost', 'GB for categorical features', 'Random Forest', 'AdaBoost'], 'correct': 1, 'explanation': 'Handles categorical natively.'},
    {'category': 'Ensemble Methods', 'question': 'What is Extra Trees?', 'options': ['Random Forest', 'Extremely randomized trees', 'Boosting', 'Stacking'], 'correct': 1, 'explanation': 'More randomness than RF.'},
    {'category': 'Ensemble Methods', 'question': 'What is Isolation Forest?', 'options': ['Classification', 'Anomaly detection ensemble', 'Regression', 'Clustering'], 'correct': 1, 'explanation': 'Isolates outliers efficiently.'},
    {'category': 'Ensemble Methods', 'question': 'What is feature importance in RF?', 'options': ['No importance', 'Average decrease in impurity', 'Coefficients', 'P-values'], 'correct': 1, 'explanation': 'Measures feature contribution.'},
    {'category': 'Ensemble Methods', 'question': 'What is OOB score?', 'options': ['Training score', 'Out-of-bag validation score', 'Test score', 'CV score'], 'correct': 1, 'explanation': 'Validation on unsampled data.'},
    {'category': 'Ensemble Methods', 'question': 'What is bootstrapping?', 'options': ['No sampling', 'Sampling with replacement', 'Without replacement', 'All data'], 'correct': 1, 'explanation': 'Creates diverse training sets.'},
    {'category': 'Ensemble Methods', 'question': 'What is pasting?', 'options': ['With replacement', 'Sampling without replacement', 'Bootstrapping', 'No sampling'], 'correct': 1, 'explanation': 'Like bagging without replacement.'},
    {'category': 'Ensemble Methods', 'question': 'What is random patches?', 'options': ['All data', 'Sample both rows and features', 'Only rows', 'Only features'], 'correct': 1, 'explanation': 'Samples data and feature subsets.'},
    {'category': 'Ensemble Methods', 'question': 'What is random subspaces?', 'options': ['Sample rows', 'Sample features only', 'All data', 'No sampling'], 'correct': 1, 'explanation': 'Uses all data, random features.'},
    {'category': 'Ensemble Methods', 'question': 'What is cascade ensemble?', 'options': ['Single level', 'Multiple stacking levels', 'No cascade', 'Parallel'], 'correct': 1, 'explanation': 'Stacks multiple meta-learner layers.'},
    {'category': 'Ensemble Methods', 'question': 'What is snapshot ensemble?', 'options': ['Single model', 'Saves models at different training stages', 'No snapshots', 'Final only'], 'correct': 1, 'explanation': 'Creates ensemble from one training run.'},
    {'category': 'Ensemble Methods', 'question': 'What is mixture of experts?', 'options': ['Single expert', 'Gating network routes to experts', 'All experts', 'No gating'], 'correct': 1, 'explanation': 'Different models for different inputs.'},
    {'category': 'Ensemble Methods', 'question': 'What is model averaging?', 'options': ['Single model', 'Average predictions across models', 'No averaging', 'Voting'], 'correct': 1, 'explanation': 'Simple ensemble technique.'},
    {'category': 'Ensemble Methods', 'question': 'What is weighted averaging?', 'options': ['Equal weights', 'Different weights per model', 'No weights', 'Single weight'], 'correct': 1, 'explanation': 'Weights based on model performance.'},
    
    # Time Series (25 questions)
    {'category': 'Time Series', 'question': 'What is time series data?', 'options': ['Independent', 'Data points ordered by time', 'Random', 'Unordered'], 'correct': 1, 'explanation': 'Sequential temporal observations.'},
    {'category': 'Time Series', 'question': 'What is stationarity?', 'options': ['Changing statistics', 'Constant mean and variance over time', 'Trending', 'Seasonal'], 'correct': 1, 'explanation': 'Statistical properties don\'t change.'},
    {'category': 'Time Series', 'question': 'What is trend?', 'options': ['No pattern', 'Long-term increase or decrease', 'Random', 'Seasonal'], 'correct': 1, 'explanation': 'Overall direction of series.'},
    {'category': 'Time Series', 'question': 'What is seasonality?', 'options': ['Random', 'Regular periodic patterns', 'Trend', 'No pattern'], 'correct': 1, 'explanation': 'Repeating patterns at fixed intervals.'},
    {'category': 'Time Series', 'question': 'What is ARIMA?', 'options': ['Classification', 'AutoRegressive Integrated Moving Average', 'Clustering', 'Regression'], 'correct': 1, 'explanation': 'Combines AR, I, and MA components.'},
    {'category': 'Time Series', 'question': 'What is AR in ARIMA?', 'options': ['Moving average', 'AutoRegressive - uses past values', 'Integrated', 'No component'], 'correct': 1, 'explanation': 'Predicts from previous observations.'},
    {'category': 'Time Series', 'question': 'What is MA in ARIMA?', 'options': ['Autoregressive', 'Moving Average - uses past errors', 'Integrated', 'No component'], 'correct': 1, 'explanation': 'Models error terms.'},
    {'category': 'Time Series', 'question': 'What is I in ARIMA?', 'options': ['Autoregressive', 'Integrated - differencing order', 'Moving average', 'No component'], 'correct': 1, 'explanation': 'Makes series stationary.'},
    {'category': 'Time Series', 'question': 'What is differencing?', 'options': ['Addition', 'Subtract previous value', 'Multiplication', 'No operation'], 'correct': 1, 'explanation': 'Removes trend, achieves stationarity.'},
    {'category': 'Time Series', 'question': 'What is ACF?', 'options': ['Partial correlation', 'AutoCorrelation Function', 'No correlation', 'Cross-correlation'], 'correct': 1, 'explanation': 'Correlation with lagged values.'},
    {'category': 'Time Series', 'question': 'What is PACF?', 'options': ['ACF', 'Partial AutoCorrelation Function', 'No correlation', 'Full correlation'], 'correct': 1, 'explanation': 'Correlation removing intermediate lags.'},
    {'category': 'Time Series', 'question': 'What is lag?', 'options': ['Current value', 'Time steps back', 'Future', 'No lag'], 'correct': 1, 'explanation': 'Number of time steps in the past.'},
    {'category': 'Time Series', 'question': 'What is forecasting?', 'options': ['Past prediction', 'Predicting future values', 'No prediction', 'Current value'], 'correct': 1, 'explanation': 'Estimating future observations.'},
    {'category': 'Time Series', 'question': 'What is walk-forward validation?', 'options': ['Random split', 'Train on past, test on future', 'K-fold', 'No validation'], 'correct': 1, 'explanation': 'Respects temporal order.'},
    {'category': 'Time Series', 'question': 'What is exponential smoothing?', 'options': ['Equal weights', 'Weighted average with decay', 'No smoothing', 'Simple average'], 'correct': 1, 'explanation': 'Recent observations weighted more.'},
    {'category': 'Time Series', 'question': 'What is Prophet?', 'options': ['ARIMA', 'Facebook time series tool', 'Random Forest', 'Neural network'], 'correct': 1, 'explanation': 'Additive model for forecasting.'},
    {'category': 'Time Series', 'question': 'What is LSTM for time series?', 'options': ['Statistical model', 'Neural network for sequences', 'ARIMA', 'Linear'], 'correct': 1, 'explanation': 'Captures long-term dependencies.'},
    {'category': 'Time Series', 'question': 'What is window size?', 'options': ['No window', 'Number of past observations used', 'Future size', 'All data'], 'correct': 1, 'explanation': 'Lookback period for prediction.'},
    {'category': 'Time Series', 'question': 'What is multivariate time series?', 'options': ['Single variable', 'Multiple time-dependent variables', 'Univariate', 'No variables'], 'correct': 1, 'explanation': 'Multiple series evolving together.'},
    {'category': 'Time Series', 'question': 'What is decomposition?', 'options': ['No decomposition', 'Separating trend, seasonal, residual', 'Combination', 'No separation'], 'correct': 1, 'explanation': 'Breaks into components.'},
    {'category': 'Time Series', 'question': 'What is additive decomposition?', 'options': ['Multiplicative', 'Y = Trend + Seasonal + Error', 'No decomposition', 'Division'], 'correct': 1, 'explanation': 'Components added together.'},
    {'category': 'Time Series', 'question': 'What is multiplicative decomposition?', 'options': ['Additive', 'Y = Trend * Seasonal * Error', 'No decomposition', 'Addition'], 'correct': 1, 'explanation': 'Components multiplied.'},
    {'category': 'Time Series', 'question': 'What is Dickey-Fuller test?', 'options': ['Seasonality test', 'Tests for stationarity', 'Trend test', 'No test'], 'correct': 1, 'explanation': 'Checks if series is stationary.'},
    {'category': 'Time Series', 'question': 'What is rolling mean?', 'options': ['Single value', 'Moving average over window', 'No average', 'Fixed mean'], 'correct': 1, 'explanation': 'Average over sliding window.'},
    {'category': 'Time Series', 'question': 'What is seasonal ARIMA (SARIMA)?', 'options': ['No seasonality', 'ARIMA with seasonal components', 'Standard ARIMA', 'No model'], 'correct': 1, 'explanation': 'Extends ARIMA for seasonality.'},
    
    # Model Evaluation (35 questions)
    {'category': 'Model Evaluation', 'question': 'What is cross-validation?', 'options': ['Single split', 'Multiple train/test splits', 'No validation', 'Test only'], 'correct': 1, 'explanation': 'Robust performance estimation.'},
    {'category': 'Model Evaluation', 'question': 'What is k-fold CV?', 'options': ['Single fold', 'Split data into k folds', 'No folds', 'Two folds'], 'correct': 1, 'explanation': 'Train on k-1, test on 1, repeat k times.'},
    {'category': 'Model Evaluation', 'question': 'What is stratified CV?', 'options': ['Random', 'Preserves class distribution', 'No stratification', 'All data'], 'correct': 1, 'explanation': 'Maintains class proportions.'},
    {'category': 'Model Evaluation', 'question': 'What is LOOCV?', 'options': ['K-fold', 'Leave-one-out cross-validation', 'No CV', 'Two-fold'], 'correct': 1, 'explanation': 'K=n, one sample per test fold.'},
    {'category': 'Model Evaluation', 'question': 'What is holdout validation?', 'options': ['CV', 'Single train/test split', 'No split', 'K-fold'], 'correct': 1, 'explanation': 'Simple single split.'},
    {'category': 'Model Evaluation', 'question': 'What is train/val/test split?', 'options': ['Two splits', 'Three-way data split', 'Single split', 'No split'], 'correct': 1, 'explanation': 'Training, validation, testing sets.'},
    {'category': 'Model Evaluation', 'question': 'What is accuracy?', 'options': ['Precision', 'Correct predictions / Total', 'Recall', 'F1'], 'correct': 1, 'explanation': 'Overall correctness metric.'},
    {'category': 'Model Evaluation', 'question': 'What is precision?', 'options': ['Recall', 'TP / (TP + FP)', 'Accuracy', 'F1'], 'correct': 1, 'explanation': 'Positive prediction accuracy.'},
    {'category': 'Model Evaluation', 'question': 'What is recall?', 'options': ['Precision', 'TP / (TP + FN)', 'Accuracy', 'F1'], 'correct': 1, 'explanation': 'True positive detection rate.'},
    {'category': 'Model Evaluation', 'question': 'What is F1-score?', 'options': ['Accuracy', 'Harmonic mean of precision/recall', 'Precision only', 'Recall only'], 'correct': 1, 'explanation': 'Balances precision and recall.'},
    {'category': 'Model Evaluation', 'question': 'What is F-beta score?', 'options': ['F1 only', 'Weighted F-score with beta', 'Accuracy', 'Precision'], 'correct': 1, 'explanation': 'Beta weights recall vs precision.'},
    {'category': 'Model Evaluation', 'question': 'What is ROC curve?', 'options': ['Precision-Recall', 'TPR vs FPR curve', 'Loss curve', 'Accuracy curve'], 'correct': 1, 'explanation': 'Visualizes classification performance.'},
    {'category': 'Model Evaluation', 'question': 'What is AUC?', 'options': ['Accuracy', 'Area Under Curve', 'Loss', 'F1'], 'correct': 1, 'explanation': 'Summarizes ROC performance.'},
    {'category': 'Model Evaluation', 'question': 'What is PR curve?', 'options': ['ROC', 'Precision vs Recall curve', 'Loss curve', 'Accuracy'], 'correct': 1, 'explanation': 'Better for imbalanced data.'},
    {'category': 'Model Evaluation', 'question': 'What is MSE?', 'options': ['MAE', 'Mean Squared Error', 'RMSE', 'R²'], 'correct': 1, 'explanation': 'Average squared prediction errors.'},
    {'category': 'Model Evaluation', 'question': 'What is RMSE?', 'options': ['MSE', 'Root Mean Squared Error', 'MAE', 'R²'], 'correct': 1, 'explanation': 'Square root of MSE, same units.'},
    {'category': 'Model Evaluation', 'question': 'What is MAE?', 'options': ['MSE', 'Mean Absolute Error', 'RMSE', 'R²'], 'correct': 1, 'explanation': 'Average absolute errors.'},
    {'category': 'Model Evaluation', 'question': 'What is R²?', 'options': ['MSE', 'Coefficient of determination', 'MAE', 'RMSE'], 'correct': 1, 'explanation': 'Variance explained (0-1).'},
    {'category': 'Model Evaluation', 'question': 'What is adjusted R²?', 'options': ['Standard R²', 'R² penalized for features', 'MSE', 'MAE'], 'correct': 1, 'explanation': 'Accounts for model complexity.'},
    {'category': 'Model Evaluation', 'question': 'What is MAPE?', 'options': ['MAE', 'Mean Absolute Percentage Error', 'MSE', 'R²'], 'correct': 1, 'explanation': 'Percentage-based error metric.'},
    {'category': 'Model Evaluation', 'question': 'What is log loss?', 'options': ['MSE', 'Logarithmic loss for probabilities', 'MAE', 'Accuracy'], 'correct': 1, 'explanation': 'Penalizes confident wrong predictions.'},
    {'category': 'Model Evaluation', 'question': 'What is Cohen Kappa?', 'options': ['Accuracy', 'Agreement beyond chance', 'F1', 'Precision'], 'correct': 1, 'explanation': 'Measures inter-rater agreement.'},
    {'category': 'Model Evaluation', 'question': 'What is Matthews Correlation?', 'options': ['Accuracy', 'Balanced metric using all confusion elements', 'F1', 'Precision'], 'correct': 1, 'explanation': 'Good for imbalanced data.'},
    {'category': 'Model Evaluation', 'question': 'What is silhouette score?', 'options': ['Classification', 'Clustering quality metric', 'Regression', 'F1'], 'correct': 1, 'explanation': 'Measures cluster separation.'},
    {'category': 'Model Evaluation', 'question': 'What is Davies-Bouldin index?', 'options': ['Classification', 'Clustering metric (lower better)', 'Regression', 'Accuracy'], 'correct': 1, 'explanation': 'Average similarity ratio.'},
    {'category': 'Model Evaluation', 'question': 'What is Calinski-Harabasz?', 'options': ['Classification', 'Clustering metric (higher better)', 'Regression', 'F1'], 'correct': 1, 'explanation': 'Ratio of between/within variance.'},
    {'category': 'Model Evaluation', 'question': 'What is learning curve?', 'options': ['ROC', 'Performance vs training size', 'Loss curve', 'Accuracy only'], 'correct': 1, 'explanation': 'Diagnoses bias-variance.'},
    {'category': 'Model Evaluation', 'question': 'What is validation curve?', 'options': ['Learning curve', 'Performance vs hyperparameter', 'ROC', 'Loss only'], 'correct': 1, 'explanation': 'Shows hyperparameter impact.'},
    {'category': 'Model Evaluation', 'question': 'What is baseline model?', 'options': ['Complex model', 'Simple model for comparison', 'Best model', 'No model'], 'correct': 1, 'explanation': 'Minimum performance benchmark.'},
    {'category': 'Model Evaluation', 'question': 'What is overfitting?', 'options': ['Good fit', 'Model memorizes training data', 'Underfitting', 'Perfect'], 'correct': 1, 'explanation': 'High train, low test performance.'},
    {'category': 'Model Evaluation', 'question': 'What is underfitting?', 'options': ['Overfitting', 'Model too simple', 'Good fit', 'Perfect'], 'correct': 1, 'explanation': 'Poor train and test performance.'},
    {'category': 'Model Evaluation', 'question': 'What is bias?', 'options': ['Variance', 'Error from wrong assumptions', 'Overfitting', 'No error'], 'correct': 1, 'explanation': 'Systematic prediction error.'},
    {'category': 'Model Evaluation', 'question': 'What is variance?', 'options': ['Bias', 'Error from sensitivity to data', 'Underfitting', 'No error'], 'correct': 1, 'explanation': 'Model instability across datasets.'},
    {'category': 'Model Evaluation', 'question': 'What is bias-variance tradeoff?', 'options': ['No tradeoff', 'Balance between bias and variance', 'Minimize both', 'Maximize both'], 'correct': 1, 'explanation': 'Simple: high bias, complex: high variance.'},
    {'category': 'Model Evaluation', 'question': 'What is early stopping?', 'options': ['Train fully', 'Stop when validation deteriorates', 'Never stop', 'Fixed epochs'], 'correct': 1, 'explanation': 'Prevents overfitting in iterative models.'},
    
    # Hyperparameter Tuning (20 questions)
    {'category': 'Hyperparameter Tuning', 'question': 'What are hyperparameters?', 'options': ['Learned parameters', 'Set before training', 'Weights', 'Biases'], 'correct': 1, 'explanation': 'Configuration settings not learned.'},
    {'category': 'Hyperparameter Tuning', 'question': 'What is grid search?', 'options': ['Random search', 'Exhaustive search over grid', 'No search', 'Single parameter'], 'correct': 1, 'explanation': 'Tries all combinations.'},
    {'category': 'Hyperparameter Tuning', 'question': 'What is random search?', 'options': ['Grid search', 'Random sampling of parameters', 'Exhaustive', 'No search'], 'correct': 1, 'explanation': 'Samples random combinations.'},
    {'category': 'Hyperparameter Tuning', 'question': 'What is Bayesian optimization?', 'options': ['Random', 'Uses probabilistic model to guide search', 'Grid', 'No optimization'], 'correct': 1, 'explanation': 'Intelligent search using past results.'},
    {'category': 'Hyperparameter Tuning', 'question': 'Grid vs random search?', 'options': ['Same', 'Grid exhaustive, random faster', 'Random exhaustive', 'No difference'], 'correct': 1, 'explanation': 'Random often better for high dimensions.'},
    {'category': 'Hyperparameter Tuning', 'question': 'What is hyperband?', 'options': ['Grid search', 'Bandit-based early stopping', 'Random', 'Bayesian'], 'correct': 1, 'explanation': 'Allocates resources adaptively.'},
    {'category': 'Hyperparameter Tuning', 'question': 'What is learning rate?', 'options': ['Batch size', 'Step size for optimization', 'Epochs', 'Layers'], 'correct': 1, 'explanation': 'Controls weight update magnitude.'},
    {'category': 'Hyperparameter Tuning', 'question': 'What is batch size?', 'options': ['Learning rate', 'Samples per update', 'Epochs', 'Layers'], 'correct': 1, 'explanation': 'Number of samples per gradient update.'},
    {'category': 'Hyperparameter Tuning', 'question': 'What is number of epochs?', 'options': ['Batch size', 'Full passes through data', 'Learning rate', 'Layers'], 'correct': 1, 'explanation': 'Training iterations over dataset.'},
    {'category': 'Hyperparameter Tuning', 'question': 'What is regularization strength?', 'options': ['Learning rate', 'Penalty coefficient (alpha/lambda)', 'Batch size', 'Epochs'], 'correct': 1, 'explanation': 'Controls regularization amount.'},
    {'category': 'Hyperparameter Tuning', 'question': 'What is n_estimators in RF?', 'options': ['Tree depth', 'Number of trees', 'Features', 'Samples'], 'correct': 1, 'explanation': 'How many trees to build.'},
    {'category': 'Hyperparameter Tuning', 'question': 'What is max_depth?', 'options': ['Number of trees', 'Maximum tree depth', 'Features', 'Samples'], 'correct': 1, 'explanation': 'Limits tree growth.'},
    {'category': 'Hyperparameter Tuning', 'question': 'What is min_samples_split?', 'options': ['Leaf samples', 'Minimum samples to split', 'Tree depth', 'Features'], 'correct': 1, 'explanation': 'Required samples for splitting.'},
    {'category': 'Hyperparameter Tuning', 'question': 'What is K in K-NN?', 'options': ['Clusters', 'Number of neighbors', 'Features', 'Samples'], 'correct': 1, 'explanation': 'Neighbors to consider.'},
    {'category': 'Hyperparameter Tuning', 'question': 'What is C in SVM?', 'options': ['Kernel parameter', 'Regularization parameter', 'Learning rate', 'Margin'], 'correct': 1, 'explanation': 'Trade off margin vs errors.'},
    {'category': 'Hyperparameter Tuning', 'question': 'What is gamma in RBF?', 'options': ['C parameter', 'Kernel coefficient', 'Learning rate', 'Regularization'], 'correct': 1, 'explanation': 'Controls kernel width.'},
    {'category': 'Hyperparameter Tuning', 'question': 'What is dropout rate?', 'options': ['Learning rate', 'Fraction of neurons to drop', 'Batch size', 'Epochs'], 'correct': 1,     {'category': 'Matplotlib', 'question': 'What is plt.plot?', 'options': ['Scatter', 'Line plot', 'Bar chart', 'Histogram'], 'correct': 1, 'explanation': 'Creates line plots.'},
    {'category': 'Matplotlib', 'question': 'What is plt.scatter?', 'options': ['Line', 'Scatter plot', 'Bar', 'Pie'], 'correct': 1, 'explanation': 'Shows relationships between variables.'},
    {'category': 'Matplotlib', 'question': 'What is plt.hist?', 'options': ['Line', 'Histogram showing distribution', 'Scatter', 'Box'], 'correct': 1, 'explanation': 'Displays frequency distribution.'},
    {'category': 'Matplotlib', 'question': 'What is plt.subplot?', 'options': ['Single plot', 'Creates multiple plots in grid', 'Title', 'Legend'], 'correct': 1, 'explanation': 'Creates grid of subplots.'},
    {'category': 'Matplotlib', 'question': 'What is plt.figure?', 'options': ['Plots data', 'Creates figure object', 'Saves', 'Shows'], 'correct': 1, 'explanation': 'Creates new figure container.'},
    {'category': 'Matplotlib', 'question': 'What is plt.xlabel?', 'options': ['Title', 'Sets x-axis label', 'Legend', 'Y-label'], 'correct': 1, 'explanation': 'Labels x-axis.'},
    {'category': 'Matplotlib', 'question': 'What is plt.ylabel?', 'options': ['Title', 'Sets y-axis label', 'Legend', 'X-label'], 'correct': 1, 'explanation': 'Labels y-axis.'},
    {'category': 'Matplotlib', 'question': 'What is plt.title?', 'options': ['Label', 'Sets plot title', 'Legend', 'Annotation'], 'correct': 1, 'explanation': 'Adds title to plot.'},
    {'category': 'Matplotlib', 'question': 'What is plt.legend?', 'options': ['Title', 'Adds legend', 'Labels', 'Grid'], 'correct': 1, 'explanation': 'Displays legend.'},
    {'category': 'Matplotlib', 'question': 'What is plt.savefig?', 'options': ['Shows plot', 'Saves plot to file', 'Creates plot', 'Deletes'], 'correct': 1, 'explanation': 'Exports plot to image file.'},
    {'category': 'Matplotlib', 'question': 'What is plt.show?', 'options': ['Saves', 'Displays plot', 'Creates', 'Hides'], 'correct': 1, 'explanation': 'Renders plot to screen.'},
    {'category': 'Matplotlib', 'question': 'What is plt.bar?', 'options': ['Line', 'Bar chart', 'Scatter', 'Histogram'], 'correct': 1, 'explanation': 'Creates bar charts.'},
    {'category': 'Matplotlib', 'question': 'What is plt.barh?', 'options': ['Vertical bars', 'Horizontal bar chart', 'Scatter', 'Line'], 'correct': 1, 'explanation': 'Horizontal bar chart.'},
    {'category': 'Matplotlib', 'question': 'What is plt.pie?', 'options': ['Bar', 'Pie chart', 'Line', 'Scatter'], 'correct': 1, 'explanation': 'Creates pie charts.'},
    {'category': 'Matplotlib', 'question': 'What is plt.boxplot?', 'options': ['Scatter', 'Box-and-whisker plot', 'Line', 'Histogram'], 'correct': 1, 'explanation': 'Shows distribution via quartiles.'},
    {'category': 'Matplotlib', 'question': 'What is plt.imshow?', 'options': ['Line plot', 'Displays image data', 'Scatter', 'Bar'], 'correct': 1, 'explanation': 'Shows 2D arrays as images.'},
    {'category': 'Matplotlib', 'question': 'What is plt.contour?', 'options': ['Bar', 'Contour plot', 'Scatter', 'Line'], 'correct': 1, 'explanation': 'Creates contour lines.'},
    {'category': 'Matplotlib', 'question': 'What is plt.contourf?', 'options': ['Line contour', 'Filled contour plot', 'Scatter', 'Bar'], 'correct': 1, 'explanation': 'Filled contour regions.'},
    {'category': 'Matplotlib', 'question': 'What is plt.grid?', 'options': ['Removes grid', 'Adds grid lines', 'No effect', 'Hides axes'], 'correct': 1, 'explanation': 'Shows/hides grid.'},
    {'category': 'Matplotlib', 'question': 'What is plt.xlim?', 'options': ['Y-axis limits', 'Sets x-axis limits', 'Title', 'Legend'], 'correct': 1, 'explanation': 'Controls x-axis range.'},
    {'category': 'Matplotlib', 'question': 'What is plt.ylim?', 'options': ['X-axis limits', 'Sets y-axis limits', 'Title', 'Legend'], 'correct': 1, 'explanation': 'Controls y-axis range.'},
    {'category': 'Matplotlib', 'question': 'What is plt.xticks?', 'options': ['Y-ticks', 'Sets x-axis ticks', 'Title', 'Grid'], 'correct': 1, 'explanation': 'Customizes x-axis tick marks.'},
    {'category': 'Matplotlib', 'question': 'What is plt.yticks?', 'options': ['X-ticks', 'Sets y-axis ticks', 'Title', 'Grid'], 'correct': 1, 'explanation': 'Customizes y-axis tick marks.'},
    {'category': 'Matplotlib', 'question': 'What is plt.tight_layout?', 'options': ['Loose layout', 'Adjusts spacing automatically', 'No adjustment', 'Fixed spacing'], 'correct': 1, 'explanation': 'Prevents overlapping elements.'},
    {'category': 'Matplotlib', 'question': 'What is figsize parameter?', 'options': ['Data size', 'Figure dimensions in inches', 'Font size', 'Marker size'], 'correct': 1, 'explanation': 'Sets figure width and height.'},
    
    # Seaborn (25 questions)
    {'category': 'Seaborn', 'question': 'What is Seaborn?', 'options': ['Database', 'Statistical visualization on Matplotlib', 'ML framework', 'Web framework'], 'correct': 1, 'explanation': 'High-level interface for statistical graphics.'},
    {'category': 'Seaborn', 'question': 'What is sns.heatmap?', 'options': ['Scatter', 'Color-coded matrix', 'Line', 'Bar'], 'correct': 1, 'explanation': 'Visualizes matrix with colors.'},
    {'category': 'Seaborn', 'question': 'What is sns.pairplot?', 'options': ['Single plot', 'Pairwise relationships', 'Line', 'Heatmap'], 'correct': 1, 'explanation': 'Grid of scatter plots.'},
    {'category': 'Seaborn', 'question': 'What is sns.boxplot?', 'options': ['Scatter', 'Box-and-whisker plot', 'Line', 'Histogram'], 'correct': 1, 'explanation': 'Shows distribution quartiles.'},
    {'category': 'Seaborn', 'question': 'What is sns.violinplot?', 'options': ['Box', 'Box plot with KDE', 'Bar', 'Scatter'], 'correct': 1, 'explanation': 'Combines box plot and density.'},
    {'category': 'Seaborn', 'question': 'What is sns.distplot?', 'options': ['Scatter', 'Histogram with KDE', 'Box', 'Heatmap'], 'correct': 1, 'explanation': 'Shows distribution with curve.'},
    {'category': 'Seaborn', 'question': 'What is sns.countplot?', 'options': ['Histogram', 'Bar chart of counts', 'Line', 'Scatter'], 'correct': 1, 'explanation': 'Counts categorical observations.'},
    {'category': 'Seaborn', 'question': 'What is sns.barplot?', 'options': ['Histogram', 'Bar plot with error bars', 'Line', 'Scatter'], 'correct': 1, 'explanation': 'Shows estimates with confidence.'},
    {'category': 'Seaborn', 'question': 'What is sns.scatterplot?', 'options': ['Line', 'Scatter plot with relationships', 'Bar', 'Box'], 'correct': 1, 'explanation': 'Enhanced scatter visualization.'},
    {'category': 'Seaborn', 'question': 'What is sns.lineplot?', 'options': ['Scatter', 'Line plot with confidence intervals', 'Bar', 'Box'], 'correct': 1, 'explanation': 'Time series with uncertainty.'},
    {'category': 'Seaborn', 'question': 'What is sns.regplot?', 'options': ['No regression', 'Scatter with regression line', 'Bar', 'Box'], 'correct': 1, 'explanation': 'Adds linear regression fit.'},
    {'category': 'Seaborn', 'question': 'What is sns.lmplot?', 'options': ['Simple plot', 'Regression with facets', 'Bar', 'Box'], 'correct': 1, 'explanation': 'Regression across subplots.'},
    {'category': 'Seaborn', 'question': 'What is sns.jointplot?', 'options': ['Single plot', 'Bivariate with marginals', 'Line', 'Bar'], 'correct': 1, 'explanation': 'Shows joint and marginal distributions.'},
    {'category': 'Seaborn', 'question': 'What is sns.swarmplot?', 'options': ['Box', 'Categorical scatter avoiding overlap', 'Line', 'Bar'], 'correct': 1, 'explanation': 'Non-overlapping point plot.'},
    {'category': 'Seaborn', 'question': 'What is sns.stripplot?', 'options': ['Box', 'Categorical scatter with jitter', 'Line', 'Bar'], 'correct': 1, 'explanation': 'Jittered categorical points.'},
    {'category': 'Seaborn', 'question': 'What is sns.catplot?', 'options': ['Continuous only', 'Categorical plot interface', 'Line', 'Heatmap'], 'correct': 1, 'explanation': 'Flexible categorical plotting.'},
    {'category': 'Seaborn', 'question': 'What is sns.FacetGrid?', 'options': ['Single plot', 'Multi-plot grid', 'Line', 'Bar'], 'correct': 1, 'explanation': 'Creates subplot grid.'},
    {'category': 'Seaborn', 'question': 'What is sns.PairGrid?', 'options': ['Single plot', 'Customizable pairplot grid', 'Line', 'Bar'], 'correct': 1, 'explanation': 'More flexible than pairplot.'},
    {'category': 'Seaborn', 'question': 'What is sns.clustermap?', 'options': ['Regular heatmap', 'Heatmap with hierarchical clustering', 'Bar', 'Line'], 'correct': 1, 'explanation': 'Clusters rows and columns.'},
    {'category': 'Seaborn', 'question': 'What is sns.set_style?', 'options': ['No effect', 'Sets plot aesthetic style', 'Data style', 'Color only'], 'correct': 1, 'explanation': 'Chooses darkgrid, whitegrid, etc.'},
    {'category': 'Seaborn', 'question': 'What is sns.set_palette?', 'options': ['No effect', 'Sets color palette', 'Style', 'Theme'], 'correct': 1, 'explanation': 'Defines color scheme.'},
    {'category': 'Seaborn', 'question': 'What is sns.despine?', 'options': ['Adds spines', 'Removes plot borders', 'No effect', 'Adds borders'], 'correct': 1, 'explanation': 'Cleans up plot edges.'},
    {'category': 'Seaborn', 'question': 'What is hue parameter?', 'options': ['Size', 'Color by category', 'Shape', 'Alpha'], 'correct': 1, 'explanation': 'Colors points by variable.'},
    {'category': 'Seaborn', 'question': 'What is size parameter?', 'options': ['Color', 'Size by variable', 'Shape', 'Alpha'], 'correct': 1, 'explanation': 'Scales markers by values.'},
    {'category': 'Seaborn', 'question': 'What is style parameter?', 'options': ['Color', 'Marker style by category', 'Size', 'Alpha'], 'correct': 1, 'explanation': 'Different markers per group.'},
    
    # TensorFlow/Keras (40 questions)
    {'category': 'TensorFlow', 'question': 'What is TensorFlow?', 'options': ['Plotting', 'Deep learning framework', 'Database', 'Web framework'], 'correct': 1, 'explanation': 'Google\'s DL framework.'},
    {'category': 'TensorFlow', 'question': 'What is Keras?', 'options': ['Separate framework', 'High-level TensorFlow API', 'Database', 'Plotting'], 'correct': 1, 'explanation': 'Easy neural network building.'},
    {'category': 'TensorFlow', 'question': 'What is Sequential model?', 'options': ['Parallel', 'Linear stack of layers', 'Branched', 'Ensemble'], 'correct': 1, 'explanation': 'Simple layer-by-layer model.'},
    {'category': 'TensorFlow', 'question': 'What is Functional API?', 'options': ['Sequential only', 'Flexible for complex architectures', 'Simple only', 'No flexibility'], 'correct': 1, 'explanation': 'For complex models with branches.'},
    {'category': 'TensorFlow', 'question': 'What is model.compile?', 'options': ['Trains', 'Configures optimizer, loss, metrics', 'Predicts', 'Saves'], 'correct': 1, 'explanation': 'Sets up training configuration.'},
    {'category': 'TensorFlow', 'question': 'What is model.fit?', 'options': ['Compiles', 'Trains model', 'Predicts', 'Evaluates'], 'correct': 1, 'explanation': 'Trains on data for epochs.'},
    {'category': 'TensorFlow', 'question': 'What is model.predict?', 'options': ['Trains', 'Generates predictions', 'Compiles', 'Evaluates'], 'correct': 1, 'explanation': 'Makes predictions on new data.'},
    {'category': 'TensorFlow', 'question': 'What is model.evaluate?', 'options': ['Trains', 'Computes loss and metrics', 'Predicts', 'Compiles'], 'correct': 1, 'explanation': 'Tests model on data.'},
    {'category': 'TensorFlow', 'question': 'What is Dense layer?', 'options': ['Convolutional', 'Fully connected', 'Pooling', 'Dropout'], 'correct': 1, 'explanation': 'Every input to every output.'},
    {'category': 'TensorFlow', 'question': 'What is Conv2D?', 'options': ['Fully connected', '2D convolutional for images', 'Pooling', 'Dropout'], 'correct': 1, 'explanation': 'Applies convolutional filters.'},
    {'category': 'TensorFlow', 'question': 'What is MaxPooling2D?', 'options': ['Convolution', 'Downsampling using max', 'Activation', 'Dropout'], 'correct': 1, 'explanation': 'Reduces spatial dimensions.'},
    {'category': 'TensorFlow', 'question': 'What is Dropout layer?', 'options': ['Activation', 'Randomly drops neurons', 'Pooling', 'Convolution'], 'correct': 1, 'explanation': 'Regularization technique.'},
    {'category': 'TensorFlow', 'question': 'What is EarlyStopping?', 'options': ['Stops immediately', 'Stops when metric stops improving', 'Never stops', 'Saves'], 'correct': 1, 'explanation': 'Callback to prevent overfitting.'},
    {'category': 'TensorFlow', 'question': 'What is ModelCheckpoint?', 'options': ['Deletes', 'Saves model during training', 'Loads', 'Stops'], 'correct': 1, 'explanation': 'Saves best model weights.'},
    {'category': 'TensorFlow', 'question': 'What is ImageDataGenerator?', 'options': ['Generates images', 'Augments and loads images', 'Deletes', 'Classifies'], 'correct': 1, 'explanation': 'Real-time data augmentation.'},
    {'category': 'TensorFlow', 'question': 'What is Flatten layer?', 'options': ['No change', 'Converts multi-dim to 1D', 'Pools', 'Convolution'], 'correct': 1, 'explanation': 'Flattens for dense layers.'},
    {'category': 'TensorFlow', 'question': 'What is BatchNormalization?', 'options': ['Data normalization', 'Normalizes layer activations', 'Dropout', 'Pooling'], 'correct': 1, 'explanation': 'Stabilizes training.'},
    {'category': 'TensorFlow', 'question': 'What is LSTM layer?', 'options': ['CNN', 'Long Short-Term Memory', 'Dense', 'Dropout'], 'correct': 1, 'explanation': 'For sequence data.'},
    {'category': 'TensorFlow', 'question': 'What is GRU layer?', 'options': ['LSTM', 'Gated Recurrent Unit', 'CNN', 'Dense'], 'correct': 1, 'explanation': 'Simpler than LSTM.'},
    {'category': 'TensorFlow', 'question': 'What is Embedding layer?', 'options': ['Dense', 'Maps integers to dense vectors', 'Convolution', 'Pooling'], 'correct': 1, 'explanation': 'For categorical/text data.'},
    {'category': 'TensorFlow', 'question': 'What is GlobalAveragePooling2D?', 'options': ['Max pooling', 'Averages each feature map', 'Convolution', 'Dense'], 'correct': 1, 'explanation': 'Reduces to 1 value per channel.'},
    {'category': 'TensorFlow', 'question': 'What is GlobalMaxPooling2D?', 'options': ['Average pooling', 'Max of each feature map', 'Convolution', 'Dense'], 'correct': 1, 'explanation': 'Takes max per channel.'},
    {'category': 'TensorFlow', 'question': 'What is Concatenate layer?', 'options': ['Splits', 'Joins layers', 'Pools', 'Convolution'], 'correct': 1, 'explanation': 'Merges multiple inputs.'},
    {'category': 'TensorFlow', 'question': 'What is Add layer?', 'options': ['Concatenate', 'Element-wise addition', 'Multiply', 'Subtract'], 'correct': 1, 'explanation': 'Adds layer outputs.'},
    {'category': 'TensorFlow', 'question': 'What is Input layer?', 'options': ['Output', 'Defines input shape', 'Hidden', 'Dense'], 'correct': 1, 'explanation': 'Specifies input dimensions.'},
    {'category': 'TensorFlow', 'question': 'What is Model class?', 'options': ['Sequential only', 'Functional API model', 'No class', 'Dataset'], 'correct': 1, 'explanation': 'For complex architectures.'},
    {'category': 'TensorFlow', 'question': 'What is model.summary?', 'options': ['Training summary', 'Prints model architecture', 'Loss values', 'Predictions'], 'correct': 1, 'explanation': 'Shows layers and parameters.'},
    {'category': 'TensorFlow', 'question': 'What is model.save?', 'options': ['Loads model', 'Saves entire model', 'Deletes', 'Compiles'], 'correct': 1, 'explanation': 'Saves architecture and weights.'},
    {'category': 'TensorFlow', 'question': 'What is load_model?', 'options': ['Saves', 'Loads saved model', 'Trains', 'Compiles'], 'correct': 1, 'explanation': 'Restores model from file.'},
    {'category': 'TensorFlow', 'question': 'What is callbacks parameter?', 'options': ['No effect', 'List of callback functions', 'Single callback', 'No callbacks'], 'correct': 1, 'explanation': 'Functions called during training.'},
    {'category': 'TensorFlow', 'question': 'What is validation_split?', 'options': ['No split', 'Fraction of data for validation', 'Test split', 'No validation'], 'correct': 1, 'explanation': 'Splits training data for validation.'},
    {'category': 'TensorFlow', 'question': 'What is validation_data?', 'options': ['Training data', 'Separate validation dataset', 'Test data', 'No validation'], 'correct': 1, 'explanation': 'Explicit validation set.'},
    {'category': 'TensorFlow', 'question': 'What is verbose parameter?', 'options': ['Silent', 'Controls output verbosity', 'No effect', 'Always verbose'], 'correct': 1, 'explanation': '0=silent, 1=progress bar, 2=one line.'},
    {'category': 'TensorFlow', 'question': 'What is shuffle parameter?', 'options': ['No shuffle', 'Whether to shuffle training data', 'Always shuffle', 'Sort data'], 'correct': 1, 'explanation': 'Shuffles samples before each epoch.'},
    {'category': 'TensorFlow', 'question': 'What is class_weight?', 'options': ['Layer weight', 'Weight for imbalanced classes', 'No weight', 'Sample weight'], 'correct': 1, 'explanation': 'Balances class importance.'},
    {'category': 'TensorFlow', 'question': 'What is sample_weight?', 'options': ['Class weight', 'Weight per sample', 'Layer weight', 'No weight'], 'correct': 1, 'explanation': 'Individual sample importance.'},
    {'category': 'TensorFlow', 'question': 'What is initial_epoch?', 'options': ['Always 0', 'Resume training from epoch', 'Final epoch', 'No effect'], 'correct': 1, 'explanation': 'For resuming training.'},
    {'category': 'TensorFlow', 'question': 'What is steps_per_epoch?', 'options': ['Auto', 'Number of batches per epoch', 'Epochs', 'Batch size'], 'correct': 1, 'explanation': 'For generators.'},
    {'category': 'TensorFlow', 'question': 'What is validation_steps?', 'options': ['Auto', 'Validation batches per epoch', 'Train steps', 'No validation'], 'correct': 1, 'explanation': 'For validation generators.'},
    {'category': 'TensorFlow', 'question': 'What is use_multiprocessing?', 'options': ['Single thread', 'Enable multiprocessing for generators', 'No effect', 'Always single'], 'correct': 1, 'explanation': 'Speeds up data loading.'},
    
    # Feature Engineering (30 questions)
    {'category': 'Feature Engineering', 'question': 'What is feature scaling?', 'options': ['Selection', 'Transform to similar scale', 'Creation', 'Removal'], 'correct': 1, 'explanation': 'Ensures equal feature contribution.'},
    {'category': 'Feature Engineering', 'question': 'What is feature selection?', 'options': ['Creating', 'Choosing relevant features', 'Scaling', 'Encoding'], 'correct': 1, 'explanation': 'Identifies most informative features.'},
    {'category': 'Feature Engineering', 'question': 'What is feature extraction?', 'options': ['Selecting', 'Creating new features from existing', 'Removing', 'Scaling'], 'correct': 1, 'explanation': 'Derives new features.'},
    {'category': 'Feature Engineering', 'question': 'What is one-hot encoding?', 'options': ['Label encoding', 'Binary columns for categories', 'Normalization', 'Scaling'], 'correct': 1, 'explanation': 'Creates dummy variables.'},
    {'category': 'Feature Engineering', 'question': 'What is label encoding?', 'options': ['One-hot', 'Converts categories to integers', 'Normalization', 'Scaling'], 'correct': 1, 'explanation': 'Assigns integers to categories.'},
    {'category': 'Feature Engineering', 'question': 'What is ordinal encoding?', 'options': ['Nominal', 'Encoding with order', 'No order', 'Random'], 'correct': 1, 'explanation': 'Preserves category order.'},
    {'category': 'Feature Engineering', 'question': 'What is target encoding?', 'options': ['One-hot', 'Encode by target statistics', 'Label', 'Frequency'], 'correct': 1, 'explanation': 'Uses target mean per category.'},
    {'category': 'Feature Engineering', 'question': 'What is frequency encoding?', 'options': ['One-hot', 'Encode by occurrence frequency', 'Target', 'Label'], 'correct': 1, 'explanation': 'Replaces with frequency count.'},
    {'category': 'Feature Engineering', 'question': 'What is binning?', 'options': ['No binning', 'Group continuous into discrete', 'Scaling', 'Encoding'], 'correct': 1, 'explanation': 'Discretizes continuous variables.'},
    {'category': 'Feature Engineering', 'question': 'What is log transformation?', 'options': ['Linear', 'Applies logarithm to reduce skew', 'No transform', 'Exponential'], 'correct': 1, 'explanation': 'Handles skewed distributions.'},
    {'category': 'Feature Engineering', 'question': 'What is Box-Cox transformation?', 'options': ['Simple log', 'Power transformation for normality', 'No transform', 'Linear'], 'correct': 1, 'explanation': 'Makes data more Gaussian.'},
    {'category': 'Feature Engineering', 'question': 'What is Yeo-Johnson?', 'options': ['Box-Cox', 'Box-Cox for positive and negative', 'No transform', 'Log only'], 'correct': 1, 'explanation': 'Handles zero and negative values.'},
    {'category': 'Feature Engineering', 'question': 'What is interaction feature?', 'options': ['Single feature', 'Product or ratio of features', 'Sum', 'Difference only'], 'correct': 1, 'explanation': 'Captures combined effects.'},
    {'category': 'Feature Engineering', 'question': 'What is polynomial feature?', 'options': ['Linear', 'Powers and interactions', 'No transformation', 'Logarithmic'], 'correct': 1, 'explanation': 'Creates x², x³, x*y, etc.'},
    {'category': 'Feature Engineering', 'question': 'What is feature hashing?', 'options': ['No hashing', 'Maps features to fixed-size vector', 'One-hot', 'Label encoding'], 'correct': 1, 'explanation': 'Dimensionality reduction via hashing.'},
    {'category': 'Feature Engineering', 'question': 'What is text vectorization?', 'options': ['No vectors', 'Converts text to numerical', 'Image processing', 'Audio'], 'correct': 1, 'explanation': 'Transforms text to numbers.'},
    {'category': 'Feature Engineering', 'question': 'What is TF-IDF?', 'options': ['Word count', 'Term Frequency-Inverse Document Frequency', 'One-hot', 'Embedding'], 'correct': 1, 'explanation': 'Weights words by importance.'},
    {'category': 'Feature Engineering', 'question': 'What is CountVectorizer?', 'options': ['TF-IDF', 'Bag-of-words with counts', 'Embeddings', 'No vectorization'], 'correct': 1, 'explanation': 'Creates word count matrix.'},
    {'category': 'Feature Engineering', 'question': 'What is word embedding?', 'options': ['Count vector', 'Dense vector representation', 'One-hot', 'TF-IDF'], 'correct': 1, 'explanation': 'Learns semantic word vectors.'},
    {'category': 'Feature Engineering', 'question': 'What is missing value imputation?', 'options': ['Remove missing', 'Fill missing with estimates', 'Ignore', 'No action'], 'correct': 1, 'explanation': 'Replaces missing values.'},
    {'category': 'Feature Engineering', 'question': 'What is mean imputation?', 'options': ['Median', 'Fill with mean value', 'Mode', 'Random'], 'correct': 1, 'explanation': 'Replaces with column mean.'},
    {'category': 'Feature Engineering', 'question': 'What is KNN imputation?', 'options': ['Mean', 'Uses K-nearest neighbors', 'Median', 'Mode'], 'correct': 1, 'explanation': 'Imputes based on similar samples.'},
    {'category': 'Feature Engineering', 'question': 'What is forward fill?', 'options': ['Backward', 'Propagates last valid observation', 'Mean', 'No fill'], 'correct': 1, 'explanation': 'For time series.'},
    {'category': 'Feature Engineering', 'question': 'What is outlier detection?', 'options': ['Creates outliers', 'Identifies unusual values', 'Removes all', 'No detection'], 'correct': 1, 'explanation': 'Finds anomalous data points.'},
    {'category': 'Feature Engineering', 'question': 'What is IQR method?', 'options': ['Standard deviation', 'Uses quartiles for outliers', 'Mean-based', 'No method'], 'correct': 1, 'explanation': 'Values outside Q1-1.5*IQR to Q3+1.5*IQR.'},    
    # Pandas (50 questions)
    {'category': 'Pandas', 'question': 'What is Pandas?', 'options': ['NumPy extension', 'Data manipulation with DataFrames', 'Plotting', 'Database'], 'correct': 1, 'explanation': 'Library for structured data manipulation.'},
    {'category': 'Pandas', 'question': 'What is DataFrame?', 'options': ['Array', '2D labeled table', 'List', 'Dictionary'], 'correct': 1, 'explanation': 'Table with labeled rows and columns.'},
    {'category': 'Pandas', 'question': 'What is Series?', 'options': ['DataFrame', '1D labeled array', 'Matrix', 'Tuple'], 'correct': 1, 'explanation': 'One column of DataFrame.'},
    {'category': 'Pandas', 'question': 'What does iloc do?', 'options': ['Label indexing', 'Integer-position indexing', 'Conditional', 'Sorting'], 'correct': 1, 'explanation': 'Selects by integer position.'},
    {'category': 'Pandas', 'question': 'What does loc do?', 'options': ['Position indexing', 'Label-based indexing', 'Random', 'Deletion'], 'correct': 1, 'explanation': 'Selects by labels.'},
    {'category': 'Pandas', 'question': 'What is apply?', 'options': ['Filters', 'Applies function to rows/columns', 'Sorts', 'Merges'], 'correct': 1, 'explanation': 'Apply function along axis.'},
    {'category': 'Pandas', 'question': 'What does groupby do?', 'options': ['Sorts groups', 'Groups for aggregation', 'Removes groups', 'Merges'], 'correct': 1, 'explanation': 'Split-apply-combine operations.'},
    {'category': 'Pandas', 'question': 'What is merge?', 'options': ['Splits', 'Joins DataFrames like SQL', 'Removes', 'Sorts'], 'correct': 1, 'explanation': 'Database-style joins.'},
    {'category': 'Pandas', 'question': 'What is concat?', 'options': ['Joins strings', 'Concatenates DataFrames', 'Splits', 'Filters'], 'correct': 1, 'explanation': 'Stacks DataFrames vertically/horizontally.'},
    {'category': 'Pandas', 'question': 'What does fillna do?', 'options': ['Creates NaN', 'Fills missing values', 'Removes NaN', 'Counts NaN'], 'correct': 1, 'explanation': 'Replaces NaN with values.'},
    {'category': 'Pandas', 'question': 'What is dropna?', 'options': ['Fills NaN', 'Removes rows/columns with NaN', 'Counts NaN', 'Sorts NaN'], 'correct': 1, 'explanation': 'Drops missing values.'},
    {'category': 'Pandas', 'question': 'What does pivot_table do?', 'options': ['Removes pivot', 'Creates spreadsheet-style pivot', 'Transposes', 'Sorts'], 'correct': 1, 'explanation': 'Creates pivot table with aggregation.'},
    {'category': 'Pandas', 'question': 'What is value_counts?', 'options': ['Counts values', 'Returns frequency of unique values', 'Sums', 'Averages'], 'correct': 1, 'explanation': 'Counts occurrences of each value.'},
    {'category': 'Pandas', 'question': 'What does isnull return?', 'options': ['Missing values', 'Boolean mask of missing', 'Count', 'Removes'], 'correct': 1, 'explanation': 'Returns True where NaN.'},
    {'category': 'Pandas', 'question': 'What is describe?', 'options': ['Schema', 'Statistical summary', 'Data types', 'Column names'], 'correct': 1, 'explanation': 'Provides count, mean, std, quartiles.'},
    {'category': 'Pandas', 'question': 'What does astype do?', 'options': ['Adds type', 'Converts data type', 'Removes type', 'Checks type'], 'correct': 1, 'explanation': 'Casts to specified dtype.'},
    {'category': 'Pandas', 'question': 'What is reset_index?', 'options': ['Removes index', 'Resets to default integers', 'Sorts', 'Creates'], 'correct': 1, 'explanation': 'Replaces index with 0,1,2...'},
    {'category': 'Pandas', 'question': 'What does sort_values do?', 'options': ['Sorts index', 'Sorts by column values', 'Removes', 'Filters'], 'correct': 1, 'explanation': 'Sorts rows by columns.'},
    {'category': 'Pandas', 'question': 'What is read_csv?', 'options': ['Writes CSV', 'Reads CSV into DataFrame', 'Deletes CSV', 'Converts'], 'correct': 1, 'explanation': 'Loads CSV file.'},
    {'category': 'Pandas', 'question': 'What is categorical dtype?', 'options': ['Continuous', 'Efficient storage for repeated strings', 'Numerical', 'Boolean'], 'correct': 1, 'explanation': 'Saves memory for repeated categories.'},
    {'category': 'Pandas', 'question': 'What is at vs loc?', 'options': ['Same', 'at for single value, faster', 'No difference', 'loc faster'], 'correct': 1, 'explanation': 'at optimized for scalar access.'},
    {'category': 'Pandas', 'question': 'What is iat vs iloc?', 'options': ['Same', 'iat for single value, faster', 'No difference', 'iloc faster'], 'correct': 1, 'explanation': 'iat optimized for scalar access.'},
    {'category': 'Pandas', 'question': 'What does query do?', 'options': ['SQL query', 'Filter rows using string expression', 'Merges', 'Sorts'], 'correct': 1, 'explanation': 'Filter using string expressions.'},
    {'category': 'Pandas', 'question': 'What is melt?', 'options': ['Widens', 'Unpivots DataFrame', 'Pivots', 'No change'], 'correct': 1, 'explanation': 'Transforms wide to long format.'},
    {'category': 'Pandas', 'question': 'What is stack?', 'options': ['Unstacks', 'Pivots columns to rows', 'No change', 'Merges'], 'correct': 1, 'explanation': 'Compresses columns to multi-index rows.'},
    {'category': 'Pandas', 'question': 'What is unstack?', 'options': ['Stacks', 'Pivots rows to columns', 'No change', 'Merges'], 'correct': 1, 'explanation': 'Expands multi-index to columns.'},
    {'category': 'Pandas', 'question': 'What does explode do?', 'options': ['Combines', 'Transforms list-like to rows', 'No change', 'Merges'], 'correct': 1, 'explanation': 'Expands list-like elements to separate rows.'},
    {'category': 'Pandas', 'question': 'What is assign?', 'options': ['Removes columns', 'Creates new columns', 'No change', 'Renames'], 'correct': 1, 'explanation': 'Adds new columns to DataFrame.'},
    {'category': 'Pandas', 'question': 'What is pipe?', 'options': ['No piping', 'Chains function calls', 'Single function', 'No chaining'], 'correct': 1, 'explanation': 'Enables method chaining.'},
    {'category': 'Pandas', 'question': 'What is map vs apply?', 'options': ['Same', 'map for Series, apply for DataFrame', 'No difference', 'apply for Series'], 'correct': 1, 'explanation': 'map is Series method, apply more general.'},
    {'category': 'Pandas', 'question': 'What is applymap?', 'options': ['Row-wise', 'Element-wise on DataFrame', 'Column-wise', 'No mapping'], 'correct': 1, 'explanation': 'Applies function to every element.'},
    {'category': 'Pandas', 'question': 'What is transform?', 'options': ['Same as apply', 'Returns same-shaped result', 'Different shape', 'No transform'], 'correct': 1, 'explanation': 'Like apply but preserves shape.'},
    {'category': 'Pandas', 'question': 'What is agg vs aggregate?', 'options': ['Different', 'Same function, aggregate is alias', 'No relation', 'agg better'], 'correct': 1, 'explanation': 'Aggregate is longer alias for agg.'},
    {'category': 'Pandas', 'question': 'What does nunique do?', 'options': ['All values', 'Count of unique values', 'Unique values', 'Duplicates'], 'correct': 1, 'explanation': 'Returns number of unique values.'},
    {'category': 'Pandas', 'question': 'What is duplicated?', 'options': ['Removes duplicates', 'Boolean mask of duplicates', 'Counts', 'Unique'], 'correct': 1, 'explanation': 'Marks duplicate rows as True.'},
    {'category': 'Pandas', 'question': 'What is drop_duplicates?', 'options': ['Keeps duplicates', 'Removes duplicate rows', 'Marks duplicates', 'Counts'], 'correct': 1, 'explanation': 'Drops duplicate rows.'},
    {'category': 'Pandas', 'question': 'What is cut?', 'options': ['Removes data', 'Bins continuous into discrete', 'No binning', 'Filters'], 'correct': 1, 'explanation': 'Discretizes continuous values.'},
    {'category': 'Pandas', 'question': 'What is qcut?', 'options': ['Equal-width', 'Quantile-based binning', 'No binning', 'Random'], 'correct': 1, 'explanation': 'Bins into equal-sized groups.'},
    {'category': 'Pandas', 'question': 'What is get_dummies?', 'options': ['Removes dummies', 'One-hot encoding', 'Label encoding', 'No encoding'], 'correct': 1, 'explanation': 'Creates dummy/indicator variables.'},
    {'category': 'Pandas', 'question': 'What is replace?', 'options': ['Fills NaN', 'Replaces values', 'Removes values', 'No change'], 'correct': 1, 'explanation': 'Replaces specified values.'},
    {'category': 'Pandas', 'question': 'What is rename?', 'options': ['Removes columns', 'Renames columns/index', 'No change', 'Adds columns'], 'correct': 1, 'explanation': 'Changes column or index labels.'},
    {'category': 'Pandas', 'question': 'What is set_index?', 'options': ['Resets index', 'Sets column as index', 'Removes index', 'No change'], 'correct': 1, 'explanation': 'Makes column the index.'},
    {'category': 'Pandas', 'question': 'What is join?', 'options': ['Merges', 'Joins on index', 'Concatenates', 'Splits'], 'correct': 1, 'explanation': 'Convenient index-based join.'},
    {'category': 'Pandas', 'question': 'Inner vs outer join?', 'options': ['Same', 'Inner: intersection, outer: union', 'No difference', 'Opposite'], 'correct': 1, 'explanation': 'Inner keeps matching, outer keeps all.'},
    {'category': 'Pandas', 'question': 'What is left vs right join?', 'options': ['Same', 'Left keeps left DF, right keeps right', 'No difference', 'Random'], 'correct': 1, 'explanation': 'Preserves rows from specified side.'},
    {'category': 'Pandas', 'question': 'What is memory_usage?', 'options': ['No info', 'Returns memory consumption', 'Data types', 'Shape'], 'correct': 1, 'explanation': 'Shows memory used by DataFrame.'},
    {'category': 'Pandas', 'question': 'What is info?', 'options': ['Statistics', 'Summary of DataFrame structure', 'Values', 'No info'], 'correct': 1, 'explanation': 'Shows dtypes, non-null counts, memory.'},
    {'category': 'Pandas', 'question': 'What is sample?', 'options': ['All rows', 'Random sample of rows', 'First rows', 'Last rows'], 'correct': 1, 'explanation': 'Returns random sample.'},
    {'category': 'Pandas', 'question': 'What is nlargest?', 'options': ['Smallest', 'N largest values', 'All values', 'Random'], 'correct': 1, 'explanation': 'Returns top N values.'},
    {'category': 'Pandas', 'question': 'What is nsmallest?', 'options': ['Largest', 'N smallest values', 'All values', 'Random'], 'correct': 1, 'explanation': 'Returns bottom N values.'},
    
    # Scikit-learn (60 questions)
    {'category': 'Scikit-learn', 'question': 'What is scikit-learn?', 'options': ['Deep learning', 'ML library for classical algorithms', 'Database', 'Plotting'], 'correct': 1, 'explanation': 'Comprehensive ML library.'},
    {'category': 'Scikit-learn', 'question': 'What is train_test_split?', 'options': ['Trains model', 'Splits data into train/test', 'Tests model', 'Validates'], 'correct': 1, 'explanation': 'Randomly splits dataset.'},
    {'category': 'Scikit-learn', 'question': 'What is cross_val_score?', 'options': ['Single validation', 'Performs k-fold CV', 'Training score', 'Test score'], 'correct': 1, 'explanation': 'Evaluates via cross-validation.'},
    {'category': 'Scikit-learn', 'question': 'What is StandardScaler?', 'options': ['Normalizes to [0,1]', 'Standardizes to mean=0, std=1', 'Removes outliers', 'Encodes'], 'correct': 1, 'explanation': 'Z-score normalization.'},
    {'category': 'Scikit-learn', 'question': 'What is MinMaxScaler?', 'options': ['Standardizes', 'Scales to [0,1]', 'Removes min/max', 'Clips'], 'correct': 1, 'explanation': 'Scales to specified range.'},
    {'category': 'Scikit-learn', 'question': 'What is LabelEncoder?', 'options': ['One-hot', 'Encodes labels to integers', 'Decodes', 'Removes'], 'correct': 1, 'explanation': 'Converts categories to integers.'},
    {'category': 'Scikit-learn', 'question': 'What is OneHotEncoder?', 'options': ['Label encoding', 'Creates binary columns', 'Removes', 'Combines'], 'correct': 1, 'explanation': 'Creates dummy variables.'},
    {'category': 'Scikit-learn', 'question': 'What is Pipeline?', 'options': ['Data flow', 'Chains preprocessing and model', 'Parallel', 'Storage'], 'correct': 1, 'explanation': 'Sequences transformers and estimator.'},
    {'category': 'Scikit-learn', 'question': 'What is GridSearchCV?', 'options': ['Random search', 'Exhaustive hyperparameter search', 'Manual', 'Single parameter'], 'correct': 1, 'explanation': 'Tries all hyperparameter combinations.'},
    {'category': 'Scikit-learn', 'question': 'What is RandomizedSearchCV?', 'options': ['Grid search', 'Random hyperparameter sampling', 'Exhaustive', 'No search'], 'correct': 1, 'explanation': 'Samples random combinations.'},
    {'category': 'Scikit-learn', 'question': 'What is SimpleImputer?', 'options': ['Removes missing', 'Fills missing with strategy', 'Detects', 'Creates'], 'correct': 1, 'explanation': 'Imputes missing values.'},
    {'category': 'Scikit-learn', 'question': 'What does fit do?', 'options': ['Predicts', 'Learns from training data', 'Transforms', 'Evaluates'], 'correct': 1, 'explanation': 'Trains the model.'},
    {'category': 'Scikit-learn', 'question': 'What does predict do?', 'options': ['Trains', 'Makes predictions', 'Transforms', 'Fits'], 'correct': 1, 'explanation': 'Applies trained model.'},
    {'category': 'Scikit-learn', 'question': 'What does transform do?', 'options': ['Trains', 'Applies learned transformation', 'Predicts', 'Fits'], 'correct': 1, 'explanation': 'Transforms using fitted transformer.'},
    {'category': 'Scikit-learn', 'question': 'What is fit_transform?', 'options': ['Only fits', 'Fits and transforms together', 'Only transforms', 'Predicts'], 'correct': 1, 'explanation': 'Combined fit and transform.'},
    {'category': 'Scikit-learn', 'question': 'What is confusion_matrix?', 'options': ['Loss matrix', 'Matrix of TP, FP, TN, FN', 'Correlation', 'Distance'], 'correct': 1, 'explanation': 'Classification error matrix.'},
    {'category': 'Scikit-learn', 'question': 'What is classification_report?', 'options': ['Training report', 'Precision, recall, F1 per class', 'Loss', 'Predictions'], 'correct': 1, 'explanation': 'Detailed per-class metrics.'},
    {'category': 'Scikit-learn', 'question': 'What is roc_auc_score?', 'options': ['Accuracy', 'Area under ROC curve', 'Loss', 'Precision'], 'correct': 1, 'explanation': 'Measures classification performance.'},
    {'category': 'Scikit-learn', 'question': 'What is mean_squared_error?', 'options': ['Classification', 'Average squared errors', 'Accuracy', 'R²'], 'correct': 1, 'explanation': 'Regression error metric.'},
    {'category': 'Scikit-learn', 'question': 'What is r2_score?', 'options': ['Loss', 'Coefficient of determination', 'MSE', 'Accuracy'], 'correct': 1, 'explanation': 'Proportion of variance explained.'},
    {'category': 'Scikit-learn', 'question': 'What is ColumnTransformer?', 'options': ['Transforms rows', 'Different transforms per column', 'Single transform', 'Removes'], 'correct': 1, 'explanation': 'Applies transformers to specific columns.'},
    {'category': 'Scikit-learn', 'question': 'What is make_pipeline?', 'options': ['Creates data', 'Constructs pipeline without naming', 'Removes', 'Tests'], 'correct': 1, 'explanation': 'Convenient pipeline creation.'},
    {'category': 'Scikit-learn', 'question': 'What is StratifiedKFold?', 'options': ['Random split', 'K-fold preserving class distribution', 'Single split', 'No stratification'], 'correct': 1, 'explanation': 'Maintains class proportions in folds.'},
    {'category': 'Scikit-learn', 'question': 'What is VotingClassifier?', 'options': ['Single model', 'Ensemble combining classifiers', 'Data voting', 'Feature voting'], 'correct': 1, 'explanation': 'Combines multiple models via voting.'},
    {'category': 'Scikit-learn', 'question': 'What is feature_importances_?', 'options': ['Feature values', 'Importance scores from trees', 'Feature names', 'Feature count'], 'correct': 1, 'explanation': 'Tree-based importance scores.'},
    {'category': 'Scikit-learn', 'question': 'What is RobustScaler?', 'options': ['Standard scaler', 'Scales using median and IQR', 'Min-max', 'No scaling'], 'correct': 1, 'explanation': 'Robust to outliers.'},
    {'category': 'Scikit-learn', 'question': 'What is MaxAbsScaler?', 'options': ['Standard scaler', 'Scales by maximum absolute value', 'Min-max', 'Robust'], 'correct': 1, 'explanation': 'Scales to [-1, 1] by max abs.'},
    {'category': 'Scikit-learn', 'question': 'What is Normalizer?', 'options': ['StandardScaler', 'Scales samples to unit norm', 'Min-max', 'Robust'], 'correct': 1, 'explanation': 'L1 or L2 normalization per sample.'},
    {'category': 'Scikit-learn', 'question': 'What is QuantileTransformer?', 'options': ['Standard', 'Transforms to uniform or normal distribution', 'Min-max', 'Robust'], 'correct': 1, 'explanation': 'Non-linear transformation using quantiles.'},
    {'category': 'Scikit-learn', 'question': 'What is PowerTransformer?', 'options': ['Standard', 'Makes data more Gaussian', 'Min-max', 'Robust'], 'correct': 1, 'explanation': 'Yeo-Johnson or Box-Cox transformation.'},
    {'category': 'Scikit-learn', 'question': 'What is PolynomialFeatures?', 'options': ['Removes features', 'Creates polynomial combinations', 'Selects', 'Scales'], 'correct': 1, 'explanation': 'Generates polynomial and interaction features.'},
    {'category': 'Scikit-learn', 'question': 'What is SelectKBest?', 'options': ['Selects all', 'Selects K best features', 'Random selection', 'Removes features'], 'correct': 1, 'explanation': 'Univariate feature selection.'},
    {'category': 'Scikit-learn', 'question': 'What is RFE?', 'options': ['Forward selection', 'Recursive Feature Elimination', 'No elimination', 'Random'], 'correct': 1, 'explanation': 'Recursively removes least important features.'},
    {'category': 'Scikit-learn', 'question': 'What is RFECV?', 'options': ['RFE', 'RFE with cross-validation', 'No CV', 'Single split'], 'correct': 1, 'explanation': 'RFE with automatic feature selection.'},
    {'category': 'Scikit-learn', 'question': 'What is VarianceThreshold?', 'options': ['Removes high variance', 'Removes low variance features', 'No filtering', 'All features'], 'correct': 1, 'explanation': 'Removes features with low variance.'},
    {'category': 'Scikit-learn', 'question': 'What is mutual_info_classif?', 'options': ['Correlation', 'Mutual information for classification', 'Variance', 'Mean'], 'correct': 1, 'explanation': 'Measures dependency between features and target.'},
    {'category': 'Scikit-learn', 'question': 'What is f_classif?', 'options': ['Regression', 'ANOVA F-value for classification', 'Correlation', 'Variance'], 'correct': 1, 'explanation': 'Univariate linear regression test.'},
    {'category': 'Scikit-learn', 'question': 'What is chi2?', 'options': ['F-test', 'Chi-squared test for categorical', 'ANOVA', 'T-test'], 'correct': 1, 'explanation': 'Tests independence of categorical features.'},
    {'category': 'Scikit-learn', 'question': 'What is KFold?', 'options': ['Single split', 'K-fold cross-validation splitter', 'No folds', 'Random'], 'correct': 1, 'explanation': 'Splits data into K folds.'},
    {'category': 'Scikit-learn', 'question': 'What is LeaveOneOut?', 'options': ['Leave many out', 'Leave one sample out per fold', 'No leaving', 'Random'], 'correct': 1, 'explanation': 'K=n cross-validation.'},
    {'category': 'Scikit-learn', 'question': 'What is ShuffleSplit?', 'options': ['No shuffle', 'Random permutation CV', 'Ordered', 'Stratified'], 'correct': 1, 'explanation': 'Random train/test splits.'},
    {'category': 'Scikit-learn', 'question': 'What is TimeSeriesSplit?', 'options': ['Random split', 'Forward chaining for time series', 'No order', 'Shuffle'], 'correct': 1, 'explanation': 'Respects temporal order.'},
    {'category': 'Scikit-learn', 'question': 'What is BaggingClassifier?', 'options': ['Boosting', 'Bootstrap aggregating ensemble', 'Single model', 'No bagging'], 'correct': 1, 'explanation': 'Fits models on random subsets.'},
    {'category': 'Scikit-learn', 'question': 'What is AdaBoostClassifier?', 'options': ['Bagging', 'Adaptive boosting', 'Random Forest', 'No boosting'], 'correct': 1, 'explanation': 'Sequential boosting with sample weighting.'},
    {'category': 'Scikit-learn', 'question': 'What is GradientBoostingClassifier?', 'options': ['AdaBoost', 'Gradient boosting', 'Bagging', 'Random Forest'], 'correct': 1, 'explanation': 'Boosting with gradient descent.'},
    {'category': 'Scikit-learn', 'question': 'What is StackingClassifier?', 'options': ['Single model', 'Meta-model on base predictions', 'Bagging', 'Boosting'], 'correct': 1, 'explanation': 'Stacks models with meta-learner.'},
    {'category': 'Scikit-learn', 'question': 'What is CalibratedClassifierCV?', 'options': ['No calibration', 'Calibrates probabilities', 'Standard classifier', 'No CV'], 'correct': 1, 'explanation': 'Improves probability estimates.'},
    {'category': 'Scikit-learn', 'question': 'What is DummyClassifier?', 'options': ['Real classifier', 'Baseline using simple rules', 'Complex model', 'Neural network'], 'correct': 1, 'explanation': 'Simple baseline for comparison.'},
    {'category': 'Scikit-learn', 'question': 'What is MultiOutputClassifier?', 'options': ['Single output', 'Wraps for multi-output', 'No wrapping', 'Single target'], 'correct': 1, 'explanation': 'Extends single to multi-output.'},
    {'category': 'Scikit-learn', 'question': 'What is MultiOutputRegressor?', 'options': ['Single output', 'Wraps for multi-target regression', 'Classification', 'Single target'], 'correct': 1, 'explanation': 'Extends single to multi-output regression.'},
    {'category': 'Scikit-learn', 'question': 'What is make_classification?', 'options': ['Real data', 'Generates synthetic classification data', 'No generation', 'Loads data'], 'correct': 1, 'explanation': 'Creates synthetic datasets.'},
    {'category': 'Scikit-learn', 'question': 'What is make_regression?', 'options': ['Classification', 'Generates synthetic regression data', 'No generation', 'Real data'], 'correct': 1, 'explanation': 'Creates regression datasets.'},
    {'category': 'Scikit-learn', 'question': 'What is make_blobs?', 'options': ['Real data', 'Generates clustered data', 'No generation', 'Classification'], 'correct': 1, 'explanation': 'Creates isotropic Gaussian blobs.'},
    {'category': 'Scikit-learn', 'question': 'What is learning_curve?', 'options': ['ROC curve', 'Training/validation scores vs sample size', 'No curve', 'Confusion'], 'correct': 1, 'explanation': 'Diagnoses bias-variance tradeoff.'},
    {'category': 'Scikit-learn', 'question': 'What is validation_curve?', 'options': ['Learning curve', 'Scores vs hyperparameter values', 'No validation', 'ROC'], 'correct': 1, 'explanation': 'Visualizes hyperparameter impact.'},
    {'category': 'Scikit-learn', 'question': 'What is permutation_importance?', 'options': ['Gini importance', 'Model-agnostic feature importance', 'No importance', 'Tree-only'], 'correct': 1, 'explanation': 'Shuffles features to measure impact.'},
    {'category': 'Scikit-learn', 'question': 'What is partial_dependence?', 'options': ['Full dependence', 'Marginal effect of features', 'No dependence', 'Correlation'], 'correct': 1, 'explanation': 'Shows feature effect on predictions.'},
    {'category': 'Scikit-learn', 'question': 'What is plot_confusion_matrix?', 'options': ['No plot', 'Visualizes confusion matrix', 'Plot data', 'ROC plot'], 'correct': 1, 'explanation': 'Creates confusion matrix heatmap.'},
    {'category': 'Scikit-learn', 'question': 'What is plot_roc_curve?', 'options': ['Confusion matrix', 'Plots ROC curve', 'No plot', 'Learning curve'], 'correct': 1, 'explanation': 'Visualizes ROC curve.'},
    
    # Matplotlib (25 questions)
    {'category': 'Matplotlib', 'question': 'What is Matplotlib?', 'options': ['ML library', 'Plotting and visualization', 'Data processing', 'Database'], 'correct': 1, 'explanation': 'Creates visualizations in Python.'},
    {'category': 'Matplotlib', 'question': 'What is plt.plot?',import streamlit as st
import random
import json

# Page configuration
st.set_page_config(
    page_title="ML Algorithms Quiz Master",
    page_icon="🧠",
    layout="wide"
)

# Custom CSS
st.markdown("""
<style>
    .stButton>button {
        width: 100%;
        border-radius: 10px;
        height: 60px;
        font-size: 16px;
        font-weight: bold;
    }
    .correct {
        background-color: #10b981;
        color: white;
    }
    .incorrect {
        background-color: #ef4444;
        color: white;
    }
    .category-badge {
        background-color: #0891b2;
        color: white;
        padding: 8px 16px;
        border-radius: 20px;
        display: inline-block;
        margin-bottom: 16px;
    }
</style>
""", unsafe_allow_html=True)

# Initialize session state
if 'quiz_started' not in st.session_state:
    st.session_state.quiz_started = False
if 'current_question' not in st.session_state:
    st.session_state.current_question = 0
if 'score' not in st.session_state:
    st.session_state.score = 0
if 'selected_answer' not in st.session_state:
    st.session_state.selected_answer = None
if 'show_result' not in st.session_state:
    st.session_state.show_result = False
if 'question_pool' not in st.session_state:
    st.session_state.question_pool = []
if 'stats' not in st.session_state:
    st.session_state.stats = {'total': 0, 'correct': 0, 'wrong': 0}
if 'selected_category' not in st.session_state:
    st.session_state.selected_category = 'all'

# Questions database (1000+ questions)
questions = [
    # Linear Regression (50 questions)
    {'category': 'Linear Regression', 'question': 'What is the main assumption of linear regression?', 'options': ['Non-linear relationship', 'Linear relationship between features and target', 'Categorical target', 'No relationship needed'], 'correct': 1, 'explanation': 'Linear regression assumes a linear relationship between independent and dependent variables.'},
    {'category': 'Linear Regression', 'question': 'Which loss function does linear regression minimize?', 'options': ['Cross-entropy', 'Mean Squared Error (MSE)', 'Hinge Loss', 'Log Loss'], 'correct': 1, 'explanation': 'Linear regression uses MSE to measure the average squared difference between predictions and actual values.'},
    {'category': 'Linear Regression', 'question': 'What does the coefficient in linear regression represent?', 'options': ['Correlation', 'Change in target per unit change in feature', 'P-value', 'Standard deviation'], 'correct': 1, 'explanation': 'Each coefficient shows how much the target changes when that feature increases by one unit.'},
    {'category': 'Linear Regression', 'question': 'What is multicollinearity?', 'options': ['Multiple targets', 'High correlation between features', 'Multiple models', 'Non-linear patterns'], 'correct': 1, 'explanation': 'Multicollinearity occurs when features are highly correlated, making coefficients unstable.'},
    {'category': 'Linear Regression', 'question': 'What is the purpose of the intercept term?', 'options': ['Scaling', 'Baseline prediction when all features are zero', 'Regularization', 'Feature selection'], 'correct': 1, 'explanation': 'The intercept represents the predicted value when all features equal zero.'},
    {'category': 'Linear Regression', 'question': 'Which method is used to find optimal coefficients?', 'options': ['Grid search', 'Ordinary Least Squares (OLS)', 'K-fold', 'Bootstrapping'], 'correct': 1, 'explanation': 'OLS minimizes the sum of squared residuals to find the best-fit line.'},
    {'category': 'Linear Regression', 'question': 'What is heteroscedasticity?', 'options': ['Constant variance', 'Non-constant variance of residuals', 'Linear relationship', 'Normal distribution'], 'correct': 1, 'explanation': 'Heteroscedasticity means residuals have non-constant variance across predictions.'},
    {'category': 'Linear Regression', 'question': 'What does R² measure?', 'options': ['Error rate', 'Proportion of variance explained', 'Correlation', 'Bias'], 'correct': 1, 'explanation': 'R² indicates how much variance in the target is explained by the model (0 to 1).'},
    {'category': 'Linear Regression', 'question': 'What is the gradient in gradient descent for linear regression?', 'options': ['Learning rate', 'Derivative of loss function', 'Step size', 'Regularization term'], 'correct': 1, 'explanation': 'The gradient is the derivative showing the direction of steepest increase in loss.'},
    {'category': 'Linear Regression', 'question': 'What happens if features are not normalized?', 'options': ['Better accuracy', 'Features with larger scales dominate', 'Faster training', 'No impact'], 'correct': 1, 'explanation': 'Without normalization, large-scale features disproportionately influence the model.'},
    {'category': 'Linear Regression', 'question': 'What is polynomial regression?', 'options': ['Multiple targets', 'Linear regression with polynomial features', 'Tree-based method', 'Clustering algorithm'], 'correct': 1, 'explanation': 'Polynomial regression creates polynomial terms (x², x³) to capture non-linear patterns.'},
    {'category': 'Linear Regression', 'question': 'What is the difference between simple and multiple linear regression?', 'options': ['Loss function', 'Number of features', 'Target type', 'Algorithm complexity'], 'correct': 1, 'explanation': 'Simple uses one feature, multiple uses two or more features.'},
    {'category': 'Linear Regression', 'question': 'What does residual mean?', 'options': ['Predicted value', 'Difference between actual and predicted', 'Feature value', 'Coefficient'], 'correct': 1, 'explanation': 'Residual = Actual - Predicted, showing prediction error for each sample.'},
    {'category': 'Linear Regression', 'question': 'Why check residual plots?', 'options': ['Calculate accuracy', 'Validate model assumptions', 'Feature selection', 'Hyperparameter tuning'], 'correct': 1, 'explanation': 'Residual plots help verify linearity, homoscedasticity, and normality assumptions.'},
    {'category': 'Linear Regression', 'question': 'What is the normal equation?', 'options': ['Iterative method', 'Closed-form solution for coefficients', 'Loss function', 'Activation function'], 'correct': 1, 'explanation': 'Normal equation: θ = (X^T X)^(-1) X^T y, directly solves for optimal coefficients.'},
    {'category': 'Linear Regression', 'question': 'When does linear regression perform poorly?', 'options': ['Large datasets', 'Non-linear relationships', 'Normalized features', 'Low multicollinearity'], 'correct': 1, 'explanation': 'Linear regression struggles with non-linear patterns as it only models linear relationships.'},
    {'category': 'Linear Regression', 'question': 'What is adjusted R²?', 'options': ['Unadjusted version', 'R² penalized for number of features', 'Correlation coefficient', 'Error metric'], 'correct': 1, 'explanation': 'Adjusted R² accounts for model complexity, preventing overfitting from too many features.'},
    {'category': 'Linear Regression', 'question': 'What assumption does normality of residuals check?', 'options': ['Features are normal', 'Errors follow normal distribution', 'Target is normal', 'Coefficients are normal'], 'correct': 1, 'explanation': 'Residuals should be normally distributed for reliable statistical inference.'},
    {'category': 'Linear Regression', 'question': 'What is the VIF (Variance Inflation Factor)?', 'options': ['Loss metric', 'Measure of multicollinearity', 'Regularization term', 'Learning rate'], 'correct': 1, 'explanation': 'VIF quantifies how much variance is inflated due to multicollinearity. VIF > 10 indicates issues.'},
    {'category': 'Linear Regression', 'question': 'Can linear regression handle categorical features directly?', 'options': ['Yes, always', 'No, need encoding', 'Only binary', 'Only ordinal'], 'correct': 1, 'explanation': 'Categorical features must be encoded (one-hot, label encoding) before use.'},
    {'category': 'Linear Regression', 'question': 'What is extrapolation risk?', 'options': ['Overfitting', 'Unreliable predictions outside training range', 'High variance', 'Bias'], 'correct': 1, 'explanation': 'Linear regression may give unreliable predictions for values outside the training data range.'},
    {'category': 'Linear Regression', 'question': 'What does a negative R² indicate?', 'options': ['Perfect fit', 'Model worse than mean baseline', 'Good model', 'Overfitting'], 'correct': 1, 'explanation': 'Negative R² means the model performs worse than simply predicting the mean.'},
    {'category': 'Linear Regression', 'question': 'What is the p-value of a coefficient?', 'options': ['Coefficient value', 'Probability coefficient is zero', 'Error rate', 'Correlation'], 'correct': 1, 'explanation': 'P-value tests if the coefficient is significantly different from zero (typically p < 0.05).'},
    {'category': 'Linear Regression', 'question': 'Why use standardization over normalization?', 'options': ['Faster', 'Preserves outlier information', 'Always better', 'Required by law'], 'correct': 1, 'explanation': 'Standardization (z-score) maintains outlier distances while centering data at mean=0, std=1.'},
    {'category': 'Linear Regression', 'question': 'What is the curse of dimensionality for linear regression?', 'options': ['Too few features', 'More features than samples causes overfitting', 'Non-linearity', 'Collinearity'], 'correct': 1, 'explanation': 'When features >> samples, the model overfits and generalizes poorly.'},
    {'category': 'Linear Regression', 'question': 'What is a Q-Q plot used for?', 'options': ['Feature importance', 'Check normality of residuals', 'Find outliers', 'Tune hyperparameters'], 'correct': 1, 'explanation': 'Q-Q plots compare residual distribution to normal distribution to check normality assumption.'},
    {'category': 'Linear Regression', 'question': 'Can linear regression output probabilities?', 'options': ['Yes, directly', 'No, outputs continuous values', 'Only with softmax', 'Only binary'], 'correct': 1, 'explanation': 'Linear regression predicts continuous values, not probabilities. Use logistic regression for probabilities.'},
    {'category': 'Linear Regression', 'question': 'What is Cook\'s distance?', 'options': ['Loss metric', 'Influence of individual points on model', 'Regularization', 'Distance metric'], 'correct': 1, 'explanation': 'Cook\'s distance measures how much removing a point would change the regression coefficients.'},
    {'category': 'Linear Regression', 'question': 'What is weighted linear regression?', 'options': ['All samples equal', 'Different weights for different samples', 'Multiple targets', 'Ensemble method'], 'correct': 1, 'explanation': 'Weighted regression assigns different importance to samples, useful for heteroscedastic data.'},
    {'category': 'Linear Regression', 'question': 'What is the difference between correlation and regression?', 'options': ['Same thing', 'Correlation measures relationship, regression predicts', 'Correlation predicts', 'No difference'], 'correct': 1, 'explanation': 'Correlation measures strength of relationship; regression models the relationship for prediction.'},
    {'category': 'Linear Regression', 'question': 'What is homoscedasticity?', 'options': ['Varying variance', 'Constant variance of residuals', 'Non-linear pattern', 'Outliers'], 'correct': 1, 'explanation': 'Homoscedasticity means residuals have constant variance across all prediction levels.'},
    {'category': 'Linear Regression', 'question': 'What is the Durbin-Watson test?', 'options': ['Multicollinearity test', 'Test for autocorrelation in residuals', 'Normality test', 'Heteroscedasticity test'], 'correct': 1, 'explanation': 'Durbin-Watson tests for autocorrelation in residuals, important for time series.'},
    {'category': 'Linear Regression', 'question': 'What is studentized residual?', 'options': ['Raw residual', 'Standardized residual accounting for leverage', 'Predicted value', 'Coefficient'], 'correct': 1, 'explanation': 'Studentized residuals help identify outliers by accounting for each point\'s leverage.'},
    {'category': 'Linear Regression', 'question': 'What is leverage in regression?', 'options': ['Residual size', 'Potential of point to influence model', 'Coefficient value', 'R² value'], 'correct': 1, 'explanation': 'Leverage measures how far a point\'s features are from the mean, indicating influence potential.'},
    {'category': 'Linear Regression', 'question': 'What is an influential point?', 'options': ['Any outlier', 'Point with high leverage and large residual', 'Predicted value', 'Mean value'], 'correct': 1, 'explanation': 'Influential points have both unusual features (high leverage) and large residuals.'},
    {'category': 'Linear Regression', 'question': 'What is the Gauss-Markov theorem?', 'options': ['Loss function', 'OLS is BLUE under assumptions', 'Optimization method', 'Test statistic'], 'correct': 1, 'explanation': 'Under assumptions, OLS estimators are Best Linear Unbiased Estimators (BLUE).'},
    {'category': 'Linear Regression', 'question': 'What is RMSE?', 'options': ['R² variant', 'Root Mean Squared Error', 'Regularization', 'Residual'], 'correct': 1, 'explanation': 'RMSE = sqrt(MSE), gives error in original target units, easier to interpret.'},
    {'category': 'Linear Regression', 'question': 'What is MAE?', 'options': ['MSE variant', 'Mean Absolute Error', 'Maximum error', 'Median error'], 'correct': 1, 'explanation': 'MAE = mean(|actual - predicted|), less sensitive to outliers than MSE.'},
    {'category': 'Linear Regression', 'question': 'When to use MAE vs MSE?', 'options': ['Always MAE', 'MSE for outlier sensitivity, MAE for robustness', 'Always MSE', 'No difference'], 'correct': 1, 'explanation': 'MSE penalizes large errors more; MAE treats all errors equally, more robust to outliers.'},
    {'category': 'Linear Regression', 'question': 'What is the F-statistic in regression?', 'options': ['Coefficient test', 'Overall model significance test', 'Residual test', 'Outlier test'], 'correct': 1, 'explanation': 'F-test checks if at least one coefficient is non-zero, testing overall model usefulness.'},
    {'category': 'Linear Regression', 'question': 'What is the t-statistic for coefficients?', 'options': ['Model fit', 'Individual coefficient significance', 'Residual test', 'Variance test'], 'correct': 1, 'explanation': 'T-test checks if individual coefficient is significantly different from zero.'},
    {'category': 'Linear Regression', 'question': 'What is confidence interval for prediction?', 'options': ['Point estimate', 'Range for mean prediction at X', 'Single value', 'Residual range'], 'correct': 1, 'explanation': 'Confidence interval estimates range for the mean response at given X values.'},
    {'category': 'Linear Regression', 'question': 'What is prediction interval?', 'options': ['Confidence interval', 'Range for individual prediction', 'Mean range', 'Coefficient range'], 'correct': 1, 'explanation': 'Prediction interval is wider, accounting for both model and individual observation uncertainty.'},
    {'category': 'Linear Regression', 'question': 'What causes overfitting in linear regression?', 'options': ['Too few features', 'Too many features relative to samples', 'High R²', 'Low MSE'], 'correct': 1, 'explanation': 'Too many features allows model to fit noise, reducing generalization.'},
    {'category': 'Linear Regression', 'question': 'What is underfitting in linear regression?', 'options': ['Perfect fit', 'Model too simple to capture patterns', 'Overfitting', 'High variance'], 'correct': 1, 'explanation': 'Underfitting occurs when model is too simple, missing important patterns.'},
    {'category': 'Linear Regression', 'question': 'What is the bias-variance tradeoff?', 'options': ['No tradeoff', 'Balance between model simplicity and flexibility', 'Always minimize both', 'Maximize both'], 'correct': 1, 'explanation': 'Simple models have high bias, complex models have high variance. Need balance.'},
    {'category': 'Linear Regression', 'question': 'What is interaction term?', 'options': ['Sum of features', 'Product of features capturing combined effect', 'Difference', 'Average'], 'correct': 1, 'explanation': 'Interaction terms (x1*x2) model how features jointly affect target.'},
    {'category': 'Linear Regression', 'question': 'When to include interaction terms?', 'options': ['Always', 'When features\' effect depends on each other', 'Never', 'Randomly'], 'correct': 1, 'explanation': 'Use interactions when one feature\'s effect on target varies with another feature.'},
    {'category': 'Linear Regression', 'question': 'What is dummy variable trap?', 'options': ['Using dummies', 'Perfect multicollinearity from all dummy variables', 'Missing dummies', 'Wrong encoding'], 'correct': 1, 'explanation': 'Including all dummy variables creates multicollinearity; drop one reference category.'},
    {'category': 'Linear Regression', 'question': 'What is gradient descent convergence criterion?', 'options': ['Fixed iterations', 'Change in loss below threshold', 'Random stop', 'Maximum iterations only'], 'correct': 1, 'explanation': 'Stop when loss change between iterations falls below threshold or max iterations reached.'},
    
    # Logistic Regression (50 questions)
    {'category': 'Logistic Regression', 'question': 'What type of problem does logistic regression solve?', 'options': ['Regression', 'Classification', 'Clustering', 'Dimensionality reduction'], 'correct': 1, 'explanation': 'Despite its name, logistic regression is used for binary and multi-class classification.'},
    {'category': 'Logistic Regression', 'question': 'What function does logistic regression use?', 'options': ['Linear', 'Sigmoid/Logistic function', 'ReLU', 'Tanh'], 'correct': 1, 'explanation': 'The sigmoid function σ(z) = 1/(1+e^(-z)) maps predictions to [0,1] probability range.'},
    {'category': 'Logistic Regression', 'question': 'What loss function does logistic regression use?', 'options': ['MSE', 'Binary cross-entropy/Log loss', 'Hinge loss', 'Huber loss'], 'correct': 1, 'explanation': 'Log loss penalizes confident wrong predictions more than MSE, ideal for classification.'},
    {'category': 'Logistic Regression', 'question': 'What is the decision boundary in logistic regression?', 'options': ['Non-linear curve', 'Linear hyperplane separating classes', 'Circle', 'Random'], 'correct': 1, 'explanation': 'The decision boundary is a linear surface where P(y=1) = 0.5.'},
    {'category': 'Logistic Regression', 'question': 'What is the odds ratio?', 'options': ['Probability', 'P(event) / P(not event)', 'Accuracy', 'Loss'], 'correct': 1, 'explanation': 'Odds = P/(1-P). Logistic regression models log-odds as linear function.'},
    {'category': 'Logistic Regression', 'question': 'Can logistic regression handle multi-class classification?', 'options': ['No', 'Yes, using one-vs-rest or softmax', 'Only binary', 'Only with trees'], 'correct': 1, 'explanation': 'Multi-class uses one-vs-rest or multinomial/softmax approaches.'},
    {'category': 'Logistic Regression', 'question': 'What does coefficient represent in logistic regression?', 'options': ['Probability change', 'Change in log-odds per unit feature change', 'Accuracy', 'Loss'], 'correct': 1, 'explanation': 'Each coefficient shows how log-odds change when feature increases by one unit.'},
    {'category': 'Logistic Regression', 'question': 'What is L1 vs L2 regularization?', 'options': ['No difference', 'L1 does feature selection, L2 shrinks coefficients', 'L2 selects features', 'Same penalty'], 'correct': 1, 'explanation': 'L1 (Lasso) can zero out coefficients, L2 (Ridge) shrinks without zeroing.'},
    {'category': 'Logistic Regression', 'question': 'What metric is NOT suitable for imbalanced classification?', 'options': ['F1-score', 'Accuracy', 'Precision-Recall AUC', 'Matthews correlation'], 'correct': 1, 'explanation': 'Accuracy misleading with imbalanced classes.'},
    {'category': 'Logistic Regression', 'question': 'What is the default threshold for classification?', 'options': ['0.3', '0.5', '0.7', '0.9'], 'correct': 1, 'explanation': 'Default threshold is 0.5 but can be adjusted.'},
    {'category': 'Logistic Regression', 'question': 'What does AUC-ROC measure?', 'options': ['Accuracy', 'Model ability to discriminate between classes', 'Loss', 'Precision'], 'correct': 1, 'explanation': 'AUC-ROC measures how well model ranks positives higher than negatives.'},
    {'category': 'Logistic Regression', 'question': 'What is maximum likelihood estimation?', 'options': ['Loss function', 'Method to find parameters maximizing data likelihood', 'Regularization', 'Metric'], 'correct': 1, 'explanation': 'MLE finds parameters making observed data most probable.'},
    {'category': 'Logistic Regression', 'question': 'Why not use MSE for logistic regression?', 'options': ['Too slow', 'Non-convex loss with multiple local minima', 'Not differentiable', 'Too fast'], 'correct': 1, 'explanation': 'MSE with sigmoid creates non-convex optimization.'},
    {'category': 'Logistic Regression', 'question': 'What is the link function?', 'options': ['Sigmoid', 'Logit (log-odds)', 'Identity', 'Exponential'], 'correct': 1, 'explanation': 'Logit link connects linear predictors to probabilities.'},
    {'category': 'Logistic Regression', 'question': 'What is precision?', 'options': ['True positives / All actual positives', 'True positives / All predicted positives', 'True negatives / All negatives', 'Accuracy'], 'correct': 1, 'explanation': 'Precision = TP / (TP + FP), fraction of positive predictions correct.'},
    {'category': 'Logistic Regression', 'question': 'What is recall (sensitivity)?', 'options': ['True positives / All predicted positives', 'True positives / All actual positives', 'Specificity', 'Accuracy'], 'correct': 1, 'explanation': 'Recall = TP / (TP + FN), fraction of actual positives identified.'},
    {'category': 'Logistic Regression', 'question': 'What is F1-score?', 'options': ['Accuracy', 'Harmonic mean of precision and recall', 'Arithmetic mean', 'Geometric mean'], 'correct': 1, 'explanation': 'F1 = 2 * (precision * recall) / (precision + recall).'},
    {'category': 'Logistic Regression', 'question': 'What is class imbalance?', 'options': ['Equal classes', 'Unequal samples across classes', 'Too many features', 'Overfitting'], 'correct': 1, 'explanation': 'One class has significantly more samples than others.'},
    {'category': 'Logistic Regression', 'question': 'How to handle class imbalance?', 'options': ['Ignore it', 'Resampling, class weights, or SMOTE', 'Remove samples', 'Add features'], 'correct': 1, 'explanation': 'Use oversampling, undersampling, SMOTE, or class weights.'},
    {'category': 'Logistic Regression', 'question': 'What is SMOTE?', 'options': ['Regularization', 'Synthetic Minority Oversampling Technique', 'Loss function', 'Optimizer'], 'correct': 1, 'explanation': 'SMOTE generates synthetic samples for minority class.'},
    {'category': 'Logistic Regression', 'question': 'What is confusion matrix?', 'options': ['Loss matrix', 'Table of TP, FP, TN, FN', 'Feature importance', 'Correlation matrix'], 'correct': 1, 'explanation': 'Shows true vs predicted classifications.'},
    {'category': 'Logistic Regression', 'question': 'What is specificity?', 'options': ['Recall', 'True negatives / All actual negatives', 'Precision', 'Accuracy'], 'correct': 1, 'explanation': 'Specificity = TN / (TN + FP), fraction of negatives identified.'},
    {'category': 'Logistic Regression', 'question': 'What does ROC curve plot?', 'options': ['Precision vs Recall', 'True Positive Rate vs False Positive Rate', 'Accuracy vs Loss', 'F1 vs Threshold'], 'correct': 1, 'explanation': 'ROC plots TPR (sensitivity) against FPR at various thresholds.'},
    {'category': 'Logistic Regression', 'question': 'What is good AUC-ROC score?', 'options': ['0.5', '0.7-1.0', '0.0-0.3', '1.5'], 'correct': 1, 'explanation': 'AUC=0.5 is random, 0.7-0.8 acceptable, 0.8-0.9 good, >0.9 excellent.'},
    {'category': 'Logistic Regression', 'question': 'What is Precision-Recall curve useful for?', 'options': ['Balanced datasets', 'Imbalanced datasets', 'Regression', 'Clustering'], 'correct': 1, 'explanation': 'PR curve more informative for imbalanced datasets.'},
    {'category': 'Logistic Regression', 'question': 'What is elastic net regularization?', 'options': ['Only L1', 'Combination of L1 and L2', 'Only L2', 'No regularization'], 'correct': 1, 'explanation': 'Elastic net combines L1 and L2 penalties.'},
    {'category': 'Logistic Regression', 'question': 'Why normalize features?', 'options': ['Not needed', 'Equal contribution, faster convergence', 'Slower training', 'Decreases accuracy'], 'correct': 1, 'explanation': 'Prevents large-scale features from dominating.'},
    {'category': 'Logistic Regression', 'question': 'Can logistic regression handle non-linear boundaries?', 'options': ['Yes, naturally', 'No, unless polynomial features added', 'Always', 'Never'], 'correct': 1, 'explanation': 'Creates linear boundaries unless you engineer polynomial features.'},
    {'category': 'Logistic Regression', 'question': 'What is calibration in classification?', 'options': ['Accuracy', 'Aligning predicted probabilities with actual frequencies', 'Loss', 'Regularization'], 'correct': 1, 'explanation': 'Calibrated model has predicted probabilities matching observed frequencies.'},
    {'category': 'Logistic Regression', 'question': 'What is softmax function?', 'options': ['Binary activation', 'Multi-class generalization of sigmoid', 'Loss function', 'Optimizer'], 'correct': 1, 'explanation': 'Softmax converts logits to probabilities summing to 1.'},
    {'category': 'Logistic Regression', 'question': 'What is multinomial logistic regression?', 'options': ['Binary only', 'Extension for multiple classes', 'Ordinal only', 'Two classes'], 'correct': 1, 'explanation': 'Handles multiple classes simultaneously using softmax.'},
    {'category': 'Logistic Regression', 'question': 'What is ordinal logistic regression?', 'options': ['Nominal classes', 'For ordered categories', 'Binary only', 'Unordered'], 'correct': 1, 'explanation': 'Used when classes have natural ordering.'},
    {'category': 'Logistic Regression', 'question': 'What is Platt scaling?', 'options': ['Feature scaling', 'Calibrating probabilities via sigmoid', 'Regularization', 'Loss function'], 'correct': 1, 'explanation': 'Fits sigmoid to map scores to calibrated probabilities.'},
    {'category': 'Logistic Regression', 'question': 'What is isotonic regression for calibration?', 'options': ['Linear calibration', 'Non-parametric calibration', 'No calibration', 'Feature scaling'], 'correct': 1, 'explanation': 'Non-parametric method for probability calibration.'},
    {'category': 'Logistic Regression', 'question': 'What is log loss formula?', 'options': ['MSE', '-(y*log(p) + (1-y)*log(1-p))', 'MAE', 'Hinge'], 'correct': 1, 'explanation': 'Log loss penalizes wrong confident predictions heavily.'},
    {'category': 'Logistic Regression', 'question': 'What happens with perfect separation?', 'options': ['Good fit', 'Complete separation causes coefficient instability', 'Best model', 'No issues'], 'correct': 1, 'explanation': 'Perfect separation makes coefficients go to infinity.'},
    {'category': 'Logistic Regression', 'question': 'What is quasi-complete separation?', 'options': ['No separation', 'Partial perfect separation in feature space', 'Complete separation', 'No issues'], 'correct': 1, 'explanation': 'Some feature combinations perfectly separate classes.'},
    {'category': 'Logistic Regression', 'question': 'What is Matthew Correlation Coefficient?', 'options': ['Accuracy', 'Balanced metric for binary classification', 'Loss', 'Precision'], 'correct': 1, 'explanation': 'MCC considers all confusion matrix elements, good for imbalanced data.'},
    {'category': 'Logistic Regression', 'question': 'What is Cohen Kappa score?', 'options': ['Accuracy', 'Agreement accounting for chance', 'Loss', 'Recall'], 'correct': 1, 'explanation': 'Measures agreement beyond random chance.'},
    {'category': 'Logistic Regression', 'question': 'What is macro-average?', 'options': ['Weighted by class', 'Average metrics treating classes equally', 'Total count', 'Sample weighted'], 'correct': 1, 'explanation': 'Computes metric for each class then averages equally.'},
    {'category': 'Logistic Regression', 'question': 'What is micro-average?', 'options': ['Class-wise average', 'Global average counting all predictions', 'Weighted average', 'Median'], 'correct': 1, 'explanation': 'Aggregates TP, FP, FN globally then computes metric.'},
    {'category': 'Logistic Regression', 'question': 'What is weighted-average?', 'options': ['Equal weights', 'Average weighted by class support', 'Micro-average', 'Macro-average'], 'correct': 1, 'explanation': 'Weights metrics by number of samples in each class.'},
    {'category': 'Logistic Regression', 'question': 'What is one-vs-all strategy?', 'options': ['Pairwise', 'Train binary classifier per class vs rest', 'No strategy', 'One-vs-one'], 'correct': 1, 'explanation': 'Trains N classifiers for N classes, each vs all others.'},
    {'category': 'Logistic Regression', 'question': 'What is one-vs-one strategy?', 'options': ['One-vs-all', 'Train classifier for each class pair', 'Single classifier', 'No strategy'], 'correct': 1, 'explanation': 'Trains N(N-1)/2 classifiers for all pairs.'},
    {'category': 'Logistic Regression', 'question': 'When to use one-vs-one vs one-vs-all?', 'options': ['Always OvO', 'OvO for SVM, OvA for linear models', 'Always OvA', 'No difference'], 'correct': 1, 'explanation': 'OvO preferred for SVM, OvA for logistic regression and trees.'},
    {'category': 'Logistic Regression', 'question': 'What is balanced accuracy?', 'options': ['Standard accuracy', 'Average of sensitivity and specificity', 'Weighted accuracy', 'Total correct'], 'correct': 1, 'explanation': 'Useful for imbalanced data, averages per-class accuracy.'},
    {'category': 'Logistic Regression', 'question': 'What is Brier score?', 'options': ['Classification metric', 'Mean squared error of probabilities', 'Accuracy', 'F1'], 'correct': 1, 'explanation': 'Measures accuracy of probability predictions.'},
    {'category': 'Logistic Regression', 'question': 'What is cross-entropy loss?', 'options': ['MSE', 'Negative log likelihood', 'MAE', 'Hinge'], 'correct': 1, 'explanation': 'Measures difference between predicted and true distributions.'},
    {'category': 'Logistic Regression', 'question': 'What is Newton-Raphson method?', 'options': ['Gradient descent', 'Second-order optimization using Hessian', 'SGD', 'Adam'], 'correct': 1, 'explanation': 'Uses second derivatives for faster convergence in logistic regression.'},
    {'category': 'Logistic Regression', 'question': 'What is IRLS?', 'options': ['Random search', 'Iteratively Reweighted Least Squares', 'Grid search', 'Boosting'], 'correct': 1, 'explanation': 'Algorithm for fitting generalized linear models including logistic.'},
    
    # Decision Trees (50 questions)
    {'category': 'Decision Trees', 'question': 'What is a decision tree?', 'options': ['Linear model', 'Tree structure with if-then rules', 'Neural network', 'Clustering method'], 'correct': 1, 'explanation': 'Decision trees recursively split data based on feature values.'},
    {'category': 'Decision Trees', 'question': 'What is entropy in decision trees?', 'options': ['Loss', 'Measure of impurity/randomness', 'Accuracy', 'Depth'], 'correct': 1, 'explanation': 'Entropy measures disorder: 0 (pure) to 1 (maximum disorder).'},
    {'category': 'Decision Trees', 'question': 'What is Gini impurity?', 'options': ['Entropy', 'Probability of incorrect classification', 'Accuracy', 'Depth metric'], 'correct': 1, 'explanation': 'Gini measures impurity: 1 - Σ(pi²). Lower is purer.'},
    {'category': 'Decision Trees', 'question': 'What is information gain?', 'options': ['Loss reduction', 'Reduction in entropy after split', 'Accuracy increase', 'Depth'], 'correct': 1, 'explanation': 'Information gain = Parent entropy - Weighted child entropy.'},
    {'category': 'Decision Trees', 'question': 'Main advantage of decision trees?', 'options': ['Always accurate', 'Interpretable and handles non-linear', 'Fast training', 'No preprocessing'], 'correct': 1, 'explanation': 'Trees are easy to visualize and naturally handle non-linear patterns.'},
    {'category': 'Decision Trees', 'question': 'Main disadvantage of decision trees?', 'options': ['Hard to interpret', 'Prone to overfitting', 'Cannot handle categorical', 'Too simple'], 'correct': 1, 'explanation': 'Trees easily overfit by memorizing training data.'},
    {'category': 'Decision Trees', 'question': 'What is pruning?', 'options': ['Adding nodes', 'Removing nodes to reduce overfitting', 'Feature selection', 'Normalization'], 'correct': 1, 'explanation': 'Pruning removes branches with little predictive power.'},
    {'category': 'Decision Trees', 'question': 'What are pre-pruning techniques?', 'options': ['Prune after training', 'Stop growing early (max_depth, min_samples)', 'Remove features', 'Normalize'], 'correct': 1, 'explanation': 'Pre-pruning limits tree growth during training.'},
    {'category': 'Decision Trees', 'question': 'What is post-pruning?', 'options': ['Stop early', 'Grow full tree, then remove branches', 'Feature selection', 'Ensemble'], 'correct': 1, 'explanation': 'Post-pruning builds full tree then removes ineffective branches.'},
    {'category': 'Decision Trees', 'question': 'What is max_depth?', 'options': ['Number of features', 'Maximum tree levels', 'Number of samples', 'Number of trees'], 'correct': 1, 'explanation': 'max_depth limits how many splits can be made.'},
    {'category': 'Decision Trees', 'question': 'What is min_samples_split?', 'options': ['Max samples', 'Minimum samples needed to split node', 'Tree depth', 'Leaf size'], 'correct': 1, 'explanation': 'min_samples_split requires N samples before splitting.'},
    {'category': 'Decision Trees', 'question': 'What is min_samples_leaf?', 'options': ['Split criterion', 'Minimum samples required in leaf', 'Tree depth', 'Split count'], 'correct': 1, 'explanation': 'Ensures each leaf has at least N samples.'},
    {'category': 'Decision Trees', 'question': 'Can decision trees handle missing values?', 'options': ['No', 'Yes, with surrogate splits', 'Only with imputation', 'Never'], 'correct': 1, 'explanation': 'Some implementations learn optimal missing value direction.'},
    {'category': 'Decision Trees', 'question': 'Do decision trees need feature scaling?', 'options': ['Yes, always', 'No, invariant to scaling', 'Sometimes', 'Only for deep trees'], 'correct': 1, 'explanation': 'Trees use thresholds on individual features, scaling irrelevant.'},
    {'category': 'Decision Trees', 'question': 'What is a leaf node?', 'options': ['Root', 'Terminal node with prediction', 'Split node', 'Parent node'], 'correct': 1, 'explanation': 'Leaf nodes output final predictions.'},
    {'category': 'Decision Trees', 'question': 'What is the root node?', 'options': ['Leaf', 'Top node with first split', 'Last split', 'Any node'], 'correct': 1, 'explanation': 'Root node represents first split of all data.'},
    {'category': 'Decision Trees', 'question': 'What is CART algorithm?', 'options': ['Clustering', 'Classification and Regression Trees', 'Neural network', 'Ensemble'], 'correct': 1, 'explanation': 'CART builds binary trees using Gini for classification, MSE for regression.'},
    {'category': 'Decision Trees', 'question': 'What is ID3 algorithm?', 'options': ['Regression only', 'Iterative Dichotomiser 3 using information gain', 'Neural network', 'Clustering'], 'correct': 1, 'explanation': 'ID3 uses entropy and information gain, classification only.'},
    {'category': 'Decision Trees', 'question': 'What is C4.5 algorithm?', 'options': ['ID3 successor', 'Improved ID3 with gain ratio and pruning', 'Neural network', 'Regression only'], 'correct': 1, 'explanation': 'C4.5 improves ID3 with gain ratio and pruning.'},
    {'category': 'Decision Trees', 'question': 'What is feature importance in trees?', 'options': ['Correlation', 'Measure of feature contribution to splits', 'P-value', 'Coefficient'], 'correct': 1, 'explanation': 'Feature importance sums impurity reduction from that feature.'},
    {'category': 'Decision Trees', 'question': 'Can decision trees perform regression?', 'options': ['No', 'Yes, predict mean/median in leaves', 'Only classification', 'Only with transformation'], 'correct': 1, 'explanation': 'Regression trees predict by averaging target values in leaves.'},
    {'category': 'Decision Trees', 'question': 'Splitting criterion for regression trees?', 'options': ['Gini', 'Mean Squared Error (MSE)', 'Entropy', 'Cross-entropy'], 'correct': 1, 'explanation': 'Regression trees minimize MSE or MAE.'},
    {'category': 'Decision Trees', 'question': 'Are decision trees sensitive to data changes?', 'options': ['No, very stable', 'Yes, high variance', 'Only deep trees', 'Only shallow trees'], 'correct': 1, 'explanation': 'Small data changes create completely different structures.'},
    {'category': 'Decision Trees', 'question': 'Bias-variance tradeoff in trees?', 'options': ['No tradeoff', 'Shallow: high bias; deep: high variance', 'Always high bias', 'Always high variance'], 'correct': 1, 'explanation': 'Shallow trees underfit, deep trees overfit.'},
    {'category': 'Decision Trees', 'question': 'Can decision trees handle categorical features?', 'options': ['No', 'Yes, natively or with encoding', 'Only with one-hot', 'Never'], 'correct': 1, 'explanation': 'Some implementations handle categorical natively.'},
    {'category': 'Decision Trees', 'question': 'Time complexity of training?', 'options': ['O(n)', 'O(n*log(n)*d)', 'O(n²)', 'O(d²)'], 'correct': 1, 'explanation': 'Complexity O(n*log(n)*d) from sorting and splits.'},
    {'category': 'Decision Trees', 'question': 'What is cost complexity pruning?', 'options': ['Pre-pruning', 'Post-pruning using alpha parameter', 'No pruning', 'Feature selection'], 'correct': 1, 'explanation': 'Adds penalty alpha * |leaves| to error.'},
    {'category': 'Decision Trees', 'question': 'Can trees model linear relationships?', 'options': ['Yes, naturally', 'No, use step functions', 'Only with transformation', 'Better than linear'], 'correct': 1, 'explanation': 'Trees approximate with step functions, inefficient for linear.'},
    {'category': 'Decision Trees', 'question': 'What is a surrogate split?', 'options': ['Main split', 'Alternative split for missing values', 'Root split', 'Final split'], 'correct': 1, 'explanation': 'Uses alternative features for missing values.'},
    {'category': 'Decision Trees', 'question': 'What is gain ratio?', 'options': ['Information gain', 'Information gain normalized by split info', 'Gini', 'Entropy'], 'correct': 1, 'explanation': 'Gain ratio reduces bias toward high-cardinality features.'},
    {'category': 'Decision Trees', 'question': 'What is split information?', 'options': ['Information gain', 'Entropy of split distribution', 'Gini', 'Impurity'], 'correct': 1, 'explanation': 'Measures how data is distributed across splits.'},
    {'category': 'Decision Trees', 'question': 'What is binary split?', 'options': ['Multi-way', 'Split into exactly two branches', 'Three-way', 'No split'], 'correct': 1, 'explanation': 'CART uses binary splits for all features.'},
    {'category': 'Decision Trees', 'question': 'What is multi-way split?', 'options': ['Binary only', 'Split into multiple branches', 'Two branches', 'No split'], 'correct': 1, 'explanation': 'ID3/C4.5 can split into multiple branches for categorical.'},
    {'category': 'Decision Trees', 'question': 'What is oblique decision tree?', 'options': ['Axis-aligned', 'Uses linear combinations of features', 'Standard tree', 'Perpendicular splits'], 'correct': 1, 'explanation': 'Oblique trees split on linear combinations, not single features.'},
    {'category': 'Decision Trees', 'question': 'What is axis-aligned split?', 'options': ['Diagonal', 'Split parallel to feature axis', 'Oblique', 'Curved'], 'correct': 1, 'explanation': 'Standard trees split perpendicular to one feature axis.'},
    {'category': 'Decision Trees', 'question': 'What is reduced error pruning?', 'options': ['Pre-pruning', 'Remove node if no accuracy loss on validation', 'Cost complexity', 'No pruning'], 'correct': 1, 'explanation': 'Tests removing each node against validation set.'},
    {'category': 'Decision Trees', 'question': 'What is pessimistic error pruning?', 'options': ['Optimistic', 'Estimates error rate conservatively', 'No estimation', 'Perfect estimate'], 'correct': 1, 'explanation': 'Uses conservative error estimate to decide pruning.'},
    {'category': 'Decision Trees', 'question': 'What is minimum error pruning?', 'options': ['Maximum error', 'Prune to minimize expected error', 'No pruning', 'Random pruning'], 'correct': 1, 'explanation': 'Prunes based on minimizing expected error rate.'},
    {'category': 'Decision Trees', 'question': 'What is the role of max_features?', 'options': ['Total features', 'Features considered per split', 'Minimum features', 'Feature depth'], 'correct': 1, 'explanation': 'Limits random feature subset at each split.'},
    {'category': 'Decision Trees', 'question': 'What is max_leaf_nodes?', 'options': ['Unlimited leaves', 'Maximum number of leaf nodes', 'Minimum leaves', 'Tree depth'], 'correct': 1, 'explanation': 'Directly limits tree complexity via leaf count.'},
    {'category': 'Decision Trees', 'question': 'What is min_impurity_decrease?', 'options': ['Max impurity', 'Minimum impurity reduction to split', 'Tree depth', 'Sample size'], 'correct': 1, 'explanation': 'Split only if impurity reduction exceeds threshold.'},
    {'category': 'Decision Trees', 'question': 'What is class_weight parameter?', 'options': ['Feature weight', 'Adjust for imbalanced classes', 'Tree weight', 'Sample weight'], 'correct': 1, 'explanation': 'Balances class importance for imbalanced data.'},
    {'category': 'Decision Trees', 'question': 'What is sample_weight?', 'options': ['Class weight', 'Individual sample importance', 'Feature weight', 'Tree weight'], 'correct': 1, 'explanation': 'Assigns different importance to each sample.'},
    {'category': 'Decision Trees', 'question': 'Can trees naturally handle interactions?', 'options': ['No', 'Yes, through hierarchical splits', 'Need manual engineering', 'Never'], 'correct': 1, 'explanation': 'Tree structure naturally captures feature interactions.'},
    {'category': 'Decision Trees', 'question': 'What is monotonic constraint?', 'options': ['No constraint', 'Force monotonic relationship with feature', 'Random constraint', 'Linear only'], 'correct': 1, 'explanation': 'Ensures predictions increase/decrease with feature.'},
    {'category': 'Decision Trees', 'question': 'What is the Hoeffding bound?', 'options': ['Split criterion', 'Statistical bound for online trees', 'Impurity measure', 'Pruning method'], 'correct': 1, 'explanation': 'Used in online/streaming decision tree learning.'},
    {'category': 'Decision Trees', 'question': 'What is extremely randomized trees?', 'options': ['Standard trees', 'Trees with random thresholds', 'Pruned trees', 'Shallow trees'], 'correct': 1, 'explanation': 'Extra-Trees use random splits instead of optimal.'},
    {'category': 'Decision Trees', 'question': 'What is conditional inference tree?', 'options': ['Standard tree', 'Uses statistical tests for splits', 'Random tree', 'Ensemble'], 'correct': 1, 'explanation': 'Uses permutation tests to avoid selection bias.'},
    {'category': 'Decision Trees', 'question': 'What is regression tree variance?', 'options': ['Classification metric', 'Variance within leaf nodes', 'Feature variance', 'Sample variance'], 'correct': 1, 'explanation': 'Measures spread of target values in leaf.'},
    {'category': 'Decision Trees', 'question': 'What is friedman_mse?', 'options': ['Standard MSE', 'MSE with improvement score regularization', 'MAE', 'Gini'], 'correct': 1, 'explanation': 'Friedman MSE favors balanced splits in Scikit-learn.'},
    
    # Random Forest (50 questions)
    {'category': 'Random Forest', 'question': 'What is Random Forest?', 'options': ['Single tree', 'Ensemble of decision trees', 'Neural network', 'Linear model'], 'correct': 1, 'explanation': 'Random Forest builds multiple trees and aggregates predictions.'},
    {'category': 'Random Forest', 'question': 'What is bagging?', 'options': ['Feature selection', 'Bootstrap Aggregating - sampling with replacement', 'Boosting', 'Pruning'], 'correct': 1, 'explanation': 'Bagging creates diverse trees via bootstrap sampling.'},
    {'category': 'Random Forest', 'question': 'What is bootstrap sampling?', 'options': ['Without replacement', 'Sampling with replacement', 'Stratified', 'No sampling'], 'correct': 1, 'explanation': 'Bootstrap randomly samples with replacement.'},
    {'category': 'Random Forest', 'question': 'What is random subspace method?', 'options': ['All features', 'Random subset of features per split', 'No features', 'One feature'], 'correct': 1, 'explanation': 'Each split considers random feature subset.'},
    {'category': 'Random Forest', 'question': 'How many features per split typically?', 'options': ['All features', 'sqrt(n_features) for classification', 'One feature', 'Half features'], 'correct': 1, 'explanation': 'Default sqrt(n) for classification, n/3 for regression.'},
    {'category': 'Random Forest', 'question': 'How does RF make predictions?', 'options': ['Single tree', 'Majority vote or average', 'Weighted average', 'First tree'], 'correct': 1, 'explanation': 'Classification votes, regression averages.'},
    {'category': 'Random Forest', 'question': 'What is Out-of-Bag error?', 'options': ['Training error', 'Validation error on unsampled data', 'Test error', 'CV error'], 'correct': 1, 'explanation': 'OOB uses ~33% unsampled data as validation.'},
    {'category': 'Random Forest', 'question': 'Main advantage of RF over single tree?', 'options': ['Faster', 'Reduces overfitting and variance', 'More interpretable', 'Simpler'], 'correct': 1, 'explanation': 'Averaging reduces variance while maintaining low bias.'},
    {'category': 'Random Forest', 'question': 'Disadvantage of Random Forest?', 'options': ['Overfits easily', 'Less interpretable than single tree', 'Cannot handle missing', 'Needs scaling'], 'correct': 1, 'explanation': 'RF loses interpretability of single tree.'},
    {'category': 'Random Forest', 'question': 'Does RF need feature scaling?', 'options': ['Yes, always', 'No, tree-based', 'Sometimes', 'Only for regression'], 'correct': 1, 'explanation': 'Tree-based, no scaling needed.'},
    {'category': 'Random Forest', 'question': 'What is n_estimators?', 'options': ['Tree depth', 'Number of trees', 'Number of features', 'Sample size'], 'correct': 1, 'explanation': 'Controls how many trees to build.'},
    {'category': 'Random Forest', 'question': 'What happens with too many trees?', 'options': ['Overfitting', 'Diminishing returns, slower training', 'Underfitting', 'Worse performance'], 'correct': 1, 'explanation': 'More trees improve to a point, then plateau.'},
    {'category': 'Random Forest', 'question': 'Can RF handle imbalanced data?', 'options': ['No', 'Yes, with class_weight', 'Only balanced', 'Never'], 'correct': 1, 'explanation': 'class_weight adjusts for imbalance.'},
    {'category': 'Random Forest', 'question': 'How to get feature importance?', 'options': ['Coefficients', 'Average impurity decrease across trees', 'P-values', 'Correlation'], 'correct': 1, 'explanation': 'Averages impurity reduction from feature.'},
    {'category': 'Random Forest', 'question': 'What is max_features parameter?', 'options': ['Total features', 'Features to consider per split', 'Min features', 'Feature depth'], 'correct': 1, 'explanation': 'Limits random feature subset size.'},
    {'category': 'Random Forest', 'question': 'Is RF parallelizable?', 'options': ['No', 'Yes, trees train independently', 'Only small forests', 'Only GPU'], 'correct': 1, 'explanation': 'Trees are independent, enabling parallel training.'},
    {'category': 'Random Forest', 'question': 'Bias-variance tradeoff in RF?', 'options': ['High bias, low variance', 'Low bias, low variance', 'High bias, high variance', 'No tradeoff'], 'correct': 1, 'explanation': 'RF achieves low bias and low variance.'},
    {'category': 'Random Forest', 'question': 'Can RF handle missing values?', 'options': ['Yes, natively', 'Depends on implementation', 'No, never', 'Only with imputation'], 'correct': 1, 'explanation': 'Sklearn requires imputation.'},
    {'category': 'Random Forest', 'question': 'What is Extra Trees?', 'options': ['Same as RF', 'RF with random thresholds', 'Boosted trees', 'Single tree'], 'correct': 1, 'explanation': 'Extra Trees add randomness with random split thresholds.'},
    {'category': 'Random Forest', 'question': 'Extra Trees vs Random Forest?', 'options': ['No difference', 'More randomness, faster training', 'Slower', 'Less accurate'], 'correct': 1, 'explanation': 'Extra Trees faster but may sacrifice accuracy.'},
    {'category': 'Random Forest', 'question': 'What is bootstrap parameter?', 'options': ['Tree depth', 'Whether to use bootstrap', 'Number of trees', 'Feature count'], 'correct': 1, 'explanation': 'bootstrap=False uses whole dataset per tree.'},
    {'category': 'Random Forest', 'question': 'Can RF be used for feature selection?', 'options': ['No', 'Yes, via feature importance', 'Only manually', 'Not reliable'], 'correct': 1, 'explanation': 'Feature importance helps select relevant features.'},
    {'category': 'Random Forest', 'question': 'What is permutation importance?', 'options': ['Standard importance', 'Importance via shuffling and measuring impact', 'Gini importance', 'No importance'], 'correct': 1, 'explanation': 'Shuffles feature and measures performance drop.'},
    {'category': 'Random Forest', 'question': 'Is RF prone to overfitting?', 'options': ['Yes, always', 'Less than single trees', 'More than trees', 'Never'], 'correct': 1, 'explanation': 'Averaging reduces overfitting vs single trees.'},
    {'category': 'Random Forest', 'question': 'What is warm_start?', 'options': ['Tree depth', 'Add trees to existing forest', 'Training speed', 'Sampling'], 'correct': 1, 'explanation': 'Allows incremental tree addition.'},
    {'category': 'Random Forest', 'question': 'Can RF extrapolate?', 'options': ['Yes, naturally', 'No, limited by training range', 'Better than linear', 'Always'], 'correct': 1, 'explanation': 'Trees cannot predict beyond training range.'},
    {'category': 'Random Forest', 'question': 'What is min_impurity_decrease?', 'options': ['Max impurity', 'Minimum impurity reduction to split', 'Tree depth', 'Sample size'], 'correct': 1, 'explanation': 'Prevents weak splits.'},
    {'category': 'Random Forest', 'question': 'How to tune RF hyperparameters?', 'options': ['Manual only', 'Grid/random search', 'No tuning', 'Bayesian only'], 'correct': 1, 'explanation': 'Use grid/random/Bayesian optimization.'},
    {'category': 'Random Forest', 'question': 'What is typical OOB score range?', 'options': ['0-1 like accuracy', 'Similar to validation accuracy', '-1 to 1', 'Always 1'], 'correct': 1, 'explanation': 'OOB approximates validation accuracy.'},
    {'category': 'Random Forest', 'question': 'Can RF handle high-dimensional data?', 'options': ['No', 'Yes, via random feature selection', 'Only low dimensions', 'Needs reduction'], 'correct': 1, 'explanation': 'Random feature selection makes RF effective for high dimensions.'},
    {'category': 'Random Forest', 'question': 'What is criterion parameter?', 'options': ['Sampling', 'Split quality measure', 'Tree depth', 'Number of trees'], 'correct': 1, 'explanation': 'Chooses gini/entropy for classification, mse for regression.'},
    {'category': 'Random Forest', 'question': 'Is RF suitable for real-time prediction?', 'options': ['Always fast', 'Depends on forest size', 'Too slow', 'Only small'], 'correct': 1, 'explanation': 'Prediction time grows with trees.'},
    {'category': 'Random Forest', 'question': 'What is ccp_alpha?', 'options': ['Learning rate', 'Cost complexity pruning parameter', 'Tree depth', 'Sample weight'], 'correct': 1, 'explanation': 'Controls cost complexity pruning.'},
    {'category': 'Random Forest', 'question': 'Can RF handle mixed data types?', 'options': ['No', 'Yes, numerical and categorical', 'Only numerical', 'Only categorical'], 'correct': 1, 'explanation': 'Handles both with proper encoding.'},
    {'category': 'Random Forest', 'question': 'What percentage OOB typically?', 'options': ['10%', 'About 37%', '50%', '90%'], 'correct': 1, 'explanation': 'About 37% samples left out each bootstrap.'},
    {'category': 'Random Forest', 'question': 'What is gini importance bias?', 'options': ['No bias', 'Biased toward high cardinality features', 'No preference', 'Random'], 'correct': 1, 'explanation': 'Gini importance favors features with more categories.'},
    {'category': 'Random Forest', 'question': 'What is drop-column importance?', 'options': ['Standard importance', 'Importance by removing feature completely', 'Gini', 'Permutation'], 'correct': 1, 'explanation': 'Retrains without feature to measure importance.'},
    {'category': 'Random Forest', 'question': 'What is SHAP for RF?', 'options': ['Loss function', 'Shapley values explaining predictions', 'Accuracy', 'Importance'], 'correct': 1, 'explanation': 'SHAP provides consistent feature attributions.'},
    {'category': 'Random Forest', 'question': 'What is proximity matrix?', 'options': ['Distance matrix', 'Matrix of sample co-occurrences in leaves', 'Correlation', 'Confusion'], 'correct': 1, 'explanation': 'Counts how often samples end in same leaf.'},
    {'category': 'Random Forest', 'question': 'Can RF detect outliers?', 'options': ['No', 'Yes, via proximity or isolation', 'Never', 'Only supervised'], 'correct': 1, 'explanation': 'Outliers have low proximity to other samples.'},
    {'category': 'Random Forest', 'question': 'What is Isolation Forest?', 'options': ['Random Forest', 'Anomaly detection using random trees', 'Boosting', 'Clustering'], 'correct': 1, 'explanation': 'Isolates outliers in fewer splits.'},
    {'category': 'Random Forest', 'question': 'What is balanced random forest?', 'options': ['Standard RF', 'RF with balanced bootstrap sampling', 'No balancing', 'Boosted'], 'correct': 1, 'explanation': 'Balances classes in each bootstrap sample.'},
    {'category': 'Random Forest', 'question': 'What is weighted random forest?', 'options': ['Standard RF', 'RF with sample/class weights', 'No weights', 'Equal weights'], 'correct': 1, 'explanation': 'Incorporates sample or class weights.'},
    {'category': 'Random Forest', 'question': 'Can RF provide prediction intervals?', 'options': ['Yes, directly', 'Yes, via quantile regression forests', 'No', 'Never'], 'correct': 1, 'explanation': 'Quantile RF estimates prediction intervals.'},
    {'category': 'Random Forest', 'question': 'What is conditional forest?', 'options': ['Standard RF', 'RF with unbiased variable selection', 'Boosted', 'Pruned'], 'correct': 1, 'explanation': 'Uses conditional inference to avoid bias.'},
    {'category': 'Random Forest', 'question': 'What is Mondrian forest?', 'options': ['Standard RF', 'Online random forest variant', 'Offline only', 'Boosted'], 'correct': 1, 'explanation': 'Supports online/streaming learning.'},
    {'category': 'Random Forest', 'question': 'What is rotation forest?', 'options': ['Standard RF', 'RF with PCA on feature subsets', 'No rotation', 'Boosted'], 'correct': 1, 'explanation': 'Applies PCA to random feature subsets.'},
    {'category': 'Random Forest', 'question': 'What is oblique random forest?', 'options': ['Axis-aligned', 'RF with oblique splits', 'Standard RF', 'Perpendicular'], 'correct': 1, 'explanation': 'Uses linear combinations for splits.'},
    {'category': 'Random Forest', 'question': 'Memory usage of RF?', 'options': ['Low', 'Grows linearly with trees', 'Constant', 'Logarithmic'], 'correct': 1, 'explanation': 'Must store all trees in memory.'},
    {'category': 'Random Forest', 'question': 'Can RF overfit with enough trees?', 'options': ['Yes, easily', 'No, converges to limit', 'Always overfits', 'Depends'], 'correct': 1, 'explanation': 'More trees generally improve or plateau, not overfit.'},
    
    # Gradient Boosting (50 questions)
    {'category': 'Gradient Boosting', 'question': 'What is boosting?', 'options': ['Parallel training', 'Sequential training correcting errors', 'Bagging', 'Random sampling'], 'correct': 1, 'explanation': 'Boosting builds models sequentially, each focusing on previous errors.'},
    {'category': 'Gradient Boosting', 'question': 'How does GB differ from RF?', 'options': ['No difference', 'Sequential vs parallel, fits residuals', 'Faster', 'Simpler'], 'correct': 1, 'explanation': 'GB trains sequentially on residuals, RF trains independently.'},
    {'category': 'Gradient Boosting', 'question': 'What does each tree predict in GB?', 'options': ['Original target', 'Residual errors from previous', 'Random values', 'Average'], 'correct': 1, 'explanation': 'Each tree fits negative gradient (residuals) of loss.'},
    {'category': 'Gradient Boosting', 'question': 'What is learning rate in GB?', 'options': ['Training speed', 'Shrinkage factor for tree contributions', 'Loss function', 'Tree depth'], 'correct': 1, 'explanation': 'Learning rate scales each tree contribution.'},
    {'category': 'Gradient Boosting', 'question': 'Tradeoff with learning rate?', 'options': ['No tradeoff', 'Lower rate needs more trees but generalizes better', 'Higher always better', 'No impact'], 'correct': 1, 'explanation': 'Lower rates reduce overfitting but need more trees.'},
    {'category': 'Gradient Boosting', 'question': 'What is early stopping?', 'options': ['Stop at fixed trees', 'Stop when validation error stops improving', 'Random stopping', 'Never stop'], 'correct': 1, 'explanation': 'Monitors validation error to stop training.'},
    {'category': 'Gradient Boosting', 'question': 'Is GB more prone to overfitting than RF?', 'options': ['No', 'Yes, sequential nature can memorize', 'Same', 'Never overfits'], 'correct': 1, 'explanation': 'Sequential fitting can overfit, needs careful tuning.'},
    {'category': 'Gradient Boosting', 'question': 'What is subsample parameter?', 'options': ['Feature sampling', 'Fraction of samples per tree', 'Tree depth', 'Number of trees'], 'correct': 1, 'explanation': 'subsample < 1 uses stochastic gradient boosting.'},
    {'category': 'Gradient Boosting', 'question': 'Typical max_depth for GB?', 'options': ['Very deep (>20)', 'Shallow (3-8)', 'No limit', '1'], 'correct': 1, 'explanation': 'GB uses shallow trees as weak learners.'},
    {'category': 'Gradient Boosting', 'question': 'What is a weak learner?', 'options': ['Bad model', 'Simple model slightly better than random', 'Complex model', 'Random predictor'], 'correct': 1, 'explanation': 'Weak learners have low complexity, slightly better than chance.'},
    {'category': 'Gradient Boosting', 'question': 'Can GB be parallelized?', 'options': ['Yes, like RF', 'Limited, trees are sequential', 'Fully parallel', 'Never'], 'correct': 1, 'explanation': 'Trees must be sequential, but within-tree can parallelize.'},
    {'category': 'Gradient Boosting', 'question': 'What is XGBoost?', 'options': ['RF variant', 'Extreme Gradient Boosting with regularization', 'Neural network', 'Clustering'], 'correct': 1, 'explanation': 'XGBoost has L1/L2 regularization and optimizations.'},
    {'category': 'Gradient Boosting', 'question': 'What is LightGBM?', 'options': ['Light neural net', 'GB using histogram-based learning', 'Random Forest', 'Linear model'], 'correct': 1, 'explanation': 'LightGBM uses histogram-based for speed.'},
    {'category': 'Gradient Boosting', 'question': 'What is CatBoost?', 'options': ['Cat classifier', 'GB handling categorical natively', 'Image classifier', 'Clustering'], 'correct': 1, 'explanation': 'CatBoost handles categorical without encoding.'},
    {'category': 'Gradient Boosting', 'question': 'Leaf-wise vs level-wise growth?', 'options': ['No difference', 'Leaf-wise grows best leaf, level-wise full level', 'Same thing', 'Random'], 'correct': 1, 'explanation': 'Leaf-wise (LightGBM) vs level-wise (XGBoost).'},
    {'category': 'Gradient Boosting', 'question': 'What is n_estimators?', 'options': ['Tree depth', 'Number of boosting rounds/trees', 'Sample size', 'Feature count'], 'correct': 1, 'explanation': 'Controls sequential tree count.'},
    {'category': 'Gradient Boosting', 'question': 'What regularization does XGBoost provide?', 'options': ['None', 'L1 (alpha) and L2 (lambda)', 'Only L1', 'Only L2'], 'correct': 1, 'explanation': 'XGBoost adds L1/L2 on leaf weights.'},
    {'category': 'Gradient Boosting', 'question': 'What is gamma in XGBoost?', 'options': ['Learning rate', 'Minimum loss reduction to split', 'Tree depth', 'Sample weight'], 'correct': 1, 'explanation': 'gamma is min_split_loss for regularization.'},
    {'category': 'Gradient Boosting', 'question': 'What is colsample_bytree?', 'options': ['Sample rows', 'Fraction of features per tree', 'Tree depth', 'Learning rate'], 'correct': 1, 'explanation': 'Randomly samples features per tree.'},
    {'category': 'Gradient Boosting', 'question': 'What is scale_pos_weight?', 'options': ['Feature scaling', 'Balance positive class for imbalanced', 'Learning rate', 'Tree weight'], 'correct': 1, 'explanation': 'Adjusts positive class weight.'},
    {'category': 'Gradient Boosting', 'question': 'How does GB handle missing values?', 'options': ['Requires imputation', 'Learns optimal direction per split', 'Removes samples', 'Random'], 'correct': 1, 'explanation': 'XGBoost/LightGBM learn optimal missing direction.'},
    {'category': 'Gradient Boosting', 'question': 'What is histogram-based learning?', 'options': ['Plotting', 'Binning features for faster splits', 'Loss function', 'Ensemble'], 'correct': 1, 'explanation': 'Bins features to reduce split complexity.'},
    {'category': 'Gradient Boosting', 'question': 'What is GOSS in LightGBM?', 'options': ['Loss function', 'Gradient-based One-Side Sampling', 'Tree structure', 'Feature selection'], 'correct': 1, 'explanation': 'GOSS keeps large-gradient samples for speed.'},
    {'category': 'Gradient Boosting', 'question': 'What is EFB in LightGBM?', 'options': ['Error function', 'Exclusive Feature Bundling', 'Tree pruning', 'Sampling'], 'correct': 1, 'explanation': 'EFB bundles mutually exclusive features.'},
    {'category': 'Gradient Boosting', 'question': 'What objectives can GB optimize?', 'options': ['Only MSE', 'MSE, log loss, custom objectives', 'Only classification', 'Only regression'], 'correct': 1, 'explanation': 'GB optimizes various objectives including custom.'},
    {'category': 'Gradient Boosting', 'question': 'What is monotonic constraint?', 'options': ['No constraints', 'Force monotonic relationship', 'Tree depth limit', 'Sample limit'], 'correct': 1, 'explanation': 'Ensures predictions increase/decrease with feature.'},
    {'category': 'Gradient Boosting', 'question': 'What is eval_metric?', 'options': ['Training metric', 'Metric for validation monitoring', 'Loss function', 'Learning rate'], 'correct': 1, 'explanation': 'Specifies validation metric to monitor.'},
    {'category': 'Gradient Boosting', 'question': 'Can GB handle multi-output?', 'options': ['Yes, natively', 'Limited, better train separately', 'No', 'Only classification'], 'correct': 1, 'explanation': 'Most GB focus on single output.'},
    {'category': 'Gradient Boosting', 'question': 'What is DART in XGBoost?', 'options': ['Feature', 'Dropouts meet Multiple Additive Regression Trees', 'Loss', 'Sampling'], 'correct': 1, 'explanation': 'DART adds dropout to boosting.'},
    {'category': 'Gradient Boosting', 'question': 'Typical learning rate range?', 'options': ['0.5-1.0', '0.01-0.3', '1.0-10.0', 'No range'], 'correct': 1, 'explanation': 'Typically 0.01-0.3, lower with more trees.'},
    {'category': 'Gradient Boosting', 'question': 'What is Newton boosting?', 'options': ['Standard GB', 'Uses second-order derivatives', 'First-order only', 'No derivatives'], 'correct': 1, 'explanation': 'Uses second derivatives (Hessian) for better approximation.'},
    {'category': 'Gradient Boosting', 'question': 'What is colsample_bylevel?', 'options': ['Tree-level sampling', 'Feature sampling per tree level', 'No sampling', 'Row sampling'], 'correct': 1, 'explanation': 'Samples features at each tree level.'},
    {'category': 'Gradient Boosting', 'question': 'What is colsample_bynode?', 'options': ['Tree sampling', 'Feature sampling per node', 'No sampling', 'Level sampling'], 'correct': 1, 'explanation': 'Samples features at each node split.'},
    {'category': 'Gradient Boosting', 'question': 'What is min_child_weight?', 'options': ['Max weight', 'Minimum sum of instance weight in child', 'Tree depth', 'Learning rate'], 'correct': 1, 'explanation': 'Controls minimum samples or weight per leaf.'},
    {'category': 'Gradient Boosting', 'question': 'What is max_delta_step?', 'options': ['No limit', 'Maximum step for tree weight updates', 'Tree depth', 'Sample size'], 'correct': 1, 'explanation': 'Limits leaf weight updates for stability.'},
    {'category': 'Gradient Boosting', 'question': 'What is tree_method in XGBoost?', 'options': ['Tree type', 'Algorithm for tree construction', 'Loss function', 'Metric'], 'correct': 1, 'explanation': 'Chooses exact, approx, hist, or gpu_hist.'},
    {'category': 'Gradient Boosting', 'question': 'What is sketch_eps?', 'options': ['Learning rate', 'Approximation accuracy for quantiles', 'Tree depth', 'Regularization'], 'correct': 1, 'explanation': 'Controls accuracy in approximate algorithms.'},
    {'category': 'Gradient Boosting', 'question': 'What is grow_policy?', 'options': ['No policy', 'Depthwise or lossguide growth', 'Random', 'Fixed'], 'correct': 1, 'explanation': 'Controls tree growing strategy.'},
    {'category': 'Gradient Boosting', 'question': 'What is max_leaves?', 'options': ['Unlimited', 'Maximum leaf nodes in tree', 'Minimum leaves', 'Tree depth'], 'correct': 1, 'explanation': 'Directly limits tree complexity.'},
    {'category': 'Gradient Boosting', 'question': 'What is max_bin in LightGBM?', 'options': ['No limit', 'Maximum bins for feature discretization', 'Tree depth', 'Sample size'], 'correct': 1, 'explanation': 'Controls histogram bin count.'},
    {'category': 'Gradient Boosting', 'question': 'What is min_data_in_leaf?', 'options': ['Maximum', 'Minimum samples required in leaf', 'Tree depth', 'Split count'], 'correct': 1, 'explanation': 'Prevents overfitting with tiny leaves.'},
    {'category': 'Gradient Boosting', 'question': 'What is feature_fraction in LightGBM?', 'options': ['All features', 'Fraction of features per tree', 'No sampling', 'Row fraction'], 'correct': 1, 'explanation': 'Random feature sampling per tree.'},
    {'category': 'Gradient Boosting', 'question': 'What is bagging_fraction?', 'options': ['No bagging', 'Data sampling fraction', 'Feature fraction', 'Tree fraction'], 'correct': 1, 'explanation': 'Samples data without replacement per iteration.'},
    {'category': 'Gradient Boosting', 'question': 'What is boosting_type in LightGBM?', 'options': ['Only GBDT', 'GBDT, DART, or GOSS', 'Only DART', 'Only GOSS'], 'correct': 1, 'explanation': 'Chooses boosting algorithm variant.'},
    {'category': 'Gradient Boosting', 'question': 'What is ordered boosting in CatBoost?', 'options': ['Random order', 'Prevents target leakage via ordering', 'No order', 'Fixed order'], 'correct': 1, 'explanation': 'Uses ordering to avoid prediction shift.'},
    {'category': 'Gradient Boosting', 'question': 'What is target encoding in CatBoost?', 'options': ['One-hot', 'Encoding categorical by target statistics', 'Label encoding', 'No encoding'], 'correct': 1, 'explanation': 'Encodes categories using target statistics.'},
    {'category': 'Gradient Boosting', 'question': 'What is border_count in CatBoost?', 'options': ['No limit', 'Number of splits for numerical features', 'Tree depth', 'Sample count'], 'correct': 1, 'explanation': 'Controls discretization of numerical features.'},
    {'category': 'Gradient Boosting', 'question': 'What is one_hot_max_size?', 'options': ['No limit', 'Max cardinality for one-hot encoding', 'Tree depth', 'Sample size'], 'correct': 1, 'explanation': 'CatBoost uses one-hot for small cardinality.'},
    {'category': 'Gradient Boosting', 'question': 'What is feature importance types in XGBoost?', 'options': ['Only gain', 'Gain, weight, cover, total_gain, total_cover', 'Only weight', 'Only cover'], 'correct': 1, 'explanation': 'Multiple importance calculation methods available.'},
    {'category': 'Gradient Boosting', 'question': 'Can GB be used for ranking?', 'options': ['No', 'Yes, with pairwise/listwise objectives', 'Only classification', 'Only regression'], 'correct': 1, 'explanation': 'GB supports ranking with specialized losses.'},
    
    # Support Vector Machines (50 questions)
    {'category': 'SVM', 'question': 'What is goal of SVM?', 'options': ['Minimize error', 'Find hyperplane maximizing margin', 'Build trees', 'Cluster data'], 'correct': 1, 'explanation': 'SVM finds optimal hyperplane maximizing margin.'},
    {'category': 'SVM', 'question': 'What is margin in SVM?', 'options': ['Error', 'Distance to nearest points', 'Accuracy', 'Loss'], 'correct': 1, 'explanation': 'Margin is distance to closest data points.'},
    {'category': 'SVM', 'question': 'What are support vectors?', 'options': ['All points', 'Points closest to boundary', 'Outliers', 'Centers'], 'correct': 1, 'explanation': 'Support vectors define the hyperplane.'},
    {'category': 'SVM', 'question': 'What is kernel trick?', 'options': ['Loss function', 'Transform to higher dimensions implicitly', 'Regularization', 'Optimization'], 'correct': 1, 'explanation': 'Maps data to higher dimensions efficiently.'},
    {'category': 'SVM', 'question': 'What is linear kernel?', 'options': ['No kernel', 'Dot product: K(x,y) = x^T y', 'Polynomial', 'RBF'], 'correct': 1, 'explanation': 'Linear kernel performs no transformation.'},
    {'category': 'SVM', 'question': 'What is RBF kernel?', 'options': ['Linear', 'K(x,y) = exp(-gamma * ||x-y||²)', 'Polynomial', 'Sigmoid'], 'correct': 1, 'explanation': 'RBF maps to infinite dimensions.'},
    {'category': 'SVM', 'question': 'What is polynomial kernel?', 'options': ['Linear', 'K(x,y) = (x^T y + c)^d', 'RBF', 'Sigmoid'], 'correct': 1, 'explanation': 'Polynomial kernel of degree d.'},
    {'category': 'SVM', 'question': 'What is C parameter?', 'options': ['Kernel parameter', 'Regularization - margin vs errors tradeoff', 'Learning rate', 'Kernel degree'], 'correct': 1, 'explanation': 'C controls misclassification penalty.'},
    {'category': 'SVM', 'question': 'What is gamma in RBF?', 'options': ['Regularization', 'Controls influence range', 'Learning rate', 'Margin width'], 'correct': 1, 'explanation': 'High gamma: small influence, complex boundary.'},
    {'category': 'SVM', 'question': 'What is hard margin SVM?', 'options': ['Soft margin', 'No misclassification allowed', 'With errors', 'Non-linear'], 'correct': 1, 'explanation': 'Hard margin requires perfect separation.'},
    {'category': 'SVM', 'question': 'What is soft margin SVM?', 'options': ['Hard margin', 'Allows misclassification with penalty', 'No errors', 'Linear only'], 'correct': 1, 'explanation': 'Soft margin allows errors controlled by C.'},
    {'category': 'SVM', 'question': 'Does SVM need feature scaling?', 'options': ['No', 'Yes, very sensitive to scale', 'Sometimes', 'Only linear'], 'correct': 1, 'explanation': 'SVM is distance-based, needs scaling.'},
    {'category': 'SVM', 'question': 'Is SVM suitable for large datasets?', 'options': ['Yes, very fast', 'No, O(n²) to O(n³) complexity', 'Always fast', 'Best for big data'], 'correct': 1, 'explanation': 'Training complexity quadratic to cubic.'},
    {'category': 'SVM', 'question': 'Can SVM do multi-class?', 'options': ['Yes, natively binary extended', 'One-vs-rest or one-vs-one', 'No', 'Only binary'], 'correct': 1, 'explanation': 'Uses OvR or OvO strategies.'},
    {'category': 'SVM', 'question': 'What is hinge loss?', 'options': ['MSE', 'max(0, 1 - y*f(x))', 'Cross-entropy', 'Absolute'], 'correct': 1, 'explanation': 'Hinge loss penalizes margin violations.'},
    {'category': 'SVM', 'question': 'Can SVM do regression?', 'options': ['No', 'Yes, Support Vector Regression', 'Only classification', 'Never'], 'correct': 1, 'explanation': 'SVR uses epsilon-insensitive loss.'},
    {'category': 'SVM', 'question': 'What is epsilon in SVR?', 'options': ['Learning rate', 'Width of no-penalty zone', 'Regularization', 'Kernel parameter'], 'correct': 1, 'explanation': 'Defines tube width for acceptable errors.'},
    {'category': 'SVM', 'question': 'What is separating hyperplane?', 'options': ['Non-linear', 'Linear boundary separating classes', 'Cluster center', 'Feature space'], 'correct': 1, 'explanation': 'Hyperplane divides space into classes.'},
    {'category': 'SVM', 'question': 'What is dual formulation?', 'options': ['Same as primal', 'Optimization via Lagrange multipliers', 'Loss function', 'Kernel'], 'correct': 1, 'explanation': 'Dual enables kernel trick.'},
    {'category': 'SVM', 'question': 'What is sigmoid kernel?', 'options': ['RBF', 'K(x,y) = tanh(gamma*x^T y + r)', 'Linear', 'Polynomial'], 'correct': 1, 'explanation': 'Sigmoid kernel like neural activation.'},
    {'category': 'SVM', 'question': 'Why use kernels?', 'options': ['Speed', 'Handle non-linear without explicit transform', 'Regularization', 'Simplicity'], 'correct': 1, 'explanation': 'Kernels compute in high dimensions implicitly.'},
    {'category': 'SVM', 'question': 'What is decision function?', 'options': ['Probability', 'Signed distance to hyperplane', 'Class label', 'Kernel value'], 'correct': 1, 'explanation': 'f(x) = w·x + b, sign determines class.'},
    {'category': 'SVM', 'question': 'Can SVM output probabilities?', 'options': ['Yes, directly', 'Yes, via Platt scaling', 'No', 'Only certain kernels'], 'correct': 1, 'explanation': 'Platt scaling maps distances to probabilities.'},
    {'category': 'SVM', 'question': 'What is class_weight?', 'options': ['Kernel weight', 'Adjust for imbalanced classes', 'Margin width', 'Learning rate'], 'correct': 1, 'explanation': 'Balances class penalties.'},
    {'category': 'SVM', 'question': 'What is OvR strategy?', 'options': ['Binary only', 'Train N classifiers for N classes', 'One-vs-one', 'No strategy'], 'correct': 1, 'explanation': 'Each class vs all others.'},
    {'category': 'SVM', 'question': 'What is OvO strategy?', 'options': ['One-vs-rest', 'Classifier for each pair, vote', 'Binary only', 'No strategy'], 'correct': 1, 'explanation': 'Trains N(N-1)/2 classifiers.'},
    {'category': 'SVM', 'question': 'Advantage of SVM?', 'options': ['Fast on big data', 'Effective in high dimensions, kernel flexibility', 'Easy to tune', 'Always best'], 'correct': 1, 'explanation': 'Works well in high dimensions with flexible kernels.'},
    {'category': 'SVM', 'question': 'Disadvantage of SVM?', 'options': ['Always accurate', 'Slow on large data, sensitive parameters', 'Too simple', 'No disadvantages'], 'correct': 1, 'explanation': 'Slow and needs careful tuning.'},
    {'category': 'SVM', 'question': 'What is nu-SVM?', 'options': ['Standard SVM', 'SVM with nu replacing C', 'Kernel type', 'Loss function'], 'correct': 1, 'explanation': 'Nu-SVM uses nu ∈ (0,1) parameter.'},
    {'category': 'SVM', 'question': 'Can SVM handle missing?', 'options': ['Yes, natively', 'No, requires imputation', 'Sometimes', 'Always'], 'correct': 1, 'explanation': 'Requires complete data.'},
    {'category': 'SVM', 'question': 'What is kernel matrix?', 'options': ['Feature matrix', 'Matrix of all pairwise kernel values', 'Weight matrix', 'Distance matrix'], 'correct': 1, 'explanation': 'Gram matrix K_ij = k(x_i, x_j).'},
    {'category': 'SVM', 'question': 'What is Mercer condition?', 'options': ['Any function', 'Condition for valid kernels', 'Loss function', 'No condition'], 'correct': 1, 'explanation': 'Kernel must be positive semi-definite.'},
    {'category': 'SVM', 'question': 'What is SMO algorithm?', 'options': ['Random search', 'Sequential Minimal Optimization', 'Grid search', 'Gradient descent'], 'correct': 1, 'explanation': 'Efficient algorithm for training SVM.'},
    {'category': 'SVM', 'question': 'What is shrinking heuristic?', 'options': ['Enlarging', 'Speed up by removing non-support vectors', 'Regularization', 'Loss function'], 'correct': 1, 'explanation': 'Removes likely non-SV during training.'},
    {'category': 'SVM', 'question': 'What is cache_size in SVM?', 'options': ['Dataset size', 'Kernel cache size in MB', 'Model size', 'Tree depth'], 'correct': 1, 'explanation': 'Cache for kernel values.'},
    {'category': 'SVM', 'question': 'What is tol parameter?', 'options': ['Regularization', 'Tolerance for stopping criterion', 'Learning rate', 'Margin'], 'correct': 1, 'explanation': 'Convergence tolerance threshold.'},
    {'category': 'SVM', 'question': 'What is decision_function_shape?', 'options': ['Binary only', 'OvR or OvO for multi-class', 'No shape', 'Fixed'], 'correct': 1, 'explanation': 'Chooses multi-class strategy.'},
    {'category': 'SVM', 'question': 'What is LinearSVC?', 'options': ['Non-linear only', 'Fast linear SVM implementation', 'Kernel SVM', 'Regression'], 'correct': 1, 'explanation': 'Optimized for linear case using liblinear.'},
    {'category': 'SVM', 'question': 'What is NuSVC vs SVC?', 'options': ['No difference', 'Nu vs C parameterization', 'Different kernels', 'Different loss'], 'correct': 1, 'explanation': 'Nu bounds support vectors and errors.'},
    {'category': 'SVM', 'question': 'What is OneClassSVM?', 'options': ['Binary classification', 'Novelty/outlier detection', 'Multi-class', 'Regression'], 'correct': 1, 'explanation': 'Learns decision boundary for one class.'},
    {'category': 'SVM', 'question': 'What is coef0 in polynomial/sigmoid?', 'options': ['Coefficient', 'Independent term in kernel', 'Degree', 'Gamma'], 'correct': 1, 'explanation': 'Constant term in kernel formula.'},
    {'category': 'SVM', 'question': 'What is degree in polynomial kernel?', 'options': ['Always 2', 'Polynomial degree parameter', 'Regularization', 'Gamma'], 'correct': 1, 'explanation': 'Degree d in (x·y + r)^d.'},
    {'category': 'SVM', 'question': 'Can SVM handle non-linearly separable data?', 'options': ['No', 'Yes, with kernels and soft margin', 'Only linearly separable', 'Never'], 'correct': 1, 'explanation': 'Kernels and soft margin handle non-separable.'},
    {'category': 'SVM', 'question': 'What is support vector ratio typically?', 'options': ['100%', 'Small fraction of training data', '50%', '0%'], 'correct': 1, 'explanation': 'Usually small fraction are support vectors.'},
    {'category': 'SVM', 'question': 'What is primal vs dual problem?', 'options': ['Same', 'Primal in feature space, dual in sample space', 'No difference', 'Random'], 'correct': 1, 'explanation': 'Dual more efficient for high-dimensional data.'},
    {'category': 'SVM', 'question': 'What is max_iter parameter?', 'options': ['Minimum iterations', 'Maximum iterations for convergence', 'Fixed iterations', 'No limit'], 'correct': 1, 'explanation': 'Limits solver iterations.'},
    {'category': 'SVM', 'question': 'What is probability parameter?', 'options': ['Always true', 'Enable probability estimates', 'Disable probabilities', 'No effect'], 'correct': 1, 'explanation': 'Enables Platt scaling for probabilities.'},
    {'category': 'SVM', 'question': 'What is random_state for?', 'options': ['No randomness', 'Reproducibility of data shuffling', 'Learning rate', 'Regularization'], 'correct': 1, 'explanation': 'Seeds random number generator.'},
    {'category': 'SVM', 'question': 'What is break_ties parameter?', 'options': ['No ties', 'Tie-breaking for OvO predictions', 'Binary only', 'No effect'], 'correct': 1, 'explanation': 'Uses confidence scores to break ties.'},
    {'category': 'SVM', 'question': 'Can SVM scale to millions of samples?', 'options': ['Yes, easily', 'No, use linear SVM or SGD', 'Always scales', 'Never'], 'correct': 1, 'explanation': 'Use LinearSVC or SGDClassifier for large data.'},
    
    # K-Means (30 questions)
    {'category': 'K-Means', 'question': 'What type of algorithm is K-Means?', 'options': ['Supervised', 'Unsupervised clustering', 'Semi-supervised', 'Reinforcement'], 'correct': 1, 'explanation': 'K-Means groups data without labels.'},
    {'category': 'K-Means', 'question': 'What is K in K-Means?', 'options': ['Features', 'Number of clusters', 'Samples', 'Iterations'], 'correct': 1, 'explanation': 'K specifies cluster count.'},
    {'category': 'K-Means', 'question': 'How does K-Means assign points?', 'options': ['Randomly', 'To nearest centroid', 'Farthest centroid', 'No assignment'], 'correct': 1, 'explanation': 'Assigns to nearest centroid by distance.'},
    {'category': 'K-Means', 'question': 'How are centroids updated?', 'options': ['Fixed', 'Mean of assigned points', 'Random', 'Median'], 'correct': 1, 'explanation': 'Centroids are mean of cluster points.'},
    {'category': 'K-Means', 'question': 'What is K-Means objective?', 'options': ['Maximize variance', 'Minimize within-cluster sum of squares', 'Maximize distance', 'Random'], 'correct': 1, 'explanation': 'Minimizes WCSS (inertia).'},
    {'category': 'K-Means', 'question': 'What is elbow method?', 'options': ['Clustering algorithm', 'Plot WCSS vs K to find optimal', 'Distance metric', 'Initialization'], 'correct': 1, 'explanation': 'Find elbow point in WCSS curve.'},
    {'category': 'K-Means', 'question': 'What is silhouette score?', 'options': ['Loss', 'Measure of cohesion and separation (-1 to 1)', 'Accuracy', 'Distance'], 'correct': 1, 'explanation': 'Measures cluster quality.'},
    {'category': 'K-Means', 'question': 'What is K-Means++?', 'options': ['Standard K-Means', 'Smart initialization method', 'Loss function', 'Distance metric'], 'correct': 1, 'explanation': 'Initializes centroids far apart.'},
    {'category': 'K-Means', 'question': 'Does K-Means guarantee global optimum?', 'options': ['Yes', 'No, can converge to local', 'Always optimal', 'No convergence'], 'correct': 1, 'explanation': 'Sensitive to initialization.'},
    {'category': 'K-Means', 'question': 'Does K-Means need scaling?', 'options': ['No', 'Yes, distance-based', 'Sometimes', 'Never'], 'correct': 1, 'explanation': 'Uses distances, needs scaling.'},
    {'category': 'K-Means', 'question': 'What shapes does K-Means assume?', 'options': ['Any shape', 'Spherical/globular clusters', 'Linear', 'No assumption'], 'correct': 1, 'explanation': 'Assumes spherical clusters.'},
    {'category': 'K-Means', 'question': 'Can K-Means handle outliers?', 'options': ['Very robust', 'No, sensitive to outliers', 'Ignores them', 'Always handles'], 'correct': 1, 'explanation': 'Outliers shift centroids significantly.'},
    {'category': 'K-Means', 'question': 'What is inertia?', 'options': ['Speed', 'Sum of squared distances to centroid', 'Iterations', 'Accuracy'], 'correct': 1, 'explanation': 'Measures cluster compactness.'},
    {'category': 'K-Means', 'question': 'Time complexity of K-Means?', 'options': ['O(n)', 'O(n * K * i * d)', 'O(n²)', 'O(1)'], 'correct': 1, 'explanation': 'n=samples, K=clusters, i=iterations, d=dimensions.'},
    {'category': 'K-Means', 'question': 'Stopping criterion?', 'options': ['Fixed iterations', 'Centroids stabilize or max iterations', 'Random', 'Never stops'], 'correct': 1, 'explanation': 'Stops when centroids stop changing.'},
    {'category': 'K-Means', 'question': 'Can K-Means handle categorical?', 'options': ['Yes, directly', 'No, use K-Modes or encode', 'Sometimes', 'Always'], 'correct': 1, 'explanation': 'Needs numerical data for distances.'},
    {'category': 'K-Means', 'question': 'What is mini-batch K-Means?', 'options': ['Standard', 'Uses random batches for speed', 'Slower', 'Different algorithm'], 'correct': 1, 'explanation': 'Faster with small random batches.'},
    {'category': 'K-Means', 'question': 'How to determine optimal K?', 'options': ['Always 3', 'Elbow, silhouette, domain knowledge', 'Random', 'Always 10'], 'correct': 1, 'explanation': 'Use multiple methods to choose K.'},
    {'category': 'K-Means', 'question': 'Curse of dimensionality for K-Means?', 'options': ['More better', 'Distance meaningless in high dimensions', 'No effect', 'Faster'], 'correct': 1, 'explanation': 'High dimensions make distances similar.'},
    {'category': 'K-Means', 'question': 'Can K-Means find arbitrary shapes?', 'options': ['Yes', 'No, only convex spherical', 'Any shape', 'Only linear'], 'correct': 1, 'explanation': 'Limited to convex boundaries.'},
    {'category': 'K-Means', 'question': 'What is K-Medoids?', 'options': ['K-Means', 'Uses actual data points as centers', 'Different algorithm', 'No medoids'], 'correct': 1, 'explanation': 'More robust to outliers using medoids.'},
    {'category': 'K-Means', 'question': 'What is fuzzy C-Means?', 'options': ['Hard clustering', 'Soft clustering with membership degrees', 'K-Means', 'Hierarchical'], 'correct': 1, 'explanation': 'Assigns probabilistic membership.'},
    {'category': 'K-Means', 'question': 'What is K-Modes?', 'options': ['K-Means', 'K-Means for categorical data', 'Numerical only', 'Regression'], 'correct': 1, 'explanation': 'Uses modes instead of means.'},
    {'category': 'K-Means', 'question': 'What distance metric typically used?', 'options': ['Manhattan', 'Euclidean', 'Cosine', 'Hamming'], 'correct': 1, 'explanation': 'Default is Euclidean distance.'},
    {'category': 'K-Means', 'question': 'Can use other distance metrics?', 'options': ['No', 'Yes, but may not converge', 'Only Euclidean', 'Always converges'], 'correct': 1, 'explanation': 'Non-Euclidean may not guarantee convergence.'},
    {'category': 'K-Means', 'question': 'What is n_init parameter?', 'options': ['Iterations', 'Number of times to run with different seeds', 'Clusters', 'Features'], 'correct': 1, 'explanation': 'Runs multiple times, keeps best.'},
    {'category': 'K-Means', 'question': 'What is max_iter?', 'options': ['Minimum', 'Maximum iterations per run', 'Fixed', 'No limit'], 'correct': 1, 'explanation': 'Limits iterations per run.'},
    {'category': 'K-Means', 'question': 'What is tol parameter?', 'options': ['Regularization', 'Tolerance for declaring convergence', 'Learning rate', 'Distance'], 'correct': 1, 'explanation': 'Convergence threshold.'},
    {'category': 'K-Means', 'question': 'What is algorithm parameter?', 'options': ['Only one', 'auto, full, elkan algorithms', 'Fixed', 'No choice'], 'correct': 1, 'explanation': 'Chooses computational algorithm.'},
    {'category': 'K-Means', 'question': 'Can K-Means give different results?', 'options': ['No, always same', 'Yes, depends on initialization', 'Always same', 'Deterministic'], 'correct': 1, 'explanation': 'Random initialization causes variability.'},
    
    # Neural Networks (60 questions)
    {'category': 'Neural Networks', 'question': 'What is a perceptron?', 'options': ['Deep network', 'Single-layer linear classifier', 'Clustering', 'Tree'], 'correct': 1, 'explanation': 'Simplest neural network.'},
    {'category': 'Neural Networks', 'question': 'What is activation function?', 'options': ['Loss', 'Non-linear transformation', 'Optimizer', 'Metric'], 'correct': 1, 'explanation': 'Introduces non-linearity.'},
    {'category': 'Neural Networks', 'question': 'What is sigmoid activation?', 'options': ['Linear', 'σ(x) = 1/(1+e^(-x))', 'ReLU', 'Softmax'], 'correct': 1, 'explanation': 'Squashes to (0,1).'},
    {'category': 'Neural Networks', 'question': 'What is ReLU?', 'options': ['Sigmoid', 'max(0, x)', 'Tanh', 'Linear'], 'correct': 1, 'explanation': 'Rectified Linear Unit.'},
    {'category': 'Neural Networks', 'question': 'What is tanh?', 'options': ['Sigmoid', 'tanh(x), outputs [-1,1]', 'ReLU', 'Linear'], 'correct': 1, 'explanation': 'Zero-centered sigmoid variant.'},
    {'category': 'Neural Networks', 'question': 'What is softmax?', 'options': ['Binary', 'Converts logits to probabilities', 'Hidden layer', 'ReLU'], 'correct': 1, 'explanation': 'For multi-class output.'},
    {'category': 'Neural Networks', 'question': 'What is backpropagation?', 'options': ['Forward pass', 'Algorithm to compute gradients', 'Loss', 'Initialization'], 'correct': 1, 'explanation': 'Computes gradients via chain rule.'},
    {'category': 'Neural Networks', 'question': 'What is vanishing gradient?', 'options': ['Exploding', 'Gradients too small in deep networks', 'No gradients', 'Large gradients'], 'correct': 1, 'explanation': 'Prevents learning in early layers.'},
    {'category': 'Neural Networks', 'question': 'What is exploding gradient?', 'options': ['Vanishing', 'Gradients too large causing instability', 'No problem', 'Small gradients'], 'correct': 1, 'explanation': 'Causes NaN values, use gradient clipping.'},
    {'category': 'Neural Networks', 'question': 'What is dropout?', 'options': ['Data augmentation', 'Randomly deactivate neurons', 'Loss', 'Optimizer'], 'correct': 1, 'explanation': 'Prevents overfitting.'},
    {'category': 'Neural Networks', 'question': 'What is batch normalization?', 'options': ['Data normalization', 'Normalize layer inputs per batch', 'Loss', 'Dropout'], 'correct': 1, 'explanation': 'Stabilizes training.'},
    {'category': 'Neural Networks', 'question': 'What is learning rate?', 'options': ['Regularization', 'Step size for gradient descent', 'Loss', 'Batch size'], 'correct': 1, 'explanation': 'Controls weight update magnitude.'},
    {'category': 'Neural Networks', 'question': 'What is an epoch?', 'options': ['One sample', 'Full pass through training data', 'One batch', 'One layer'], 'correct': 1, 'explanation': 'Complete dataset iteration.'},
    {'category': 'Neural Networks', 'question': 'What is batch size?', 'options': ['Dataset size', 'Samples per gradient update', 'Epochs', 'Layers'], 'correct': 1, 'explanation': 'Mini-batch size.'},
    {'category': 'Neural Networks', 'question': 'What is SGD?', 'options': ['Batch GD', 'Update using mini-batches', 'No updates', 'Adam'], 'correct': 1, 'explanation': 'Stochastic Gradient Descent.'},
    {'category': 'Neural Networks', 'question': 'What is Adam optimizer?', 'options': ['SGD variant', 'Adaptive learning with momentum', 'Loss', 'Activation'], 'correct': 1, 'explanation': 'Combines momentum and RMSprop.'},
    {'category': 'Neural Networks', 'question': 'What is momentum?', 'options': ['Learning rate', 'Accumulates gradient history', 'Batch size', 'Loss'], 'correct': 1, 'explanation': 'Accelerates convergence.'},
    {'category': 'Neural Networks', 'question': 'Why is weight initialization important?', 'options': ['Not important', 'Affects convergence and gradient flow', 'Random fine', 'Always zero'], 'correct': 1, 'explanation': 'Proper init ensures stable training.'},
    {'category': 'Neural Networks', 'question': 'What is Xavier initialization?', 'options': ['Random', 'Variance scaled by fan-in/out', 'Zero', 'One'], 'correct': 1, 'explanation': 'For sigmoid/tanh activations.'},
    {'category': 'Neural Networks', 'question': 'What is He initialization?', 'options': ['Xavier', 'Variance scaled by fan-in for ReLU', 'Random', 'Zero'], 'correct': 1, 'explanation': 'Designed for ReLU.'},
    {'category': 'Neural Networks', 'question': 'What is overfitting in NN?', 'options': ['Good generalization', 'Memorizes training data', 'Underfitting', 'Perfect fit'], 'correct': 1, 'explanation': 'Learns noise instead of patterns.'},
    {'category': 'Neural Networks', 'question': 'How to prevent overfitting?', 'options': ['More layers', 'Dropout, regularization, early stopping', 'Smaller dataset', 'No prevention'], 'correct': 1, 'explanation': 'Multiple regularization techniques.'},
    {'category': 'Neural Networks', 'question': 'What is L2 regularization?', 'options': ['L1 penalty', 'Add squared weights to loss', 'Dropout', 'Batch norm'], 'correct': 1, 'explanation': 'Weight decay penalty.'},
    {'category': 'Neural Networks', 'question': 'What is early stopping?', 'options': ['Stop at fixed epochs', 'Stop when validation error increases', 'Never stop', 'Random'], 'correct': 1, 'explanation': 'Prevents overfitting via validation monitoring.'},
    {'category': 'Neural Networks', 'question': 'What is convolutional layer?', 'options': ['Fully connected', 'Applies filters to local regions', 'Pooling', 'Dropout'], 'correct': 1, 'explanation': 'For spatial pattern detection.'},
    {'category': 'Neural Networks', 'question': 'What is pooling?', 'options': ['Convolution', 'Downsampling operation', 'Activation', 'Normalization'], 'correct': 1, 'explanation': 'Reduces spatial dimensions.'},
    {'category': 'Neural Networks', 'question': 'What is fully connected layer?', 'options': ['Convolutional', 'Every neuron connects to all previous', 'Pooling', 'Dropout'], 'correct': 1, 'explanation': 'Dense connections.'},
    {'category': 'Neural Networks', 'question': 'What is transfer learning?', 'options': ['Train from scratch', 'Use pre-trained model and fine-tune', 'No learning', 'Ensemble'], 'correct': 1, 'explanation': 'Leverage pre-trained weights.'},
    {'category': 'Neural Networks', 'question': 'What is data augmentation?', 'options': ['More collection', 'Artificially increase data with transforms', 'Cleaning', 'Normalization'], 'correct': 1, 'explanation': 'Create variations to expand dataset.'},
    {'category': 'Neural Networks', 'question': 'What is dying ReLU?', 'options': ['Vanishing', 'Neurons output zero permanently', 'Exploding', 'No problem'], 'correct': 1, 'explanation': 'Large negative inputs kill neurons.'},
    {'category': 'Neural Networks', 'question': 'What is Leaky ReLU?', 'options': ['ReLU', 'f(x) = max(αx, x) small α', 'Sigmoid', 'Tanh'], 'correct': 1, 'explanation': 'Prevents dying neurons.'},
    {'category': 'Neural Networks', 'question': 'What is gradient clipping?', 'options': ['No clipping', 'Limit gradient magnitude', 'Loss clipping', 'Weight clipping'], 'correct': 1, 'explanation': 'Prevents exploding gradients.'},
    {'category': 'Neural Networks', 'question': 'What is RNN?', 'options': ['Feedforward', 'Network with loops for sequences', 'CNN', 'Linear'], 'correct': 1, 'explanation': 'For sequential data.'},
    {'category': 'Neural Networks', 'question': 'What is LSTM?', 'options': ['Standard RNN', 'Long Short-Term Memory with gates', 'CNN', 'Transformer'], 'correct': 1, 'explanation': 'Handles long-term dependencies.'},
    {'category': 'Neural Networks', 'question': 'What is GRU?', 'options': ['LSTM', 'Gated Recurrent Unit, simpler', 'CNN', 'RNN'], 'correct': 1, 'explanation': 'Simpler than LSTM.'},
    {'category': 'Neural Networks', 'question': 'What is attention mechanism?', 'options': ['Pooling', 'Weights focus on relevant parts', 'Activation', 'Dropout'], 'correct': 1, 'explanation': 'Learns what to focus on.'},
    {'category': 'Neural Networks', 'question': 'What is transformer?', 'options': ['RNN', 'Architecture using self-attention', 'CNN', 'LSTM'], 'correct': 1, 'explanation': 'Basis for BERT, GPT.'},
    {'category': 'Neural Networks', 'question': 'What is residual connection?', 'options': ['Standard', 'Adds input to output: y = F(x) + x', 'Dropout', 'Pooling'], 'correct': 1, 'explanation': 'Enables very deep networks.'},
    {'category': 'Neural Networks', 'question': 'What is universal approximation theorem?', 'options': ['Cannot approximate', 'NN can approximate any function', 'Need infinite layers', 'Only linear'], 'correct': 1, 'explanation': 'Single hidden layer sufficient theoretically.'},
    {'category': 'Neural Networks', 'question': 'Parameters vs hyperparameters?', 'options': ['Same', 'Parameters learned, hyperparameters manual', 'Both learned', 'Both manual'], 'correct': 1, 'explanation': 'Parameters learned during training.'},
    {'category': 'Neural Networks', 'question': 'What is PReLU?', 'options': ['ReLU', 'Parametric ReLU with learnable α', 'Sigmoid', 'Tanh'], 'correct': 1, 'explanation': 'Learns negative slope.'},
    {'category': 'Neural Networks', 'question': 'What is ELU?', 'options': ['ReLU', 'Exponential Linear Unit', 'Sigmoid', 'Tanh'], 'correct': 1, 'explanation': 'Smoother than ReLU with negative values.'},
    {'category': 'Neural Networks', 'question': 'What is SELU?', 'options': ['ReLU', 'Scaled Exponential Linear Unit', 'Sigmoid', 'Tanh'], 'correct': 1, 'explanation': 'Self-normalizing activation.'},
    {'category': 'Neural Networks', 'question': 'What is Swish?', 'options': ['ReLU', 'x * sigmoid(x)', 'Sigmoid', 'Tanh'], 'correct': 1, 'explanation': 'Google\'s smooth activation.'},
    {'category': 'Neural Networks', 'question': 'What is GELU?', 'options': ['ReLU', 'Gaussian Error Linear Unit', 'Sigmoid', 'Tanh'], 'correct': 1, 'explanation': 'Used in BERT and GPT.'},
    {'category': 'Neural Networks', 'question': 'What is layer normalization?', 'options': ['Batch norm', 'Normalizes across features per sample', 'Dropout', 'Activation'], 'correct': 1, 'explanation': 'Alternative to batch norm.'},
    {'category': 'Neural Networks', 'question': 'What is group normalization?', 'options': ['Batch norm', 'Normalizes feature groups', 'Layer norm', 'Instance norm'], 'correct': 1, 'explanation': 'Divides channels into groups.'},
    {'category': 'Neural Networks', 'question': 'What is instance normalization?', 'options': ['Batch norm', 'Normalizes each sample independently', 'Layer norm', 'Group norm'], 'correct': 1, 'explanation': 'Used in style transfer.'},
    {'category': 'Neural Networks', 'question': 'What is weight decay?', 'options': ['L1', 'L2 regularization on weights', 'No decay', 'Dropout'], 'correct': 1, 'explanation': 'Adds penalty to large weights.'},
    {'category': 'Neural Networks', 'question': 'What is learning rate schedule?', 'options': ['Fixed rate', 'Varying learning rate during training', 'No schedule', 'Random'], 'correct': 1, 'explanation': 'Adjusts learning rate over time.'},
    {'category': 'Neural Networks', 'question': 'What is learning rate decay?', 'options': ['Increase', 'Gradually decrease learning rate', 'Constant', 'Random'], 'correct': 1, 'explanation': 'Helps fine-tune convergence.'},
    {'category': 'Neural Networks', 'question': 'What is warm-up?', 'options': ['Cool down', 'Gradually increase learning rate initially', 'Constant', 'Decrease'], 'correct': 1, 'explanation': 'Prevents early instability.'},
    {'category': 'Neural Networks', 'question': 'What is cyclical learning rate?', 'options': ['Constant', 'Oscillates between bounds', 'Only decrease', 'Only increase'], 'correct': 1, 'explanation': 'Cycles to escape local minima.'},
    {'category': 'Neural Networks', 'question': 'What is cosine annealing?', 'options': ['Linear decay', 'Cosine decay schedule', 'Exponential', 'Step decay'], 'correct': 1, 'explanation': 'Smoothly decays following cosine.'},
    {'category': 'Neural Networks', 'question': 'What is gradient accumulation?', 'options': ['No accumulation', 'Sum gradients over multiple batches', 'Single batch', 'Average'], 'correct': 1, 'explanation': 'Simulates larger batch sizes.'},
    {'category': 'Neural Networks', 'question': 'What is mixed precision training?', 'options': ['Single precision', 'Uses float16 and float32', 'Only float32', 'Only float16'], 'correct': 1, 'explanation': 'Speeds up training with less memory.'},
    {'category': 'Neural Networks', 'question': 'What is teacher forcing?', 'options': ['Student learning', 'Using ground truth as input in RNN', 'No forcing', 'Random'], 'correct': 1, 'explanation': 'Training technique for sequence models.'},
    {'category': 'Neural Networks', 'question': 'What is curriculum learning?', 'options': ['Random order', 'Train on easy examples first', 'Hard first', 'No order'], 'correct': 1, 'explanation': 'Gradually increase task difficulty.'},
    {'category': 'Neural Networks', 'question': 'What is knowledge distillation?', 'options': ['Single model', 'Transfer knowledge from teacher to student', 'No transfer', 'Random'], 'correct': 1, 'explanation': 'Compress large models to smaller ones.'},
    {'category': 'Neural Networks', 'question': 'What is neural architecture search?', 'options': ['Manual design', 'Automated architecture discovery', 'Fixed architecture', 'Random'], 'correct': 1, 'explanation': 'AutoML for finding best architecture.'},
    
    # PCA (30 questions)
    {'category': 'PCA', 'question': 'What is PCA?', 'options': ['Supervised', 'Unsupervised dimensionality reduction', 'Classification', 'Clustering'], 'correct': 1, 'explanation': 'PCA reduces dimensions via variance projection.'},
    {'category': 'PCA', 'question': 'What are principal components?', 'options': ['Original features', 'Orthogonal directions of max variance', 'Clusters', 'Labels'], 'correct': 1, 'explanation': 'Uncorrelated directions capturing variance.'},
    {'category': 'PCA', 'question': 'Does PCA need scaling?', 'options': ['No', 'Yes, sensitive to scale', 'Sometimes', 'Never'], 'correct': 1, 'explanation': 'Must standardize features.'},
    {'category': 'PCA', 'question': 'What does PCA preserve?', 'options': ['Distance', 'Variance', 'Labels', 'Clusters'], 'correct': 1, 'explanation': 'Maximizes preserved variance.'},
    {'category': 'PCA', 'question': 'Are PCs interpretable?', 'options': ['Yes, easily', 'No, linear combinations', 'Always', 'Sometimes'], 'correct': 1, 'explanation': 'PCs are weighted feature combinations.'},
    {'category': 'PCA', 'question': 'What is explained variance?', 'options': ['Total variance', 'Variance captured by each PC', 'Error', 'Loss'], 'correct': 1, 'explanation': 'Shows information retained per PC.'},
    {'category': 'PCA', 'question': 'How to choose components?', 'options': ['Always 2', 'Cumulative variance (e.g., 95%)', 'Random', 'Maximum'], 'correct': 1, 'explanation': 'Keep until threshold reached.'},
    {'category': 'PCA', 'question': 'What is scree plot?', 'options': ['Loss plot', 'Plot variance vs component', 'Accuracy', 'Confusion matrix'], 'correct': 1, 'explanation': 'Find elbow in variance curve.'},
    {'category': 'PCA', 'question': 'Can PCA visualize data?', 'options': ['No', 'Yes, reduce to 2-3D', 'Only 1D', 'Not useful'], 'correct': 1, 'explanation': 'Common for visualization.'},
    {'category': 'PCA', 'question': 'Is PCA linear or non-linear?', 'options': ['Non-linear', 'Linear transformation', 'Both', 'Neither'], 'correct': 1, 'explanation': 'Performs linear projections.'},
    {'category': 'PCA', 'question': 'What is covariance matrix?', 'options': ['Distance matrix', 'Matrix of feature covariances', 'Correlation only', 'Labels'], 'correct': 1, 'explanation': 'Used to find eigenvectors.'},
    {'category': 'PCA', 'question': 'What are eigenvalues?', 'options': ['Eigenvectors', 'Variance along each PC', 'Features', 'Samples'], 'correct': 1, 'explanation': 'Represent variance per component.'},
    {'category': 'PCA', 'question': 'What are eigenvectors?', 'options': ['Eigenvalues', 'Directions of PCs', 'Features', 'Clusters'], 'correct': 1, 'explanation': 'Define PC directions.'},
    {'category': 'PCA', 'question': 'Can PCA handle missing values?', 'options': ['Yes, natively', 'No, requires imputation', 'Sometimes', 'Always'], 'correct': 1, 'explanation': 'Requires complete data.'},
    {'category': 'PCA', 'question': 'What is curse of dimensionality?', 'options': ['More dimensions help', 'Data sparse in high dimensions', 'No effect', 'Better performance'], 'correct': 1, 'explanation': 'PCA helps reduce dimensions.'},
    {'category': 'PCA', 'question': 'Can PCA be inverted?', 'options': ['No', 'Yes, with information loss', 'Perfectly', 'Never'], 'correct': 1, 'explanation': 'Approximate reconstruction possible.'},
    {'category': 'PCA', 'question': 'What is whitening?', 'options': ['Normalization before', 'Scale components to unit variance', 'Cleaning', 'Selection'], 'correct': 1, 'explanation': 'Makes components uncorrelated, unit variance.'},
    {'category': 'PCA', 'question': 'What is kernel PCA?', 'options': ['Standard PCA', 'Non-linear PCA using kernels', 'Linear only', 'Clustering'], 'correct': 1, 'explanation': 'Applies PCA in kernel space.'},
    {'category': 'PCA', 'question': 'When is PCA most useful?', 'options': ['Low dimensions', 'High-dimensional, correlated features', 'No correlation', 'Few samples'], 'correct': 1, 'explanation': 'Best with many correlated features.'},
    {'category': 'PCA', 'question': 'PCA vs LDA?', 'options': ['Same', 'PCA unsupervised, LDA supervised', 'PCA supervised', 'No difference'], 'correct': 1, 'explanation': 'PCA maximizes variance, LDA separates classes.'},
    {'category': 'PCA', 'question': 'What is incremental PCA?', 'options': ['Standard PCA', 'PCA for large datasets in batches', 'Faster', 'Slower'], 'correct': 1, 'explanation': 'Processes data in mini-batches.'},
    {'category': 'PCA', 'question': 'What is sparse PCA?', 'options': ['Dense PCA', 'PCA with sparse loadings', 'Standard PCA', 'No sparsity'], 'correct': 1, 'explanation': 'Encourages sparse components for interpretability.'},
    {'category': 'PCA', 'question': 'What is randomized PCA?', 'options': ['Deterministic', 'Faster approximation using randomization', 'Exact', 'Slower'], 'correct': 1, 'explanation': 'Approximates PCA faster for large data.'},
    {'category': 'PCA', 'question': 'What is truncated SVD?', 'options': ['Full SVD', 'Computes only k components', 'All components', 'No truncation'], 'correct': 1, 'explanation': 'Efficient for sparse matrices.'},
    {'category': 'PCA', 'question': 'PCA vs t-SNE?', 'options': ['Same', 'PCA linear, t-SNE non-linear', 'PCA non-linear', 'No difference'], 'correct': 1, 'explanation': 't-SNE better for visualization, non-linear.'},
    {'category': 'PCA', 'question': 'PCA vs UMAP?', 'options': ['Same', 'PCA linear, UMAP non-linear manifold', 'PCA non-linear', 'No difference'], 'correct': 1, 'explanation': 'UMAP preserves local and global structure.'},
    {'category': 'PCA', 'question': 'What is factor analysis?', 'options': ['PCA', 'Models latent factors with noise', 'Same as PCA', 'Clustering'], 'correct': 1, 'explanation': 'Probabilistic approach, models noise.'},
    {'category': 'PCA', 'question': 'What is ICA?', 'options': ['PCA', 'Independent Component Analysis', 'Same as PCA', 'Clustering'], 'correct': 1, 'explanation': 'Finds statistically independent components.'},
    {'category': 'PCA', 'question': 'Can PCA remove noise?', 'options': ['No', 'Yes, by discarding low-variance components', 'Never', 'Always'], 'correct': 1, 'explanation': 'Low-variance PCs often represent noise.'},
    {'category': 'PCA', 'question': 'What is n_components parameter?', 'options': ['All components', 'Number of components to keep', 'Minimum', 'Fixed'], 'correct': 1, 'explanation': 'Specifies how many PCs to retain.'},
    
    # Naive Bayes (25 questions)
    {'category': 'Naive Bayes', 'question': 'What is Naive Bayes based on?', 'options': ['Decision trees', 'Bayes theorem with independence', 'Neural networks', 'SVM'], 'correct': 1, 'explanation': 'Applies Bayes theorem with naive assumption.'},
    {'category': 'Naive Bayes', 'question': 'What does naive mean?', 'options': ['Simple', 'Assumes features independent', 'Fast', 'Inaccurate'], 'correct': 1, 'explanation': 'Assumes conditional independence.'},
    {'category': 'Naive Bayes', 'question': 'What is Gaussian NB?', 'options': ['Discrete', 'Assumes normal distribution', 'Binary', 'Text'], 'correct': 1, 'explanation': 'For continuous features.'},
    {'category': 'Naive Bayes', 'question': 'What is Multinomial NB?', 'options': ['Continuous', 'For discrete count data', 'Gaussian', 'Binary'], 'correct': 1, 'explanation': 'For count data like word frequencies.'},
    {'category': 'Naive Bayes', 'question': 'What is Bernoulli NB?', 'options': ['Count', 'For binary features', 'Continuous', 'Gaussian'], 'correct': 1, 'explanation': 'For binary/boolean features.'},
    {'category': 'Naive Bayes', 'question': 'Advantage of Naive Bayes?', 'options': ['Most accurate', 'Fast, simple, works with small data', 'Complex', 'Slow'], 'correct': 1, 'explanation': 'Extremely fast and efficient.'},
    {'category': 'Naive Bayes', 'question': 'What is Laplace smoothing?', 'options': ['No smoothing', 'Add small value to avoid zero probabilities', 'Scaling', 'Regularization'], 'correct': 1, 'explanation': 'Prevents zero probability issues.'},
    {'category': 'Naive Bayes', 'question': 'Does NB need scaling?', 'options': ['Yes', 'No, probability-based', 'Sometimes', 'Always'], 'correct': 1, 'explanation': 'Works with probabilities, not distances.'},
    {'category': 'Naive Bayes', 'question': 'Can NB handle continuous?', 'options': ['No', 'Yes, with Gaussian NB', 'Only discrete', 'Never'], 'correct': 1, 'explanation': 'Gaussian NB for continuous features.'},
    {'category': 'Naive Bayes', 'question': 'Is NB good for text?', 'options': ['No', 'Yes, very popular for text classification', 'Only numbers', 'Not effective'], 'correct': 1, 'explanation': 'Excellent for spam detection, sentiment analysis.'},
    {'category': 'Naive Bayes', 'question': 'What is prior probability?', 'options': ['P(X|y)', 'P(y) - class probability', 'P(X)', 'Likelihood'], 'correct': 1, 'explanation': 'Probability of each class.'},
    {'category': 'Naive Bayes', 'question': 'What is likelihood?', 'options': ['Prior', 'P(X|y) - features given class', 'P(y|X)', 'Posterior'], 'correct': 1, 'explanation': 'Probability of features given class.'},
    {'category': 'Naive Bayes', 'question': 'What is posterior?', 'options': ['Prior', 'P(y|X) - class given features', 'Likelihood', 'Evidence'], 'correct': 1, 'explanation': 'What we want to compute.'},
    {'category': 'Naive Bayes', 'question': 'Can NB output probabilities?', 'options': ['No', 'Yes, directly outputs probabilities', 'Only with calibration', 'Never'], 'correct': 1, 'explanation': 'Naturally outputs class probabilities.'},
    {'category': 'Naive Bayes', 'question': 'When does NB perform poorly?', 'options': ['Always good', 'When features highly correlated', 'Small data', 'Text'], 'correct': 1, 'explanation': 'Struggles with correlated features.'},
    {'category': 'Naive Bayes', 'question': 'What is alpha in smoothing?', 'options': ['No smoothing', 'Smoothing parameter (typically 1)', 'Learning rate', 'Regularization'], 'correct': 1, 'explanation': 'Controls amount of smoothing.'},
    {'category': 'Naive Bayes', 'question': 'What is fit_prior parameter?', 'options': ['Always true', 'Whether to learn class priors', 'Always false', 'No effect'], 'correct': 1, 'explanation': 'Learn priors from data or use uniform.'},
    {'category': 'Naive Bayes', 'question': 'What is class_prior?', 'options': ['Automatic', 'Manually specified class probabilities', 'Always uniform', 'No priors'], 'correct': 1, 'explanation': 'Can override learned priors.'},
    {'category': 'Naive Bayes', 'question': 'Can NB handle multi-class?', 'options': ['No', 'Yes, naturally', 'Only binary', 'Requires modification'], 'correct': 1, 'explanation': 'Extends naturally to multiple classes.'},
    {'category': 'Naive Bayes', 'question': 'Is NB generative or discriminative?', 'options': ['Discriminative', 'Generative', 'Neither', 'Both'], 'correct': 1, 'explanation': 'Models class-conditional distributions.'},
    {'category': 'Naive Bayes', 'question': 'What is MAP in NB?', 'options': ['Minimum', 'Maximum A Posteriori', 'Mean', 'Median'], 'correct': 1, 'explanation': 'Selects class with highest posterior.'},
    {'category': 'Naive Bayes', 'question': 'Can NB handle missing values?', 'options': ['Yes, ignores them', 'Depends, usually need imputation', 'Always handles', 'Never'], 'correct': 1, 'explanation': 'Implementation-dependent.'},
    {'category': 'Naive Bayes', 'question': 'What is complement NB?', 'options': ['Standard NB', 'Estimates from complement of each class', 'Same as multinomial', 'No difference'], 'correct': 1, 'explanation': 'Better for imbalanced text data.'},
    {'category': 'Naive Bayes', 'question': 'What is categorical NB?', 'options': ['Gaussian', 'For categorical features', 'Multinomial', 'Bernoulli'], 'correct': 1, 'explanation': 'Specifically for categorical data.'},
    {'category': 'Naive Bayes', 'question': 'NB vs Logistic Regression?', 'options': ['Same', 'NB generative, LR discriminative', 'NB discriminative', 'No difference'], 'correct': 1, 'explanation': 'Different modeling approaches.'},
    
    # NumPy (40 questions)
    {'category': 'NumPy', 'question': 'What is NumPy?', 'options': ['Plotting', 'Numerical computing for arrays', 'ML framework', 'Database'], 'correct': 1, 'explanation': 'Efficient array operations.'},
    {'category': 'NumPy', 'question': 'What is ndarray?', 'options': ['List', 'N-dimensional array', 'DataFrame', 'Dictionary'], 'correct': 1, 'explanation': 'Core NumPy data structure.'},
    {'category': 'NumPy', 'question': 'What is broadcasting?', 'options': ['Sending data', 'Automatic shape adjustment', 'Parallel computing', 'Type conversion'], 'correct': 1, 'explanation': 'Allows operations on different shapes.'},
    {'category': 'NumPy', 'question': 'What is vectorization?', 'options': ['Adding vectors', 'Replace loops with array operations', 'Normalization', 'Engineering'], 'correct': 1, 'explanation': 'Much faster than Python loops.'},
    {'category': 'NumPy', 'question': 'What does reshape do?', 'options': ['Changes values', 'Changes dimensions without changing data', 'Sorts', 'Filters'], 'correct': 1, 'explanation': 'Returns new shape view.'},
    {'category': 'NumPy', 'question': 'Copy vs view?', 'options': ['No difference', 'Copy creates new, view shares memory', 'View copies', 'Both copy'], 'correct': 1, 'explanation': 'View shares data with original.'},
    {'category': 'NumPy', 'question': 'What does transpose do?', 'options': ['Sorts', 'Swaps dimensions', 'Reverses', 'Normalizes'], 'correct': 1, 'explanation': 'Permutes array dimensions.'},
    {'category': 'NumPy', 'question': 'What is random.seed for?', 'options': ['Generate random', 'Set random state for reproducibility', 'Delete random', 'Count randoms'], 'correct': 1, 'explanation': 'Makes random operations reproducible.'},
    {'category': 'NumPy', 'question': 'What does where do?', 'options': ['Searches files', 'Returns indices/values based on condition', 'Deletes', 'Sorts'], 'correct': 1, 'explanation': 'Conditional element selection.'},
    {'category': 'NumPy', 'question': 'What is concatenate?', 'options': ['Splits', 'Joins arrays along axis', 'Creates', 'Deletes'], 'correct': 1, 'explanation': 'Joins arrays on existing axis.'},
    {'category': 'NumPy', 'question': 'What does stack do?', 'options': ['Removes', 'Joins along new axis', 'Splits', 'Sorts'], 'correct': 1, 'explanation': 'Joins arrays along new dimension.'},
    {'category': 'NumPy', 'question': 'What is argmax?', 'options': ['Maximum value', 'Index of maximum', 'Minimum', 'Average'], 'correct': 1, 'explanation': 'Returns index of max value.'},
    {'category': 'NumPy', 'question': 'What is linspace?', 'options': ['Random', 'Evenly spaced values', 'Integers only', 'Logarithmic'], 'correct': 1, 'explanation': 'Creates evenly spaced numbers.'},
    {'category': 'NumPy', 'question': 'What is einsum?', 'options': ['Simple addition', 'Einstein summation for tensors', 'Element-wise', 'Sorting'], 'correct': 1, 'explanation': 'Efficient tensor operations.'},
    {'category': 'NumPy', 'question': 'What is dtype?', 'options': ['Shape', 'Data type of elements', 'Dimension', 'Size'], 'correct': 1, 'explanation': 'Specifies element type.'},
    {'category': 'NumPy', 'question': 'What is np.array vs np.asarray?', 'options': ['Same', 'array copies, asarray may not', 'asarray copies', 'No difference'], 'correct': 1, 'explanation': 'asarray avoids copy if possible.'},
    {'category': 'NumPy', 'question': 'What is np.arange?', 'options': ['Random', 'Range of values', 'Sorting', 'Filtering'], 'correct': 1, 'explanation': 'Like Python range for arrays.'},
    {'category': 'NumPy', 'question': 'What is np.zeros?', 'options': ['Random', 'Array filled with zeros', 'Ones', 'Empty'], 'correct': 1, 'explanation': 'Creates zero-filled array.'},
    {'category': 'NumPy', 'question': 'What is np.ones?', 'options': ['Zeros', 'Array filled with ones', 'Random', 'Empty'], 'correct': 1, 'explanation': 'Creates one-filled array.'},
    {'category': 'NumPy', 'question': 'What is np.empty?', 'options': ['Zeros', 'Uninitialized array', 'Ones', 'Random'], 'correct': 1, 'explanation': 'Allocates memory without initializing.'},
    {'category': 'NumPy', 'question': 'What is np.eye?', 'options': ['Zeros', 'Identity matrix', 'Random', 'Diagonal'], 'correct': 1, 'explanation': 'Creates identity matrix.'},
    {'category': 'NumPy', 'question': 'What is np.diag?', 'options': ['Full matrix', 'Extract/construct diagonal', 'Random', 'Identity'], 'correct': 1, 'explanation': 'Works with diagonal elements.'},
    {'category': 'NumPy', 'question': 'What is np.dot?', 'options': ['Element-wise', 'Dot product/matrix multiplication', 'Addition', 'Division'], 'correct': 1, 'explanation': 'Matrix multiplication.'},
    {'category': 'NumPy', 'question': 'What is np.matmul vs np.dot?', 'options': ['Same', 'matmul is modern, stricter rules', 'No difference', 'dot better'], 'correct': 1, 'explanation': 'matmul preferred for matrix multiplication.'},
    {'category': 'NumPy', 'question': 'What is @ operator?', 'options': ['Addition', 'Matrix multiplication', 'Division', 'Power'], 'correct': 1, 'explanation': 'Shorthand for matmul.'},
    {'category': 'NumPy', 'question': 'What is np.sum vs np.cumsum?', 'options': ['Same', 'sum totals, cumsum cumulative', 'No difference', 'cumsum sums'], 'correct': 1, 'explanation': 'cumsum gives running total.'},
    {'category': 'NumPy', 'question': 'What is axis parameter?', 'options': ['No effect', 'Specifies dimension for operation', 'Data type', 'Shape'], 'correct': 1, 'explanation': 'Controls operation direction.'},
    {'category': 'NumPy', 'question': 'What does flatten do?', 'options': ['No change', 'Converts to 1D array', '2D only', 'Transposes'], 'correct': 1, 'explanation': 'Creates 1D copy.'},
    {'category': 'NumPy', 'question': 'What does ravel do?', 'options': ['Copies always', 'Flattens, returns view if possible', 'Creates copy', 'No flattening'], 'correct': 1, 'explanation': 'Like flatten but may return view.'},
    {'category': 'NumPy', 'question': 'What is np.squeeze?', 'options': ['Adds dimensions', 'Removes single-dimensional entries', 'No change', 'Flattens'], 'correct': 1, 'explanation': 'Removes axes of length 1.'},
    {'category': 'NumPy', 'question': 'What is np.expand_dims?', 'options': ['Removes dimensions', 'Adds dimension', 'No change', 'Flattens'], 'correct': 1, 'explanation': 'Inserts new axis.'},
    {'category': 'NumPy', 'question': 'What is np.tile?', 'options': ['Splits', 'Repeats array', 'No repeat', 'Concatenates'], 'correct': 1, 'explanation': 'Constructs array by repeating.'},
    {'category': 'NumPy', 'question': 'What is np.repeat?', 'options': ['Tiles', 'Repeats elements', 'No repeat', 'Different from tile'], 'correct': 1, 'explanation': 'Repeats each element.'},
    {'category': 'NumPy', 'question': 'What is np.unique?', 'options': ['All values', 'Returns unique values', 'Duplicates', 'Sorted'], 'correct': 1, 'explanation': 'Finds unique elements.'},
    {'category': 'NumPy', 'question': 'What is np.sort vs np.argsort?', 'options': ['Same', 'sort returns sorted, argsort indices', 'No difference', 'argsort sorts'], 'correct': 1, 'explanation': 'argsort gives sorting indices.'},
    {'category': 'NumPy', 'question': 'What is np.clip?', 'options': ['No limit', 'Limits values to range', 'Sorting', 'Filtering'], 'correct': 1, 'explanation': 'Clips values to min/max.'},
    {'category': 'NumPy', 'question': 'What is np.meshgrid?', 'options': ['1D grid', 'Creates coordinate matrices', 'No grid', 'Sorting'], 'correct': 1, 'explanation': 'For coordinate grids.'},
    {'category': 'NumPy', 'question': 'What is np.linalg.inv?', 'options': ['Transpose', 'Matrix inverse', 'Determinant', 'Eigenvalues'], 'correct': 1, 'explanation': 'Computes matrix inverse.'},
    {'category': 'NumPy', 'question': 'What is np.linalg.eig?', 'options': ['Inverse', 'Eigenvalues and eigenvectors', 'Determinant', 'Transpose'], 'correct': 1, 'explanation': 'Computes eigendecomposition.'},
    {'category': 'NumPy', 'question': 'What is np.linalg.norm?', 'options': ['Normalization', 'Vector/matrix norm', 'Transpose', 'Inverse'], 'correct': 1, 'explanation': 'Computes various norms.'},
    
    # Pandas (50 questions)

def get_categories():
    return ['all'] + sorted(list(set([q['category'] for q in questions])))

def filter_questions(category):
    if category == 'all':
        return questions
    return [q for q in questions if q['category'] == category]

def start_quiz():
    filtered = filter_questions(st.session_state.selected_category)
    st.session_state.question_pool = random.sample(filtered, len(filtered))
    st.session_state.quiz_started = True
    st.session_state.current_question = 0
    st.session_state.score = 0
    st.session_state.selected_answer = None
    st.session_state.show_result = False

def select_answer(answer_idx):
    if st.session_state.selected_answer is None:
        st.session_state.selected_answer = answer_idx
        current_q = st.session_state.question_pool[st.session_state.current_question]
        is_correct = answer_idx == current_q['correct']
        
        if is_correct:
            st.session_state.score += 1
            st.session_state.stats['correct'] += 1
        else:
            st.session_state.stats['wrong'] += 1
        
        st.session_state.stats['total'] += 1

def next_question():
    if st.session_state.current_question + 1 < len(st.session_state.question_pool):
        st.session_state.current_question += 1
        st.session_state.selected_answer = None
    else:
        st.session_state.show_result = True

def restart_quiz():
    st.session_state.quiz_started = False
    st.session_state.current_question = 0
    st.session_state.score = 0
    st.session_state.selected_answer = None
    st.session_state.show_result = False
    st.session_state.question_pool = []

def reset_stats():
    st.session_state.stats = {'total': 0, 'correct': 0, 'wrong': 0}

# Main App
if not st.session_state.quiz_started:
    # Home Screen
    st.markdown("<h1 style='text-align: center;'>🧠 ML Algorithms Quiz Master</h1>", unsafe_allow_html=True)
    st.markdown("<p style='text-align: center; font-size: 20px;'>Test your knowledge across 500+ questions!</p>", unsafe_allow_html=True)
    
    st.markdown("---")
    
    # Stats Display
    st.subheader("📊 Your Stats")
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("Total Attempts", st.session_state.stats['total'])
    with col2:
        st.metric("Correct", st.session_state.stats['correct'])
    with col3:
        st.metric("Wrong", st.session_state.stats['wrong'])
    
    if st.session_state.stats['total'] > 0:
        accuracy = (st.session_state.stats['correct'] / st.session_state.stats['total']) * 100
        st.success(f"🎯 Accuracy: {accuracy:.1f}%")
        if st.button("Reset Stats"):
            reset_stats()
            st.rerun()
    
    st.markdown("---")
    
    # Category Selection
    st.subheader("Select Category")
    categories = get_categories()
    
    cols = st.columns(3)
    for idx, cat in enumerate(categories):
        with cols[idx % 3]:
            if cat == 'all':
                label = f"🎯 All Topics ({len(questions)} questions)"
            else:
                count = len([q for q in questions if q['category'] == cat])
                label = f"{cat} ({count} questions)"
            
            if st.button(label, key=f"cat_{cat}", use_container_width=True):
                st.session_state.selected_category = cat
    
    st.info(f"Selected: **{st.session_state.selected_category}**")
    
    st.markdown("---")
    
    if st.button("🚀 Start Quiz", type="primary", use_container_width=True):
        start_quiz()
        st.rerun()
    
    # Topics covered
    st.markdown("---")
    st.subheader("📚 Topics Covered")
    st.markdown("""
    - Linear & Logistic Regression
    - Decision Trees & Random Forest
    - Gradient Boosting (XGBoost, LightGBM)
    - Support Vector Machines
    - K-Means & Clustering
    - Neural Networks & Deep Learning
    - PCA & Dimensionality Reduction
    - Naive Bayes
    - NumPy & Pandas
    - Scikit-learn & TensorFlow
    - Matplotlib & Seaborn
    - And many more!
    """)

elif st.session_state.show_result:
    # Results Screen
    st.markdown("<h1 style='text-align: center;'>🏆 Quiz Complete!</h1>", unsafe_allow_html=True)
    
    percentage = (st.session_state.score / len(st.session_state.question_pool)) * 100
    
    st.markdown(f"<h1 style='text-align: center; color: #0891b2;'>{percentage:.1f}%</h1>", unsafe_allow_html=True)
    st.markdown(f"<p style='text-align: center; font-size: 24px;'>You scored {st.session_state.score} out of {len(st.session_state.question_pool)}</p>", unsafe_allow_html=True)
    
    if percentage >= 90:
        st.success("🏆 Outstanding! ML Expert!")
    elif percentage >= 75:
        st.success("🌟 Excellent! Great knowledge!")
    elif percentage >= 60:
        st.info("👍 Good job! Keep learning!")
    elif percentage >= 40:
        st.warning("📚 Not bad! More practice needed!")
    else:
        st.error("💪 Keep studying! You can do it!")
    
    col1, col2 = st.columns(2)
    with col1:
        if st.button("🔄 Take Another Quiz", type="primary", use_container_width=True):
            restart_quiz()
            st.rerun()
    with col2:
        if st.button("🏠 Back to Home", use_container_width=True):
            restart_quiz()
            st.rerun()

else:
    # Quiz Screen
    current_q = st.session_state.question_pool[st.session_state.current_question]
    progress = (st.session_state.current_question + 1) / len(st.session_state.question_pool)
    
    # Header
    col1, col2 = st.columns([2, 1])
    with col1:
        st.markdown(f"**Question {st.session_state.current_question + 1} / {len(st.session_state.question_pool)}**")
    with col2:
        st.markdown(f"**Score: {st.session_state.score}**")
    
    st.progress(progress)
    st.markdown("---")
    
    # Question
    st.markdown(f"<div class='category-badge'>{current_q['category']}</div>", unsafe_allow_html=True)
    st.markdown(f"### {current_q['question']}")
    st.markdown("")
    
    # Options
    for idx, option in enumerate(current_q['options']):
        is_selected = st.session_state.selected_answer == idx
        is_correct = idx == current_q['correct']
        show_answer = st.session_state.selected_answer is not None
        
        button_type = "primary" if not show_answer else "secondary"
        
        if show_answer:
            if is_correct:
                st.success(f"✅ {option}")
            elif is_selected:
                st.error(f"❌ {option}")
            else:
                st.write(f"⚪ {option}")
        else:
            if st.button(option, key=f"opt_{idx}", use_container_width=True):
                select_answer(idx)
                st.rerun()
    
    # Explanation
    if st.session_state.selected_answer is not None:
        st.markdown("---")
        if st.session_state.selected_answer == current_q['correct']:
            st.success("✓ Correct!")
        else:
            st.error("✗ Incorrect")
        
        st.info(f"💡 **Explanation:** {current_q['explanation']}")
        
        if st.button("Next Question →" if st.session_state.current_question + 1 < len(st.session_state.question_pool) else "View Results", 
                     type="primary", use_container_width=True):
            next_question()
            st.rerun()
    
    # Exit button
    st.markdown("---")
    if st.button("🚪 Exit Quiz"):
        restart_quiz()
        st.rerun()
